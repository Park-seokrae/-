{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6003f2",
   "metadata": {},
   "source": [
    "## 00. ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "861e5d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import collections\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# ======================\n",
    "# 0. ÌôòÍ≤Ω Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
    "# ======================\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î£®Ìä∏ Í≤ΩÎ°ú: \n",
    "DATA_ROOT = Path(\"/Users/srpark/Projects/RL_project/data/processed/RL_cleaned\")\n",
    "\n",
    "# ÌååÏùº Ïù¥Î¶Ñ \n",
    "CT_NAME   = \"ct.nii.gz\"\n",
    "MASK_NAME = \"whole_artery_cleaned.nii.gz\"\n",
    "   \n",
    "\n",
    "PATCH_SIZE = (32, 32, 32)   # (D, H, W)\n",
    "\n",
    "# ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï (M2 Îß•: mps ÏÇ¨Ïö©)\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff453884",
   "metadata": {},
   "source": [
    "## 01. action ÏùÑ ÌÜµÌï¥ Ïù¥ÎèôÌïú voxel Ïù¥ Ï†ïÎãµ ÌòàÍ¥Ä(mask.nii) volume ÎÇ¥Ïóê ÏûàÎäîÏßÄÏóê Îî∞Î•∏ Î≥¥ÏÉÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcfb7879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Found 100 cases under /Users/srpark/Projects/RL_project/data/RL_prepared\n",
      "[Episode 010] reward=6.0, steps=8, eps=0.098, buffer=121, case=01015ug_91, inside=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/78/kff0l0ts7cnc7n54tdllr0qc0000gn/T/ipykernel_49145/267094466.py:358: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)\n",
      "  s       = torch.tensor(s_lst, dtype=torch.float32, device=DEVICE)      # (B,1,32,32,32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 020] reward=-1.0, steps=1, eps=0.096, buffer=241, case=01011ug_528, inside=False\n",
      "[Episode 030] reward=11.0, steps=13, eps=0.094, buffer=430, case=01011ug_506, inside=False\n",
      "[Episode 040] reward=32.0, steps=32, eps=0.092, buffer=563, case=01010ug_136, inside=True\n",
      "[Episode 050] reward=32.0, steps=32, eps=0.090, buffer=715, case=01018ug_88, inside=True\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import collections\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# ======================\n",
    "# 0. ÌôòÍ≤Ω Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
    "# ======================\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î£®Ìä∏ Í≤ΩÎ°ú: RL_prepared Ìè¥Îçî\n",
    "DATA_ROOT = Path(\"/Users/srpark/Projects/RL_project/data/RL_prepared\")\n",
    "\n",
    "# ÌååÏùº Ïù¥Î¶Ñ (ÌïÑÏöîÌïòÎ©¥ Ïó¨Í∏∞Îßå ÏàòÏ†ï)\n",
    "CT_NAME   = \"ct.nii.gz\"\n",
    "MASK_NAME = \"Whole_artery.nii.gz\"   # Ìè¥Îçî Ïïà ÌååÏùºÎ™Ö ÌôïÏù∏Ìï¥ÏÑú ÎßûÏ∂îÍ∏∞\n",
    "\n",
    "PATCH_SIZE = (32, 32, 32)   # (D, H, W)\n",
    "\n",
    "# ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï (M2 Îß•: mps ÏÇ¨Ïö©)\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# ======================\n",
    "# 1. Îç∞Ïù¥ÌÑ∞ Î°úÎî© & Ï†ÑÏ≤òÎ¶¨\n",
    "# ======================\n",
    "\n",
    "def load_case(case_dir: Path,\n",
    "              ct_name: str = CT_NAME,\n",
    "              mask_name: str = MASK_NAME):\n",
    "    \"\"\"\n",
    "    case_dir: .../RL_prepared/01011ug_500 Ïù¥Îü∞ Ìè¥Îçî\n",
    "    ÏïàÏóê ct.nii.gz, Whole_artery.nii.gz Í∞Ä ÏûàÏñ¥Ïïº Ìï®\n",
    "    \"\"\"\n",
    "    ct_path   = case_dir / ct_name\n",
    "    mask_path = case_dir / mask_name\n",
    "\n",
    "    if not ct_path.exists():\n",
    "        raise FileNotFoundError(f\"CT not found: {ct_path}\")\n",
    "    if not mask_path.exists():\n",
    "        raise FileNotFoundError(f\"Mask not found: {mask_path}\")\n",
    "\n",
    "    ct_nii   = nib.load(str(ct_path))\n",
    "    mask_nii = nib.load(str(mask_path))\n",
    "\n",
    "    ct   = ct_nii.get_fdata().astype(np.float32)    # (D,H,W)\n",
    "    mask = mask_nii.get_fdata().astype(np.float32)  # (D,H,W), 0/1 ÎòêÎäî label\n",
    "\n",
    "    if ct.shape != mask.shape:\n",
    "        raise ValueError(f\"Shape mismatch: CT {ct.shape}, MASK {mask.shape} at {case_dir}\")\n",
    "\n",
    "    return ct, mask\n",
    "\n",
    "def normalize_ct(ct: np.ndarray,\n",
    "                 hu_min: float = -200.0,\n",
    "                 hu_max: float = 300.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    CT HU Í∞íÏùÑ [hu_min, hu_max]Î°ú ÌÅ¥Î¶¨Ìïë ÌõÑ [0,1]Î°ú Ï†ïÍ∑úÌôî\n",
    "    \"\"\"\n",
    "    ct = np.clip(ct, hu_min, hu_max)\n",
    "    ct = (ct - hu_min) / (hu_max - hu_min + 1e-8)\n",
    "    return ct.astype(np.float32)\n",
    "\n",
    "def get_patch(volume: np.ndarray,\n",
    "              center: tuple,\n",
    "              patch_size=PATCH_SIZE) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    volume: (D,H,W)\n",
    "    center: (z,y,x)\n",
    "    patch_size: (pd,ph,pw)\n",
    "    - Î≥ºÎ•® Î∞ñÏúºÎ°ú ÎÇòÍ∞ÄÎäî Í≤ΩÏö∞ 0 padding\n",
    "    \"\"\"\n",
    "    D, H, W = volume.shape\n",
    "    pd, ph, pw = patch_size\n",
    "    zc, yc, xc = center\n",
    "\n",
    "    z0 = zc - pd // 2\n",
    "    y0 = yc - ph // 2\n",
    "    x0 = xc - pw // 2\n",
    "    z1 = z0 + pd\n",
    "    y1 = y0 + ph\n",
    "    x1 = x0 + pw\n",
    "\n",
    "    patch = np.zeros((pd, ph, pw), dtype=volume.dtype)\n",
    "\n",
    "    z0_src = max(z0, 0)\n",
    "    y0_src = max(y0, 0)\n",
    "    x0_src = max(x0, 0)\n",
    "    z1_src = min(z1, D)\n",
    "    y1_src = min(y1, H)\n",
    "    x1_src = min(x1, W)\n",
    "\n",
    "    z0_dst = z0_src - z0\n",
    "    y0_dst = y0_src - y0\n",
    "    x0_dst = x0_src - x0\n",
    "\n",
    "    patch[\n",
    "        z0_dst:z0_dst + (z1_src - z0_src),\n",
    "        y0_dst:y0_dst + (y1_src - y0_src),\n",
    "        x0_dst:x0_dst + (x1_src - x0_src)\n",
    "    ] = volume[z0_src:z1_src, y0_src:y1_src, x0_src:x1_src]\n",
    "\n",
    "    return patch\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 2. CT Vessel Env Ï†ïÏùò\n",
    "# ======================\n",
    "\n",
    "class CTVesselEnv:\n",
    "    \"\"\"\n",
    "    - ÏÉÅÌÉú: ÌòÑÏû¨ ÏúÑÏπò Ï£ºÎ≥ÄÏùò 32x32x32 CT Ìå®Ïπò (normalizeÎê®)\n",
    "    - ÌñâÎèô: 6Î∞©Ìñ• Ïù¥Îèô (¬±z, ¬±y, ¬±x)\n",
    "    - Î≥¥ÏÉÅ:\n",
    "        * ÏÉàÎ°ú Ïù¥ÎèôÌïú voxel Ïù¥ ÌòàÍ¥Ä(mask>0)Ïù¥Î©¥ +1\n",
    "        * ÌòàÍ¥ÄÏù¥ ÏïÑÎãàÎ©¥ -1, Í∑∏Î¶¨Í≥† ÏóêÌîºÏÜåÎìú Ï¢ÖÎ£å(done=True)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_root: Path,\n",
    "                 patch_size=PATCH_SIZE,\n",
    "                 max_steps: int = 32):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.patch_size = patch_size\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "        # case Ìè¥Îçî Î™®ÏúºÍ∏∞\n",
    "        self.case_dirs = sorted(\n",
    "            [p for p in self.data_root.iterdir() if p.is_dir()]\n",
    "        )\n",
    "        if len(self.case_dirs) == 0:\n",
    "            raise RuntimeError(f\"No case folders found under {self.data_root}\")\n",
    "\n",
    "        print(f\"Found {len(self.case_dirs)} cases under {self.data_root}\")\n",
    "\n",
    "        # ÎÇ¥Î∂Ä ÏÉÅÌÉú\n",
    "        self.ct = None\n",
    "        self.mask = None\n",
    "        self.ct_norm = None\n",
    "        self.D = self.H = self.W = None\n",
    "\n",
    "        self.pos = None   # (z,y,x)\n",
    "        self.step_count = 0\n",
    "        self.current_case_dir = None\n",
    "\n",
    "    def _load_random_case(self):\n",
    "        \"\"\"\n",
    "        ÏºÄÏù¥Ïä§ ÌïòÎÇò ÎûúÎç§ ÏÑ†ÌÉù ÌõÑ CT, mask Î°úÎî© + Ï†ïÍ∑úÌôî\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            case_dir = random.choice(self.case_dirs)\n",
    "            try:\n",
    "                ct, mask = load_case(case_dir)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] skip case {case_dir.name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # vessel Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏\n",
    "            if (mask > 0).sum() == 0:\n",
    "                print(f\"[WARN] case {case_dir.name} has no vessel voxels, skip\")\n",
    "                continue\n",
    "\n",
    "            self.ct = ct\n",
    "            self.mask = (mask > 0.5).astype(np.uint8)  # binary\n",
    "            self.ct_norm = normalize_ct(ct)\n",
    "\n",
    "            self.D, self.H, self.W = self.ct.shape\n",
    "            self.current_case_dir = case_dir\n",
    "            break\n",
    "\n",
    "    def _sample_start_pos(self):\n",
    "        \"\"\"\n",
    "        ÌòàÍ¥Ä(mask>0) ÏïàÏùò voxel Ï§ë ÌïòÎÇò ÎûúÎç§ ÏÑ†ÌÉù\n",
    "        \"\"\"\n",
    "        vessel_indices = np.argwhere(self.mask > 0)  # (N,3)\n",
    "        idx = vessel_indices[np.random.randint(len(vessel_indices))]\n",
    "        return tuple(idx)  # (z,y,x)\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"\n",
    "        ÌòÑÏû¨ ÏúÑÏπò self.pos Í∏∞Ï§Ä Ìå®Ïπò -> (1, D, H, W)\n",
    "        \"\"\"\n",
    "        patch = get_patch(self.ct_norm, self.pos, self.patch_size)\n",
    "        state = patch[np.newaxis, ...].astype(np.float32)\n",
    "        return state\n",
    "\n",
    "    def _move(self, z, y, x, action: int):\n",
    "        \"\"\"\n",
    "        action: 0~5\n",
    "          0: +z\n",
    "          1: -z\n",
    "          2: +y\n",
    "          3: -y\n",
    "          4: +x\n",
    "          5: -x\n",
    "        \"\"\"\n",
    "        if action == 0:\n",
    "            z += 1\n",
    "        elif action == 1:\n",
    "            z -= 1\n",
    "        elif action == 2:\n",
    "            y += 1\n",
    "        elif action == 3:\n",
    "            y -= 1\n",
    "        elif action == 4:\n",
    "            x += 1\n",
    "        elif action == 5:\n",
    "            x -= 1\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid action: {action}\")\n",
    "        return z, y, x\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "        self._load_random_case()\n",
    "        self.pos = self._sample_start_pos()\n",
    "        self.step_count = 0\n",
    "\n",
    "        state = self._get_state()\n",
    "        info = {\n",
    "            \"pos\": self.pos,\n",
    "            \"case\": self.current_case_dir.name,\n",
    "        }\n",
    "        return state, info\n",
    "\n",
    "    def step(self, action: int):\n",
    "        \"\"\"\n",
    "        ÌïµÏã¨ Reward ÏÑ§Í≥Ñ:\n",
    "        - ÏÉà ÏúÑÏπòÍ∞Ä Î≥ºÎ•® Î∞ñÏù¥Î©¥: reward=-1, done=True\n",
    "        - Î≥ºÎ•® ÏïàÏù¥ÏßÄÎßå ÌòàÍ¥ÄÏù¥ ÏïÑÎãàÎ©¥: reward=-1, done=True\n",
    "        - ÌòàÍ¥ÄÏù¥Î©¥: reward=+1, done=False (Îã®, max_steps ÎèÑÎã¨ Ïãú done=True)\n",
    "        \"\"\"\n",
    "        z, y, x = self.pos\n",
    "        nz, ny, nx = self._move(z, y, x, action)\n",
    "\n",
    "        # Î≥ºÎ•® Î∞îÍπ• Ï≤¥ÌÅ¨\n",
    "        if not (0 <= nz < self.D and 0 <= ny < self.H and 0 <= nx < self.W):\n",
    "            reward = -1.0\n",
    "            done = True\n",
    "            obs = self._get_state()  # Ïñ¥Ï∞®Ìîº done Ïù¥Îùº ÌÅ¨Í≤å ÏùòÎØ∏ ÏóÜÏùå\n",
    "            info = {\n",
    "                \"pos\": (nz, ny, nx),\n",
    "                \"inside\": False,\n",
    "                \"case\": self.current_case_dir.name,\n",
    "            }\n",
    "            return obs, reward, done, False, info\n",
    "\n",
    "        # ÌòàÍ¥Ä ÎÇ¥Î∂Ä Ïó¨Î∂Ä\n",
    "        inside = bool(self.mask[nz, ny, nx] > 0)\n",
    "\n",
    "        if inside:\n",
    "            reward = +1.0\n",
    "            done = False\n",
    "        else:\n",
    "            reward = -1.0\n",
    "            done = True   # ÌòàÍ¥Ä Î≤óÏñ¥ÎÇòÎ©¥ Î∞îÎ°ú Ï¢ÖÎ£å\n",
    "\n",
    "        # ÏÉÅÌÉú ÏóÖÎç∞Ïù¥Ìä∏\n",
    "        self.pos = (nz, ny, nx)\n",
    "        self.step_count += 1\n",
    "\n",
    "        if self.step_count >= self.max_steps:\n",
    "            done = True\n",
    "\n",
    "        obs = self._get_state()\n",
    "        info = {\n",
    "            \"pos\": self.pos,\n",
    "            \"inside\": inside,\n",
    "            \"case\": self.current_case_dir.name,\n",
    "        }\n",
    "        return obs, reward, done, False, info\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 3. 3D CNN Q-network\n",
    "# ======================\n",
    "\n",
    "class CnnQNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ÏûÖÎ†•:  (B, 1, 32, 32, 32)\n",
    "    Ï∂úÎ†•:  (B, n_actions)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, n_actions=6):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, 8, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm3d(8)\n",
    "        self.conv2 = nn.Conv3d(8, 16, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm3d(16)\n",
    "        self.conv3 = nn.Conv3d(16, 32, 3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm3d(32)\n",
    "\n",
    "        self.pool  = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 32x32x32  ‚Üí  16x16x16 ‚Üí  8x8x8 ‚Üí 4x4x4, Ï±ÑÎÑê 32\n",
    "        self.fc1   = nn.Linear(32 * 4 * 4 * 4, 128)\n",
    "        self.fc2   = nn.Linear(128, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,1,32,32,32)\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))   # (B,8,16,16,16)\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))   # (B,16,8,8,8)\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))   # (B,32,4,4,4)\n",
    "        x = torch.flatten(x, 1)                          # (B, 32*4*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)                                  # (B, n_actions)\n",
    "        return x\n",
    "\n",
    "    def sample_action(self, obs_np: np.ndarray, epsilon: float):\n",
    "        \"\"\"\n",
    "        obs_np: numpy (1, 32, 32, 32)\n",
    "        \"\"\"\n",
    "        if random.random() < epsilon:\n",
    "            return random.randint(0, self.fc2.out_features - 1)\n",
    "        # greedy\n",
    "        obs_t = torch.from_numpy(obs_np).float().unsqueeze(0).to(DEVICE)  # (1,1,32,32,32)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.forward(obs_t)\n",
    "            action = q_values.argmax(dim=1).item()\n",
    "        return action\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 4. Replay Buffer & DQN ÌïôÏäµ\n",
    "# ======================\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, buffer_limit=20000):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "\n",
    "    def put(self, transition):\n",
    "        # transition: (s, a, r, s_prime, done_mask)\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        mini_batch = random.sample(self.buffer, batch_size)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        for (s, a, r, s_prime, done_mask) in mini_batch:\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "\n",
    "        s       = torch.tensor(s_lst, dtype=torch.float32, device=DEVICE)      # (B,1,32,32,32)\n",
    "        a       = torch.tensor(a_lst, device=DEVICE)                           # (B,1)\n",
    "        r       = torch.tensor(r_lst, dtype=torch.float32, device=DEVICE)      # (B,1)\n",
    "        s_prime = torch.tensor(s_prime_lst, dtype=torch.float32, device=DEVICE)# (B,1,32,32,32)\n",
    "        done_m  = torch.tensor(done_mask_lst, dtype=torch.float32, device=DEVICE) # (B,1)\n",
    "\n",
    "        return s, a, r, s_prime, done_m\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "\n",
    "def train_dqn(q_net, target_net, memory, optimizer,\n",
    "              batch_size=8, gamma=0.99, iters=1):\n",
    "    if memory.size() < batch_size:\n",
    "        return\n",
    "\n",
    "    for _ in range(iters):\n",
    "        s, a, r, s_prime, done_m = memory.sample(batch_size)\n",
    "\n",
    "        q_out = q_net(s)                 # (B, n_actions)\n",
    "        q_a   = q_out.gather(1, a)       # (B,1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            max_q_prime = target_net(s_prime).max(1, keepdim=True)[0]  # (B,1)\n",
    "            target = r + gamma * max_q_prime * done_m\n",
    "\n",
    "        loss = F.mse_loss(q_a, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 5. ÌïôÏäµ Î£®ÌîÑ\n",
    "# ======================\n",
    "\n",
    "def train_vessel_dqn(n_episodes=200,\n",
    "                     max_steps=32,\n",
    "                     buffer_limit=20000,\n",
    "                     batch_size=8):\n",
    "    env = CTVesselEnv(DATA_ROOT, patch_size=PATCH_SIZE, max_steps=max_steps)\n",
    "\n",
    "    q_net      = CnnQNet(in_channels=1, n_actions=6).to(DEVICE)\n",
    "    target_net = CnnQNet(in_channels=1, n_actions=6).to(DEVICE)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    memory = ReplayBuffer(buffer_limit=buffer_limit)\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=1e-4)\n",
    "\n",
    "    print_interval = 10\n",
    "    global_step = 0\n",
    "\n",
    "    for ep in range(1, n_episodes + 1):\n",
    "        state, info = env.reset()\n",
    "        ep_reward = 0.0\n",
    "        ep_steps = 0\n",
    "\n",
    "        # epsilon ÏÑ†Ìòï Í∞êÏÜå\n",
    "        epsilon = max(0.01, 0.1 - 0.01 * (ep / 50.0))\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            action = q_net.sample_action(state, epsilon)\n",
    "            next_state, reward, done, truncated, info2 = env.step(action)\n",
    "\n",
    "            done_mask = 0.0 if (not done) else 1.0\n",
    "\n",
    "            memory.put((state, action, reward, next_state, done_mask))\n",
    "\n",
    "            state = next_state\n",
    "            ep_reward += reward\n",
    "            ep_steps += 1\n",
    "            global_step += 1\n",
    "\n",
    "            # ÌïôÏäµ\n",
    "            if memory.size() > 200:\n",
    "                train_dqn(q_net, target_net, memory, optimizer,\n",
    "                          batch_size=batch_size, gamma=0.99, iters=1)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # ÌÉÄÍ≤ü ÎÑ§Ìä∏ÏõåÌÅ¨ Ï£ºÍ∏∞Ï†ÅÏúºÎ°ú ÎèôÍ∏∞Ìôî\n",
    "        if ep % 20 == 0:\n",
    "            target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "        if ep % print_interval == 0:\n",
    "            print(f\"[Episode {ep:03d}] \"\n",
    "                  f\"reward={ep_reward:.1f}, \"\n",
    "                  f\"steps={ep_steps}, \"\n",
    "                  f\"eps={epsilon:.3f}, \"\n",
    "                  f\"buffer={memory.size()}, \"\n",
    "                  f\"case={info2.get('case', 'NA')}, \"\n",
    "                  f\"inside={info2.get('inside', False)}\")\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "    return q_net, target_net, env\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 6. Ïã§Ìñâ\n",
    "# ======================\n",
    "\n",
    "q_net, target_net, env = train_vessel_dqn(\n",
    "    n_episodes=50,   # Ï≤òÏùåÏóî 50 Ï†ïÎèÑÎßå ÎèåÎ†§Î≥¥Í≥†\n",
    "    max_steps=32,\n",
    "    buffer_limit=5000,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d4fc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTVesselEnv:\n",
    "    def __init__(self, data_root: Path, patch_size=PATCH_SIZE, max_steps=32):\n",
    "        # ... (Í∏∞Ï°¥ Ï¥àÍ∏∞Ìôî ÏΩîÎìú ÎèôÏùº) ...\n",
    "        self.visited = set()  # Î∞©Î¨∏ Ï¢åÌëú Í∏∞Î°ùÏö© ÏßëÌï© Ï∂îÍ∞Ä\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        # ... (Í∏∞Ï°¥ Î°úÏßÅ ÎèôÏùº) ...\n",
    "        self._load_random_case()\n",
    "        self.pos = self._sample_start_pos()\n",
    "        self.step_count = 0\n",
    "        \n",
    "        # Î∞©Î¨∏ Í∏∞Î°ù Ï¥àÍ∏∞Ìôî Î∞è ÏãúÏûëÏ†ê Ï∂îÍ∞Ä\n",
    "        self.visited = set()\n",
    "        self.visited.add(self.pos) \n",
    "\n",
    "        state = self._get_state()\n",
    "        info = {\"pos\": self.pos, \"case\": self.current_case_dir.name}\n",
    "        return state, info\n",
    "\n",
    "    def step(self, action: int):\n",
    "        z, y, x = self.pos\n",
    "        nz, ny, nx = self._move(z, y, x, action)\n",
    "\n",
    "        # 1. Î≥ºÎ•® Î∞ñÏúºÎ°ú ÎÇòÍ∞ê\n",
    "        if not (0 <= nz < self.D and 0 <= ny < self.H and 0 <= nx < self.W):\n",
    "            return self._get_state(), -1.0, True, False, {\"inside\": False}\n",
    "\n",
    "        # 2. ÌòàÍ¥Ä Ïó¨Î∂Ä ÌôïÏù∏\n",
    "        inside = bool(self.mask[nz, ny, nx] > 0)\n",
    "        \n",
    "        if not inside:\n",
    "            # ÌòàÍ¥Ä Î∞ñÏúºÎ°ú ÎÇòÍ∞ê -> ÌéòÎÑêÌã∞ Î∞õÍ≥† Ï¢ÖÎ£å\n",
    "            reward = -1.0\n",
    "            done = True\n",
    "        else:\n",
    "            # ÌòàÍ¥Ä ÏïàÏ™ΩÏûÑ\n",
    "            if (nz, ny, nx) in self.visited:\n",
    "                # Ïù¥ÎØ∏ Î∞©Î¨∏ÌñàÎçò Í≥≥ -> ÌéòÎÑêÌã∞Î•º Ï°∞Í∏à Ï£ºÍ±∞ÎÇò 0Ï†ê Ï≤òÎ¶¨ (ÏßÑÎèô Î∞©ÏßÄ)\n",
    "                reward = -0.1 \n",
    "                done = False # Ï£ΩÏù¥ÏßÑ ÏïäÏùå\n",
    "            else:\n",
    "                # ÏÉàÎ°úÏö¥ ÌòàÍ¥Ä Î∞úÍ≤¨! -> Î≥¥ÏÉÅ\n",
    "                reward = +1.0\n",
    "                done = False\n",
    "                self.visited.add((nz, ny, nx))\n",
    "\n",
    "        # ÏúÑÏπò ÏóÖÎç∞Ïù¥Ìä∏ (ÌòàÍ¥Ä Î∞ñÏù¥ÎùºÎèÑ Ïù¥ÎèôÏùÄ Ìï®, Ïñ¥Ï∞®Ìîº done ÎêòÏßÄÎßå ÏãúÍ∞ÅÌôî Îì±ÏùÑ ÏúÑÌï¥)\n",
    "        self.pos = (nz, ny, nx)\n",
    "        self.step_count += 1\n",
    "\n",
    "        if self.step_count >= self.max_steps:\n",
    "            done = True\n",
    "\n",
    "        return self._get_state(), reward, done, False, {\"inside\": inside}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb999472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Found 100 cases.\n",
      "[Ep 010] Score:   -1.0 | Steps:   1 | Eps: 0.93 | Case: None | Inside: False\n",
      "[Ep 020] Score:   54.2 | Steps:  76 | Eps: 0.87 | Case: None | Inside: False\n",
      "[Ep 030] Score:   91.5 | Steps: 121 | Eps: 0.80 | Case: None | Inside: False\n",
      "[Ep 040] Score:   14.8 | Steps:  19 | Eps: 0.73 | Case: None | Inside: False\n",
      "[Ep 050] Score:    3.0 | Steps:   5 | Eps: 0.67 | Case: None | Inside: False\n",
      "[Ep 060] Score:   25.6 | Steps:  32 | Eps: 0.60 | Case: None | Inside: False\n",
      "[Ep 070] Score:   91.3 | Steps: 101 | Eps: 0.53 | Case: None | Inside: False\n",
      "[Ep 080] Score:   -1.0 | Steps:   1 | Eps: 0.47 | Case: None | Inside: False\n",
      "[Ep 090] Score:  110.0 | Steps: 123 | Eps: 0.40 | Case: None | Inside: False\n",
      "[Ep 100] Score:   26.4 | Steps:  35 | Eps: 0.33 | Case: None | Inside: False\n",
      "[Ep 110] Score:  119.2 | Steps: 128 | Eps: 0.27 | Case: None | Inside: True\n",
      "[Ep 120] Score:  125.8 | Steps: 128 | Eps: 0.20 | Case: None | Inside: True\n",
      "[Ep 130] Score:  118.1 | Steps: 128 | Eps: 0.13 | Case: None | Inside: True\n",
      "[Ep 140] Score:   71.8 | Steps:  76 | Eps: 0.07 | Case: None | Inside: False\n",
      "[Ep 150] Score:  126.9 | Steps: 128 | Eps: 0.01 | Case: None | Inside: True\n",
      "[Ep 160] Score:  128.0 | Steps: 128 | Eps: 0.01 | Case: None | Inside: True\n",
      "[Ep 170] Score:  122.5 | Steps: 128 | Eps: 0.01 | Case: None | Inside: True\n",
      "[Ep 180] Score:   -1.0 | Steps:   1 | Eps: 0.01 | Case: None | Inside: False\n",
      "[Ep 190] Score:  126.9 | Steps: 128 | Eps: 0.01 | Case: None | Inside: True\n",
      "[Ep 200] Score:  126.9 | Steps: 128 | Eps: 0.01 | Case: None | Inside: True\n",
      "[Ep 210] Score:  128.0 | Steps: 128 | Eps: 0.01 | Case: None | Inside: True\n",
      "[Ep 220] Score:   -1.0 | Steps:   1 | Eps: 0.01 | Case: None | Inside: False\n",
      "[Ep 230] Score:  125.8 | Steps: 128 | Eps: 0.01 | Case: None | Inside: True\n",
      "[Ep 240] Score:  128.0 | Steps: 128 | Eps: 0.01 | Case: None | Inside: True\n",
      "[Ep 250] Score:  120.3 | Steps: 128 | Eps: 0.01 | Case: None | Inside: True\n",
      "[Ep 260] Score:    0.0 | Steps:   2 | Eps: 0.01 | Case: None | Inside: False\n",
      "[Ep 270] Score:    0.0 | Steps:   2 | Eps: 0.01 | Case: None | Inside: False\n",
      "[Ep 280] Score:  128.0 | Steps: 128 | Eps: 0.01 | Case: None | Inside: True\n",
      "[Ep 290] Score:    2.0 | Steps:   4 | Eps: 0.01 | Case: None | Inside: False\n",
      "[Ep 300] Score:   32.0 | Steps:  34 | Eps: 0.01 | Case: None | Inside: False\n",
      "Training Finished!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import collections\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# ======================\n",
    "# 0. ÌôòÍ≤Ω Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
    "# ======================\n",
    "\n",
    "# [ÏàòÏ†ï ÌïÑÏöî] Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú\n",
    "DATA_ROOT = Path(\"/Users/srpark/Projects/RL_project/data/RL_prepared\")\n",
    "\n",
    "CT_NAME   = \"ct.nii.gz\"\n",
    "MASK_NAME = \"Whole_artery.nii.gz\"\n",
    "\n",
    "PATCH_SIZE = (32, 32, 32)  # (D, H, W)\n",
    "\n",
    "# ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 1. Îç∞Ïù¥ÌÑ∞ Î°úÎî© & Ï†ÑÏ≤òÎ¶¨ Ìï®Ïàò\n",
    "# ======================\n",
    "\n",
    "def load_case(case_dir: Path, ct_name: str = CT_NAME, mask_name: str = MASK_NAME):\n",
    "    ct_path   = case_dir / ct_name\n",
    "    mask_path = case_dir / mask_name\n",
    "\n",
    "    if not ct_path.exists(): raise FileNotFoundError(f\"CT not found: {ct_path}\")\n",
    "    if not mask_path.exists(): raise FileNotFoundError(f\"Mask not found: {mask_path}\")\n",
    "\n",
    "    ct_nii   = nib.load(str(ct_path))\n",
    "    mask_nii = nib.load(str(mask_path))\n",
    "\n",
    "    ct   = ct_nii.get_fdata().astype(np.float32)\n",
    "    mask = mask_nii.get_fdata().astype(np.float32)\n",
    "\n",
    "    return ct, mask\n",
    "\n",
    "def normalize_ct(ct: np.ndarray, hu_min=-200.0, hu_max=300.0):\n",
    "    ct = np.clip(ct, hu_min, hu_max)\n",
    "    ct = (ct - hu_min) / (hu_max - hu_min + 1e-8)\n",
    "    return ct.astype(np.float32)\n",
    "\n",
    "def get_patch(volume: np.ndarray, center: tuple, patch_size=PATCH_SIZE):\n",
    "    D, H, W = volume.shape\n",
    "    pd, ph, pw = patch_size\n",
    "    zc, yc, xc = center\n",
    "\n",
    "    z0, y0, x0 = zc - pd // 2, yc - ph // 2, xc - pw // 2\n",
    "    z1, y1, x1 = z0 + pd, y0 + ph, x0 + pw\n",
    "\n",
    "    patch = np.zeros((pd, ph, pw), dtype=volume.dtype)\n",
    "\n",
    "    z0_src, y0_src, x0_src = max(z0, 0), max(y0, 0), max(x0, 0)\n",
    "    z1_src, y1_src, x1_src = min(z1, D), min(y1, H), min(x1, W)\n",
    "\n",
    "    z0_dst, y0_dst, x0_dst = z0_src - z0, y0_src - y0, x0_src - x0\n",
    "\n",
    "    # Î≤îÏúÑÍ∞Ä Ïú†Ìö®Ìï† ÎïåÎßå Î≥µÏÇ¨\n",
    "    if z1_src > z0_src and y1_src > y0_src and x1_src > x0_src:\n",
    "        patch[\n",
    "            z0_dst:z0_dst + (z1_src - z0_src),\n",
    "            y0_dst:y0_dst + (y1_src - y0_src),\n",
    "            x0_dst:x0_dst + (x1_src - x0_src)\n",
    "        ] = volume[z0_src:z1_src, y0_src:y1_src, x0_src:x1_src]\n",
    "\n",
    "    return patch\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 2. CT Vessel Env Ï†ïÏùò (Í∞úÏÑ†Îê®)\n",
    "# ======================\n",
    "\n",
    "class CTVesselEnv:\n",
    "    \"\"\"\n",
    "    [Í∞úÏÑ† ÏÇ¨Ìï≠]\n",
    "    1. Observation: 2Ï±ÑÎÑê (CT Ïù¥ÎØ∏ÏßÄ + Î∞©Î¨∏Ìïú Í≤ΩÎ°ú Mask)\n",
    "    2. Reward: \n",
    "       - ÏÉàÎ°úÏö¥ ÌòàÍ¥Ä Î∞úÍ≤¨: +1.0\n",
    "       - Ïù¥ÎØ∏ Í∞îÎçò ÌòàÍ¥Ä: -0.1 (Ï†úÏûêÎ¶¨ ÏßÑÎèô Î∞©ÏßÄ)\n",
    "       - ÌòàÍ¥Ä Î∞ñ/Ïù¥ÌÉà: -1.0\n",
    "    \"\"\"\n",
    "    def __init__(self, data_root: Path, patch_size=PATCH_SIZE, max_steps=100):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.patch_size = patch_size\n",
    "        self.max_steps = max_steps  # Ïä§ÌÖù Ïàò Ï¢Ä ÎäòÎ†§Ï§å\n",
    "\n",
    "        self.case_dirs = sorted([p for p in self.data_root.iterdir() if p.is_dir()])\n",
    "        if not self.case_dirs:\n",
    "            raise RuntimeError(f\"No case folders found under {self.data_root}\")\n",
    "        print(f\"Found {len(self.case_dirs)} cases.\")\n",
    "\n",
    "        # ÎÇ¥Î∂Ä Î≥ÄÏàò\n",
    "        self.ct = None\n",
    "        self.mask = None\n",
    "        self.ct_norm = None\n",
    "        self.visited_vol = None  # Í¥ÄÏ∏°(Observation) ÏÉùÏÑ±Ïö© 3D Î≥ºÎ•®\n",
    "        self.visited_set = None  # Î≥¥ÏÉÅ Í≥ÑÏÇ∞Ïö© Îπ†Î•∏ Ï°∞Ìöå Set\n",
    "        \n",
    "        self.D = self.H = self.W = None\n",
    "        self.pos = None\n",
    "        self.step_count = 0\n",
    "        self.current_case_dir = None\n",
    "\n",
    "    def _load_random_case(self):\n",
    "        while True:\n",
    "            case_dir = random.choice(self.case_dirs)\n",
    "            try:\n",
    "                ct, mask = load_case(case_dir)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if (mask > 0).sum() == 0: continue\n",
    "\n",
    "            self.ct = ct\n",
    "            self.mask = (mask > 0.5).astype(np.uint8)\n",
    "            self.ct_norm = normalize_ct(ct)\n",
    "            \n",
    "            # [Ï§ëÏöî] Î∞©Î¨∏ Í∏∞Î°ùÏö© Î≥ºÎ•® Ï¥àÍ∏∞Ìôî (0ÏúºÎ°ú Ï±ÑÏõÄ)\n",
    "            self.visited_vol = np.zeros_like(self.mask, dtype=np.float32)\n",
    "            \n",
    "            self.D, self.H, self.W = self.ct.shape\n",
    "            self.current_case_dir = case_dir\n",
    "            break\n",
    "\n",
    "    def _sample_start_pos(self):\n",
    "        vessel_indices = np.argwhere(self.mask > 0)\n",
    "        idx = vessel_indices[np.random.randint(len(vessel_indices))]\n",
    "        return tuple(idx)\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"\n",
    "        [ÏàòÏ†ï] 2Ï±ÑÎÑê ÏûÖÎ†• ÏÉùÏÑ±: (2, D, H, W)\n",
    "        Channel 0: CT Patch\n",
    "        Channel 1: Visited Mask Patch\n",
    "        \"\"\"\n",
    "        # 1. CT Ìå®Ïπò\n",
    "        ct_patch = get_patch(self.ct_norm, self.pos, self.patch_size)\n",
    "        # 2. Î∞©Î¨∏ Í∏∞Î°ù Ìå®Ïπò\n",
    "        vis_patch = get_patch(self.visited_vol, self.pos, self.patch_size)\n",
    "        \n",
    "        # Îëê Ìå®ÏπòÎ•º Ìï©Ïπ® -> (2, 32, 32, 32)\n",
    "        state = np.stack([ct_patch, vis_patch], axis=0).astype(np.float32)\n",
    "        return state\n",
    "\n",
    "    def _move(self, z, y, x, action):\n",
    "        # 0:+z, 1:-z, 2:+y, 3:-y, 4:+x, 5:-x\n",
    "        deltas = [(1,0,0), (-1,0,0), (0,1,0), (0,-1,0), (0,0,1), (0,0,-1)]\n",
    "        dz, dy, dx = deltas[action]\n",
    "        return z+dz, y+dy, x+dx\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "        self._load_random_case()\n",
    "        self.pos = self._sample_start_pos()\n",
    "        self.step_count = 0\n",
    "        \n",
    "        # [Ï§ëÏöî] Î∞©Î¨∏ Í∏∞Î°ù Ï¥àÍ∏∞Ìôî\n",
    "        self.visited_set = set()\n",
    "        self.visited_set.add(self.pos)\n",
    "        self.visited_vol[self.pos] = 1.0  # Î≥ºÎ•®ÏóêÎèÑ ÌëúÏãú\n",
    "\n",
    "        state = self._get_state()\n",
    "        info = {\"pos\": self.pos, \"case\": self.current_case_dir.name}\n",
    "        return state, info\n",
    "\n",
    "    def step(self, action: int):\n",
    "        z, y, x = self.pos\n",
    "        nz, ny, nx = self._move(z, y, x, action)\n",
    "        \n",
    "        # 1. Î≥ºÎ•® Î∞ñ Ïù¥ÌÉà Ï≤¥ÌÅ¨\n",
    "        if not (0 <= nz < self.D and 0 <= ny < self.H and 0 <= nx < self.W):\n",
    "            reward = -1.0\n",
    "            done = True\n",
    "            return self._get_state(), reward, done, False, {\"inside\": False}\n",
    "\n",
    "        # 2. ÌòàÍ¥Ä ÎÇ¥Î∂Ä Ïó¨Î∂Ä Ï≤¥ÌÅ¨\n",
    "        inside = bool(self.mask[nz, ny, nx] > 0)\n",
    "\n",
    "        if not inside:\n",
    "            # ÌòàÍ¥Ä Î∞ñ -> ÌéòÎÑêÌã∞ Î∞õÍ≥† Ï¢ÖÎ£å\n",
    "            reward = -1.0\n",
    "            done = True\n",
    "        else:\n",
    "            # ÌòàÍ¥Ä ÏïàÏ™Ω\n",
    "            if (nz, ny, nx) in self.visited_set:\n",
    "                # [Ï§ëÏöî] Ïù¥ÎØ∏ Í∞îÎçò Í≥≥ -> ÏïΩÌïú ÌéòÎÑêÌã∞ (Ï†úÏûêÎ¶¨ Í±∏Ïùå Î∞©ÏßÄ)\n",
    "                reward = -0.1\n",
    "                done = False\n",
    "            else:\n",
    "                # [Ï§ëÏöî] ÏÉàÎ°úÏö¥ ÌòàÍ¥Ä -> Î≥¥ÏÉÅ (+1)\n",
    "                reward = 1.0\n",
    "                done = False\n",
    "                # Î∞©Î¨∏ Í∏∞Î°ù ÏóÖÎç∞Ïù¥Ìä∏\n",
    "                self.visited_set.add((nz, ny, nx))\n",
    "                self.visited_vol[nz, ny, nx] = 1.0\n",
    "\n",
    "        self.pos = (nz, ny, nx)\n",
    "        self.step_count += 1\n",
    "        \n",
    "        if self.step_count >= self.max_steps:\n",
    "            done = True\n",
    "\n",
    "        return self._get_state(), reward, done, False, {\"inside\": inside}\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 3. 3D CNN Q-network (2Ï±ÑÎÑê ÏûÖÎ†• ÎåÄÏùë)\n",
    "# ======================\n",
    "\n",
    "class CnnQNet(nn.Module):\n",
    "    def __init__(self, in_channels=2, n_actions=6): # [ÏàòÏ†ï] Í∏∞Î≥∏ Ï±ÑÎÑê 2\n",
    "        super().__init__()\n",
    "        # BatchNorm Ï†úÍ±∞ (ÏïàÏ†ïÏ†ÅÏù∏ ÌïôÏäµÏùÑ ÏúÑÌï¥)\n",
    "        self.conv1 = nn.Conv3d(in_channels, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, 3, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        # (B, 64, 4, 4, 4) -> 64*4*4*4 = 4096\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 2, 32, 32, 32)\n",
    "        x = self.pool(F.relu(self.conv1(x))) # -> (16, 16, 16, 16)\n",
    "        x = self.pool(F.relu(self.conv2(x))) # -> (32, 8, 8, 8)\n",
    "        x = self.pool(F.relu(self.conv3(x))) # -> (64, 4, 4, 4)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def sample_action(self, obs_np, epsilon):\n",
    "        if random.random() < epsilon:\n",
    "            return random.randint(0, self.fc2.out_features - 1)\n",
    "        \n",
    "        # obs_np: (2, 32, 32, 32)\n",
    "        obs_t = torch.from_numpy(obs_np).float().unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            q_out = self.forward(obs_t)\n",
    "            action = q_out.argmax(dim=1).item()\n",
    "        return action\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 4. Replay Buffer & Train Function\n",
    "# ======================\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, buffer_limit=50000):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "\n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        mini_batch = random.sample(self.buffer, batch_size)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "\n",
    "        for (s, a, r, s_prime, done_mask) in mini_batch:\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "\n",
    "        return (torch.tensor(np.array(s_lst), dtype=torch.float32, device=DEVICE),\n",
    "                torch.tensor(a_lst, dtype=torch.int64, device=DEVICE),\n",
    "                torch.tensor(r_lst, dtype=torch.float32, device=DEVICE),\n",
    "                torch.tensor(np.array(s_prime_lst), dtype=torch.float32, device=DEVICE),\n",
    "                torch.tensor(done_mask_lst, dtype=torch.float32, device=DEVICE))\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "def train_dqn(q_net, target_net, memory, optimizer, batch_size=32, gamma=0.99):\n",
    "    if memory.size() < batch_size: return\n",
    "\n",
    "    s, a, r, s_prime, done_mask = memory.sample(batch_size)\n",
    "\n",
    "    q_out = q_net(s)\n",
    "    q_a = q_out.gather(1, a)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        max_q_prime = target_net(s_prime).max(1, keepdim=True)[0]\n",
    "        # [ÏàòÏ†ï] DoneÏùº Îïå(0.0)Îäî ÎØ∏ÎûòÍ∞ÄÏπò ÏóÜÏùå\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "\n",
    "    # Huber Loss (SmoothL1) Ï∂îÏ≤ú\n",
    "    loss = F.smooth_l1_loss(q_a, target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 5. Main Training Loop\n",
    "# ======================\n",
    "\n",
    "def train_vessel_dqn(n_episodes=500, max_steps=128, buffer_limit=50000, batch_size=32):\n",
    "    # [ÏÑ§Ï†ï] max_stepsÎ•º 32ÏóêÏÑú 128Î°ú ÎäòÎ¶º (ÌòàÍ¥ÄÏùÑ Îçî Í∏∏Í≤å Îî∞ÎùºÍ∞ÄÎèÑÎ°ù)\n",
    "    env = CTVesselEnv(DATA_ROOT, patch_size=PATCH_SIZE, max_steps=max_steps)\n",
    "\n",
    "    # [ÏÑ§Ï†ï] ÏûÖÎ†• Ï±ÑÎÑê 2 (CT, Visited)\n",
    "    q_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "    target_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    memory = ReplayBuffer(buffer_limit)\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=1e-4)\n",
    "\n",
    "    print_interval = 10\n",
    "    \n",
    "    for ep in range(1, n_episodes + 1):\n",
    "        state, info = env.reset()\n",
    "        ep_reward = 0.0\n",
    "        ep_steps = 0\n",
    "        \n",
    "        # [ÏàòÏ†ï] Epsilon Decay: 1.0(ÏôÑÏ†ÑÎûúÎç§) -> 0.01(Í±∞Ïùò ÏµúÏ†Å) \n",
    "        # Ï≤òÏùå 50% ÏóêÌîºÏÜåÎìú ÎèôÏïà ÏÑ†Ìòï Í∞êÏÜå\n",
    "        epsilon = max(0.01, 1.0 - (ep / (n_episodes * 0.5)))\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            action = q_net.sample_action(state, epsilon)\n",
    "            next_state, reward, done, _, info2 = env.step(action)\n",
    "\n",
    "            # [ÏàòÏ†ï] Done Mask: Ï¢ÖÎ£åÎêòÎ©¥ 0, ÏïÑÎãàÎ©¥ 1\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "\n",
    "            memory.put((state, action, reward, next_state, done_mask))\n",
    "\n",
    "            state = next_state\n",
    "            ep_reward += reward\n",
    "            ep_steps += 1\n",
    "\n",
    "            # ÌïôÏäµ ÏàòÌñâ\n",
    "            train_dqn(q_net, target_net, memory, optimizer, batch_size)\n",
    "\n",
    "            if done: break\n",
    "        \n",
    "        # ÌÉÄÍ≤ü ÎÑ§Ìä∏ÏõåÌÅ¨ ÎèôÍ∏∞Ìôî\n",
    "        if ep % 20 == 0:\n",
    "            target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "        if ep % print_interval == 0:\n",
    "            print(f\"[Ep {ep:03d}] Score: {ep_reward:6.1f} | Steps: {ep_steps:3d} | \"\n",
    "                  f\"Eps: {epsilon:.2f} | Case: {info2.get('case')} | Inside: {info2.get('inside')}\")\n",
    "\n",
    "    print(\"Training Finished!\")\n",
    "    return q_net, target_net, env\n",
    "\n",
    "# ======================\n",
    "# 6. Ïã§Ìñâ\n",
    "# ======================\n",
    "if __name__ == \"__main__\":\n",
    "    q_net, target_net, env = train_vessel_dqn(\n",
    "        n_episodes=300,   # 300Ìåê Ï†ïÎèÑ Ï∂îÏ≤ú\n",
    "        max_steps=128,    # Ïä§ÌÖù Ïàò Ï∂©Î∂ÑÌûà\n",
    "        buffer_limit=50000,\n",
    "        batch_size=32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6c6e53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: vessel_dqn_final.pth\n",
      "Ïù¥Ï†ú Ïª§ÎÑêÏù¥ Í∫ºÏ†∏ÎèÑ Ïù¥ ÌååÏùºÎßå ÏûàÏúºÎ©¥ Ïñ∏Ï†úÎì† Îã§Ïãú Î∂àÎü¨Ïò¨ Ïàò ÏûàÏäµÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "# 1. Î™®Îç∏ Í∞ÄÏ§ëÏπò(Weight) Ï†ÄÏû•\n",
    "save_path = \"vessel_dqn_final.pth\"\n",
    "torch.save(q_net.state_dict(), save_path)\n",
    "print(f\"‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {save_path}\")\n",
    "print(\"Ïù¥Ï†ú Ïª§ÎÑêÏù¥ Í∫ºÏ†∏ÎèÑ Ïù¥ ÌååÏùºÎßå ÏûàÏúºÎ©¥ Ïñ∏Ï†úÎì† Îã§Ïãú Î∂àÎü¨Ïò¨ Ïàò ÏûàÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2680e05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [Test Inference] ÏãúÏûë: result_vis.nii.gz ---\n",
      "Case: 01011ug_527 ÏóêÏÑú ÌÖåÏä§Ìä∏ ÏßÑÌñâ Ï§ë...\n",
      "Ï¢ÖÎ£å! Score: 126.9, Steps: 128\n",
      "üíæ Ï†ÄÏû• ÏôÑÎ£å!\n",
      "   - Í≤ΩÎ°ú: inference_results/01011ug_527_visited.nii.gz\n",
      "   - Ï†ïÎãµ: inference_results/01011ug_527_target.nii.gz\n",
      "   - ÏõêÎ≥∏: inference_results/01011ug_527_ct.nii.gz\n",
      "üëâ ITK-SNAP ÌîÑÎ°úÍ∑∏Îû®ÏùÑ ÏºúÏÑú ÏúÑ ÌååÏùºÎì§ÏùÑ ÎìúÎûòÍ∑∏Ìï¥ÏÑú Ïó¥Ïñ¥Î≥¥ÏÑ∏Ïöî.\n"
     ]
    }
   ],
   "source": [
    "def run_inference_and_save(env, q_net, save_name=\"result_vis.nii.gz\"):\n",
    "    \"\"\"\n",
    "    ÌïôÏäµÎêú Î™®Îç∏Î°ú 1 ÏóêÌîºÏÜåÎìúÎ•º ÏàòÌñâÌïòÍ≥†, \n",
    "    Ïù¥Îèô Í≤ΩÎ°ú(Visited)ÏôÄ Ï†ïÎãµ(Mask)ÏùÑ NIfTI ÌååÏùºÎ°ú Ï†ÄÏû•ÌïòÎäî Ìï®Ïàò\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- [Test Inference] ÏãúÏûë: {save_name} ---\")\n",
    "    \n",
    "    # 1. ÌôòÍ≤Ω Ï¥àÍ∏∞Ìôî\n",
    "    state, info = env.reset()\n",
    "    case_name = info['case']\n",
    "    print(f\"Case: {case_name} ÏóêÏÑú ÌÖåÏä§Ìä∏ ÏßÑÌñâ Ï§ë...\")\n",
    "\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    \n",
    "    # 2. ÏóêÌîºÏÜåÎìú ÏßÑÌñâ (ÌÉêÌóò ÏóÜÏùå, Epsilon=0.0)\n",
    "    while not done:\n",
    "        # Î¨¥Ï°∞Í±¥ QÍ∞íÏù¥ Í∞ÄÏû• ÎÜíÏùÄ ÌñâÎèôÎßå ÏÑ†ÌÉù (Greedy)\n",
    "        action = q_net.sample_action(state, epsilon=0.0)\n",
    "        \n",
    "        next_state, reward, done, _, info = env.step(action)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "        \n",
    "    print(f\"Ï¢ÖÎ£å! Score: {total_reward:.1f}, Steps: {steps}\")\n",
    "\n",
    "    # 3. Í≤∞Í≥º Ï†ÄÏû• (NIfTI)\n",
    "    save_dir = Path(\"inference_results\")\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # (1) ÏóêÏù¥Ï†ÑÌä∏Í∞Ä ÏßÄÎÇòÍ∞Ñ Í≤ΩÎ°ú (Visited Volume)\n",
    "    # env.visited_vol ÏùÄ 0.0 ÎòêÎäî 1.0 ÏúºÎ°ú ÎêòÏñ¥ÏûàÏùå\n",
    "    visited_img = nib.Nifti1Image(env.visited_vol, affine=np.eye(4))\n",
    "    vis_path = save_dir / f\"{case_name}_visited.nii.gz\"\n",
    "    nib.save(visited_img, vis_path)\n",
    "\n",
    "    # (2) Ïã§Ï†ú Ï†ïÎãµ (Ground Truth Mask) - ÎπÑÍµêÏö©\n",
    "    target_img = nib.Nifti1Image(env.mask, affine=np.eye(4))\n",
    "    mask_path = save_dir / f\"{case_name}_target.nii.gz\"\n",
    "    nib.save(target_img, mask_path)\n",
    "    \n",
    "    # (3) ÏõêÎ≥∏ CT (Î∞∞Í≤ΩÏö©) - ÎπÑÍµêÏö©\n",
    "    ct_img = nib.Nifti1Image(env.ct, affine=np.eye(4))\n",
    "    ct_path = save_dir / f\"{case_name}_ct.nii.gz\"\n",
    "    nib.save(ct_img, ct_path)\n",
    "\n",
    "    print(f\"üíæ Ï†ÄÏû• ÏôÑÎ£å!\")\n",
    "    print(f\"   - Í≤ΩÎ°ú: {vis_path}\")\n",
    "    print(f\"   - Ï†ïÎãµ: {mask_path}\")\n",
    "    print(f\"   - ÏõêÎ≥∏: {ct_path}\")\n",
    "    print(\"üëâ ITK-SNAP ÌîÑÎ°úÍ∑∏Îû®ÏùÑ ÏºúÏÑú ÏúÑ ÌååÏùºÎì§ÏùÑ ÎìúÎûòÍ∑∏Ìï¥ÏÑú Ïó¥Ïñ¥Î≥¥ÏÑ∏Ïöî.\")\n",
    "\n",
    "# Ìï®Ïàò Ïã§Ìñâ (ÏßÄÍ∏à Î©îÎ™®Î¶¨Ïóê ÏûàÎäî q_net ÏÇ¨Ïö©)\n",
    "run_inference_and_save(env, q_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca5fda",
   "metadata": {},
   "source": [
    "aorta ÎÇ¥ÏóêÏÑúÎßå Ïπ†Ìï¥ÏßÄÎäî Î¨∏Ï†ú\n",
    "skeleton Ï≤òÎüº Í∑∏Î†§Ï†∏ÏÑú, Ï∂îÌõÑ dice Í≥ÑÏÇ∞ Î∂àÍ∞ÄÎêòÎäî Î¨∏Ï†ú\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62eb314",
   "metadata": {},
   "source": [
    "## 02. Env Ïóê adaptive brush ÎèÑÏûÖ\n",
    "\n",
    "1. Brush (Î∂ì) Í∏∞Îä•: ÏóêÏù¥Ï†ÑÌä∏Í∞Ä ÏßÄÎÇòÍ∞ÄÎ©¥ Ï£ºÎ≥Ä(5x5x5)ÏùÑ Ïπ†Ìï¥ÏÑú ÌòàÍ¥Ä(Volume)ÏùÑ Ï±ÑÏõÅÎãàÎã§. (Skeleton Î¨∏Ï†ú Ìï¥Í≤∞)\n",
    "2. Ïä§ÎßàÌä∏ Î≥¥ÏÉÅ: Ïù¥ÎØ∏ Ïπ†Ìï¥ÏßÑ Í≥≥ÏùÄ Ï†êÏàòÎ•º Ïïà Ï§òÏÑú Ïä§Ïä§Î°ú ÏÉàÎ°úÏö¥ Í∞ÄÏßÄ(Branch)Î°ú Ïù¥ÎèôÌïòÍ≤å Ìï©ÎãàÎã§. (Aorta Í≥†Î¶Ω Î¨∏Ï†ú Ìï¥Í≤∞)\n",
    "3. 2Ï±ÑÎÑê ÏûÖÎ†•: CT ÏõêÎ≥∏Í≥º Î∞©Î¨∏ Í∏∞Î°ù(Visited)ÏùÑ ÎèôÏãúÏóê Î¥êÏÑú Í∏∏ÏùÑ ÌåêÎã®Ìï©ÎãàÎã§.\n",
    "4. ÏïàÏ†ÑÌïú ÌïôÏäµ: Epsilon ÌÉêÌóò, Huber Loss, Model Save, Inference ÏãúÍ∞ÅÌôîÍπåÏßÄ Ìè¨Ìï®ÌñàÏäµÎãàÎã§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a72782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Found 100 cases.\n",
      ">>> Training Started...\n",
      "[Ep 005] Score:    31.7 | Steps:   46 | Eps: 0.97 | Case: NA\n",
      "[Ep 010] Score:    24.8 | Steps:   33 | Eps: 0.93 | Case: NA\n",
      "[Ep 015] Score:    12.2 | Steps:   21 | Eps: 0.90 | Case: NA\n",
      "[Ep 020] Score:    53.6 | Steps:   89 | Eps: 0.87 | Case: NA\n",
      "[Ep 025] Score:   251.1 | Steps:  350 | Eps: 0.83 | Case: NA\n",
      "[Ep 030] Score:    74.0 | Steps:   93 | Eps: 0.80 | Case: NA\n",
      "[Ep 035] Score:    91.6 | Steps:  112 | Eps: 0.77 | Case: NA\n",
      "[Ep 040] Score:     9.1 | Steps:   12 | Eps: 0.73 | Case: NA\n",
      "[Ep 045] Score:   161.5 | Steps:  168 | Eps: 0.70 | Case: NA\n",
      "[Ep 050] Score:     1.2 | Steps:    3 | Eps: 0.67 | Case: NA\n",
      "[Ep 055] Score:   256.0 | Steps:  290 | Eps: 0.63 | Case: NA\n",
      "[Ep 060] Score:   520.6 | Steps:  545 | Eps: 0.60 | Case: NA\n",
      "[Ep 065] Score:   204.5 | Steps:  226 | Eps: 0.57 | Case: NA\n",
      "[Ep 070] Score:   226.7 | Steps:  235 | Eps: 0.53 | Case: NA\n",
      "[Ep 075] Score:   103.9 | Steps:  105 | Eps: 0.50 | Case: NA\n",
      "[Ep 080] Score:   985.4 | Steps: 1000 | Eps: 0.47 | Case: NA\n",
      "[Ep 085] Score:     8.9 | Steps:   13 | Eps: 0.43 | Case: NA\n",
      "[Ep 090] Score:  1073.2 | Steps: 1000 | Eps: 0.40 | Case: NA\n",
      "[Ep 095] Score:   476.9 | Steps:  447 | Eps: 0.37 | Case: NA\n",
      "[Ep 100] Score:   981.2 | Steps:  906 | Eps: 0.33 | Case: NA\n",
      "[Ep 105] Score:   158.7 | Steps:  155 | Eps: 0.30 | Case: NA\n",
      "[Ep 110] Score:   565.5 | Steps:  499 | Eps: 0.27 | Case: NA\n",
      "[Ep 115] Score:   623.1 | Steps:  556 | Eps: 0.23 | Case: NA\n",
      "[Ep 120] Score:     4.7 | Steps:    6 | Eps: 0.20 | Case: NA\n",
      "[Ep 125] Score:   313.6 | Steps:  272 | Eps: 0.17 | Case: NA\n",
      "[Ep 130] Score:    -1.0 | Steps:    1 | Eps: 0.13 | Case: NA\n",
      "[Ep 135] Score:     8.2 | Steps:    9 | Eps: 0.10 | Case: NA\n",
      "[Ep 140] Score:  1183.7 | Steps: 1000 | Eps: 0.07 | Case: NA\n",
      "[Ep 145] Score:     2.2 | Steps:    5 | Eps: 0.03 | Case: NA\n",
      "[Ep 150] Score:     5.8 | Steps:   80 | Eps: 0.01 | Case: NA\n",
      "[Ep 155] Score:     7.7 | Steps:    9 | Eps: 0.01 | Case: NA\n",
      "[Ep 160] Score:   600.4 | Steps:  498 | Eps: 0.01 | Case: NA\n",
      "[Ep 165] Score:  1213.4 | Steps: 1000 | Eps: 0.01 | Case: NA\n",
      "[Ep 170] Score:  1211.6 | Steps: 1000 | Eps: 0.01 | Case: NA\n",
      "[Ep 175] Score:   932.7 | Steps:  776 | Eps: 0.01 | Case: NA\n",
      "[Ep 180] Score:  1192.3 | Steps: 1000 | Eps: 0.01 | Case: NA\n",
      "[Ep 185] Score:  1110.2 | Steps: 1000 | Eps: 0.01 | Case: NA\n",
      "[Ep 190] Score:   403.8 | Steps:  330 | Eps: 0.01 | Case: NA\n",
      "[Ep 195] Score:  1170.4 | Steps: 1000 | Eps: 0.01 | Case: NA\n",
      "[Ep 200] Score:  1116.3 | Steps: 1000 | Eps: 0.01 | Case: NA\n",
      "[Ep 205] Score:  1169.0 | Steps: 1000 | Eps: 0.01 | Case: NA\n",
      "[Ep 210] Score:  1213.3 | Steps: 1000 | Eps: 0.01 | Case: NA\n",
      "[Ep 215] Score:   718.0 | Steps:  631 | Eps: 0.01 | Case: NA\n",
      "[Ep 220] Score:  1230.9 | Steps: 1000 | Eps: 0.01 | Case: NA\n",
      "[Ep 225] Score:  1235.6 | Steps: 1000 | Eps: 0.01 | Case: NA\n",
      "[Ep 230] Score:   461.8 | Steps:  380 | Eps: 0.01 | Case: NA\n",
      "[Ep 235] Score:  1223.1 | Steps: 1000 | Eps: 0.01 | Case: NA\n",
      "[Ep 240] Score:   736.0 | Steps:  626 | Eps: 0.01 | Case: NA\n",
      "[Ep 245] Score:  1197.8 | Steps: 1000 | Eps: 0.01 | Case: NA\n",
      "[Ep 250] Score:  1225.7 | Steps: 1000 | Eps: 0.01 | Case: NA\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 456\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# 7. Ïã§Ìñâ (Execution)\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# 1. ÌïôÏäµ Ïã§Ìñâ\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m     q_net, env \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_vessel_dqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# 2. Í≤∞Í≥º ÏãúÍ∞ÅÌôî Ï†ÄÏû• (Î∞îÎ°ú ÌôïÏù∏)\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     run_inference_and_save(env, q_net)\n",
      "Cell \u001b[0;32mIn[17], line 368\u001b[0m, in \u001b[0;36mtrain_vessel_dqn\u001b[0;34m(n_episodes)\u001b[0m\n\u001b[1;32m    365\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m (ep \u001b[38;5;241m/\u001b[39m (n_episodes \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)))\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(MAX_STEPS):\n\u001b[0;32m--> 368\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mq_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     next_state, reward, done, _, info2 \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# Done Mask: Ï¢ÖÎ£å Ïãú 0.0, ÏßÑÌñâ Ï§ë 1.0\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 284\u001b[0m, in \u001b[0;36mCnnQNet.sample_action\u001b[0;34m(self, obs_np, epsilon)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m epsilon:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 284\u001b[0m obs_t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_np\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    286\u001b[0m     q_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(obs_t)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import collections\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# ==========================================\n",
    "# 0. ÏÑ§Ï†ï (Configuration)\n",
    "# ==========================================\n",
    "\n",
    "# [ÏàòÏ†ï ÌïÑÏöî] Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäî Ìè¥Îçî Í≤ΩÎ°ú\n",
    "DATA_ROOT = Path(\"/Users/srpark/Projects/RL_project/data/RL_prepared\")\n",
    "\n",
    "CT_NAME   = \"ct.nii.gz\"\n",
    "MASK_NAME = \"Whole_artery.nii.gz\"\n",
    "\n",
    "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\n",
    "PATCH_SIZE = (32, 32, 32)\n",
    "MAX_STEPS  = 1000        # ÌòàÍ¥Ä ÎÅùÍπåÏßÄ Í∞ÄÍ∏∞ ÏúÑÌï¥ Ï∂©Î∂ÑÌûà Í∏∏Í≤å ÏÑ§Ï†ï\n",
    "BRUSH_RADIUS = 2         # Î∂ì ÌÅ¨Í∏∞ (Î∞òÍ≤Ω 2 = 5x5x5 ÏòÅÏó≠)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LR         = 1e-4\n",
    "GAMMA      = 0.99\n",
    "BUFFER_LIMIT = 50000\n",
    "\n",
    "# ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 1. Îç∞Ïù¥ÌÑ∞ Î°úÎî© Î∞è Ï†ÑÏ≤òÎ¶¨ Ïú†Ìã∏Î¶¨Ìã∞\n",
    "# ==========================================\n",
    "\n",
    "def load_case(case_dir: Path, ct_name: str = CT_NAME, mask_name: str = MASK_NAME):\n",
    "    ct_path   = case_dir / ct_name\n",
    "    mask_path = case_dir / mask_name\n",
    "\n",
    "    if not ct_path.exists(): raise FileNotFoundError(f\"CT not found: {ct_path}\")\n",
    "    if not mask_path.exists(): raise FileNotFoundError(f\"Mask not found: {mask_path}\")\n",
    "\n",
    "    ct_nii   = nib.load(str(ct_path))\n",
    "    mask_nii = nib.load(str(mask_path))\n",
    "\n",
    "    ct   = ct_nii.get_fdata().astype(np.float32)\n",
    "    mask = mask_nii.get_fdata().astype(np.float32)\n",
    "\n",
    "    return ct, mask\n",
    "\n",
    "def normalize_ct(ct: np.ndarray, hu_min=-200.0, hu_max=300.0):\n",
    "    ct = np.clip(ct, hu_min, hu_max)\n",
    "    ct = (ct - hu_min) / (hu_max - hu_min + 1e-8)\n",
    "    return ct.astype(np.float32)\n",
    "\n",
    "def get_patch(volume: np.ndarray, center: tuple, patch_size=PATCH_SIZE):\n",
    "    D, H, W = volume.shape\n",
    "    pd, ph, pw = patch_size\n",
    "    zc, yc, xc = center\n",
    "\n",
    "    z0, y0, x0 = zc - pd // 2, yc - ph // 2, xc - pw // 2\n",
    "    z1, y1, x1 = z0 + pd, y0 + ph, x0 + pw\n",
    "\n",
    "    patch = np.zeros((pd, ph, pw), dtype=volume.dtype)\n",
    "\n",
    "    z0_src, y0_src, x0_src = max(z0, 0), max(y0, 0), max(x0, 0)\n",
    "    z1_src, y1_src, x1_src = min(z1, D), min(y1, H), min(x1, W)\n",
    "\n",
    "    z0_dst, y0_dst, x0_dst = z0_src - z0, y0_src - y0, x0_src - x0\n",
    "\n",
    "    if z1_src > z0_src and y1_src > y0_src and x1_src > x0_src:\n",
    "        patch[\n",
    "            z0_dst:z0_dst + (z1_src - z0_src),\n",
    "            y0_dst:y0_dst + (y1_src - y0_src),\n",
    "            x0_dst:x0_dst + (x1_src - x0_src)\n",
    "        ] = volume[z0_src:z1_src, y0_src:y1_src, x0_src:x1_src]\n",
    "\n",
    "    return patch\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. Í∞ïÌôîÌïôÏäµ ÌôòÍ≤Ω (Environment)\n",
    "# ==========================================\n",
    "\n",
    "class CTVesselEnv:\n",
    "    def __init__(self, data_root: Path, patch_size=PATCH_SIZE, max_steps=MAX_STEPS):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.patch_size = patch_size\n",
    "        self.max_steps = max_steps\n",
    "        self.brush_radius = BRUSH_RADIUS  # Î∂ì ÌÅ¨Í∏∞ ÏÑ§Ï†ï\n",
    "\n",
    "        self.case_dirs = sorted([p for p in self.data_root.iterdir() if p.is_dir()])\n",
    "        if not self.case_dirs:\n",
    "            raise RuntimeError(f\"No case folders found under {self.data_root}\")\n",
    "        print(f\"Found {len(self.case_dirs)} cases.\")\n",
    "\n",
    "        self.ct = None\n",
    "        self.mask = None\n",
    "        self.ct_norm = None\n",
    "        \n",
    "        # 3D Volume ÏÉÅÌÉú\n",
    "        self.visited_vol = None \n",
    "        \n",
    "        self.D = self.H = self.W = None\n",
    "        self.pos = None\n",
    "        self.step_count = 0\n",
    "        self.current_case_dir = None\n",
    "\n",
    "    def _load_random_case(self):\n",
    "        while True:\n",
    "            case_dir = random.choice(self.case_dirs)\n",
    "            try:\n",
    "                ct, mask = load_case(case_dir)\n",
    "            except Exception:\n",
    "                continue\n",
    "            \n",
    "            # ÌòàÍ¥ÄÏù¥ ÏóÜÎäî Îç∞Ïù¥ÌÑ∞Îäî Ïä§ÌÇµ\n",
    "            if (mask > 0).sum() == 0: continue\n",
    "\n",
    "            self.ct = ct\n",
    "            self.mask = (mask > 0.5).astype(np.uint8)\n",
    "            self.ct_norm = normalize_ct(ct)\n",
    "            \n",
    "            # Î∞©Î¨∏ Í∏∞Î°ùÏö© Îπà Î≥ºÎ•® ÏÉùÏÑ±\n",
    "            self.visited_vol = np.zeros_like(self.mask, dtype=np.float32)\n",
    "            \n",
    "            self.D, self.H, self.W = self.ct.shape\n",
    "            self.current_case_dir = case_dir\n",
    "            break\n",
    "\n",
    "    def _sample_start_pos(self):\n",
    "        # ÌòàÍ¥Ä ÎÇ¥Î∂Ä ÎûúÎç§ ÏãúÏûë\n",
    "        vessel_indices = np.argwhere(self.mask > 0)\n",
    "        idx = vessel_indices[np.random.randint(len(vessel_indices))]\n",
    "        return tuple(idx)\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"\n",
    "        [2Ï±ÑÎÑê ÏûÖÎ†•]\n",
    "        Ch 0: CT Image\n",
    "        Ch 1: Visited Mask (ÎÇ¥Í∞Ä Ïπ†Ìïú Í≥≥)\n",
    "        \"\"\"\n",
    "        ct_patch = get_patch(self.ct_norm, self.pos, self.patch_size)\n",
    "        vis_patch = get_patch(self.visited_vol, self.pos, self.patch_size)\n",
    "        state = np.stack([ct_patch, vis_patch], axis=0).astype(np.float32)\n",
    "        return state\n",
    "\n",
    "    def _move(self, z, y, x, action):\n",
    "        # 6Î∞©Ìñ• Ïù¥Îèô\n",
    "        deltas = [(1,0,0), (-1,0,0), (0,1,0), (0,-1,0), (0,0,1), (0,0,-1)]\n",
    "        dz, dy, dx = deltas[action]\n",
    "        return z+dz, y+dy, x+dx\n",
    "\n",
    "    def _apply_brush(self, center_pos):\n",
    "        \"\"\"\n",
    "        [Smart Brush Logic]\n",
    "        Î∂ì ÌÅ¨Í∏∞ÎßåÌÅº Ïπ†ÌïòÎêò, 'Ïã§Ï†ú ÌòàÍ¥Ä(Mask=1)'Ïù∏ Í≥≥Îßå Ïπ†Ìï®.\n",
    "        Ïù¥ÎØ∏ Ïπ†Ìï¥ÏßÑ Í≥≥ÏùÄ Ïπ¥Ïö¥Ìä∏ÌïòÏßÄ ÏïäÏùå.\n",
    "        return: ÏÉàÎ°≠Í≤å Ïπ†Ìï¥ÏßÑ ÌîΩÏÖÄ Ïàò\n",
    "        \"\"\"\n",
    "        z, y, x = center_pos\n",
    "        r = self.brush_radius\n",
    "        \n",
    "        z_min, z_max = max(0, z-r), min(self.D, z+r+1)\n",
    "        y_min, y_max = max(0, y-r), min(self.H, y+r+1)\n",
    "        x_min, x_max = max(0, x-r), min(self.W, x+r+1)\n",
    "        \n",
    "        target_area = self.mask[z_min:z_max, y_min:y_max, x_min:x_max]\n",
    "        visited_area = self.visited_vol[z_min:z_max, y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # (ÌòàÍ¥ÄÏù¥Î©¥ÏÑú) AND (ÏïÑÏßÅ Ïïà Ïπ†Ìïú Í≥≥)\n",
    "        newly_filled_mask = (target_area == 1) & (visited_area == 0)\n",
    "        new_fill_count = np.sum(newly_filled_mask)\n",
    "        \n",
    "        # Î∞©Î¨∏ Ï≤òÎ¶¨ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "        self.visited_vol[z_min:z_max, y_min:y_max, x_min:x_max][newly_filled_mask] = 1.0\n",
    "        \n",
    "        return new_fill_count\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "        self._load_random_case()\n",
    "        self.pos = self._sample_start_pos()\n",
    "        self.step_count = 0\n",
    "        \n",
    "        # ÏãúÏûëÌïòÏûêÎßàÏûê ÌòÑÏû¨ ÏúÑÏπò Î∂ìÏπ†\n",
    "        self._apply_brush(self.pos)\n",
    "\n",
    "        state = self._get_state()\n",
    "        info = {\"pos\": self.pos, \"case\": self.current_case_dir.name}\n",
    "        return state, info\n",
    "\n",
    "    def step(self, action: int):\n",
    "        z, y, x = self.pos\n",
    "        nz, ny, nx = self._move(z, y, x, action)\n",
    "        \n",
    "        # 1. Î≥ºÎ•® Ïù¥ÌÉà Ï≤¥ÌÅ¨\n",
    "        if not (0 <= nz < self.D and 0 <= ny < self.H and 0 <= nx < self.W):\n",
    "            reward = -1.0\n",
    "            done = True\n",
    "            return self._get_state(), reward, done, False, {\"inside\": False}\n",
    "\n",
    "        # 2. ÌòàÍ¥Ä ÎÇ¥Î∂Ä Ï≤¥ÌÅ¨\n",
    "        inside = bool(self.mask[nz, ny, nx] > 0)\n",
    "\n",
    "        if not inside:\n",
    "            # ÌòàÍ¥Ä Î∞ñ -> ÌéòÎÑêÌã∞ Î∞õÍ≥† Ï¢ÖÎ£å\n",
    "            reward = -1.0\n",
    "            done = True\n",
    "        else:\n",
    "            # 3. [Î≥¥ÏÉÅ Î°úÏßÅ] Î∏åÎü¨Ïâ¨Ïßà ÏàòÌñâ\n",
    "            new_pixels = self._apply_brush((nz, ny, nx))\n",
    "            \n",
    "            if new_pixels > 0:\n",
    "                # ÏÉàÎ°úÏö¥ ÏòÅÏó≠ÏùÑ Ï±ÑÏõÄ (Good!)\n",
    "                # 1.0 Í∏∞Î≥∏ Ï†êÏàò + ÌîΩÏÖÄ Ïàò ÎπÑÎ°Ä Ï∂îÍ∞Ä Î≥¥ÎÑàÏä§\n",
    "                reward = 1.0 + (new_pixels * 0.01)\n",
    "                done = False\n",
    "            else:\n",
    "                # Ïù¥ÎØ∏ Îã§ Ïπ†Ìï¥ÏßÑ Í≥≥ÏûÑ (Bad - ÏãúÍ∞Ñ ÎÇ≠ÎπÑ)\n",
    "                # ÏïΩÌïú ÌéòÎÑêÌã∞Î•º Ï§òÏÑú Îã§Î•∏ Í≥≥ÏúºÎ°ú Ïù¥Îèô Ïú†ÎèÑ\n",
    "                reward = -0.1\n",
    "                done = False\n",
    "\n",
    "        self.pos = (nz, ny, nx)\n",
    "        self.step_count += 1\n",
    "        \n",
    "        if self.step_count >= self.max_steps:\n",
    "            done = True\n",
    "\n",
    "        return self._get_state(), reward, done, False, {\"inside\": inside}\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. Ïã†Í≤ΩÎßù (DQN Agent)\n",
    "# ==========================================\n",
    "\n",
    "class CnnQNet(nn.Module):\n",
    "    def __init__(self, in_channels=2, n_actions=6): # ÏûÖÎ†• Ï±ÑÎÑê 2 (CT, Visited)\n",
    "        super().__init__()\n",
    "        # BatchNorm Ï†úÍ±∞ (ÏïàÏ†ïÏÑ±)\n",
    "        self.conv1 = nn.Conv3d(in_channels, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, 3, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten ÌõÑ FC\n",
    "        # 32 -> 16 -> 8 -> 4 ÌÅ¨Í∏∞Î°ú Ï§ÑÏñ¥Îì¶. Ï±ÑÎÑê 64.\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def sample_action(self, obs_np, epsilon):\n",
    "        # Epsilon-Greedy\n",
    "        if random.random() < epsilon:\n",
    "            return random.randint(0, self.fc2.out_features - 1)\n",
    "        \n",
    "        obs_t = torch.from_numpy(obs_np).float().unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            q_out = self.forward(obs_t)\n",
    "            action = q_out.argmax(dim=1).item()\n",
    "        return action\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. ÌïôÏäµ Ìó¨Ìçº (Replay Buffer & Train)\n",
    "# ==========================================\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, buffer_limit=BUFFER_LIMIT):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "\n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        mini_batch = random.sample(self.buffer, batch_size)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "\n",
    "        for (s, a, r, s_prime, done_mask) in mini_batch:\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "\n",
    "        return (torch.tensor(np.array(s_lst), dtype=torch.float32, device=DEVICE),\n",
    "                torch.tensor(a_lst, dtype=torch.int64, device=DEVICE),\n",
    "                torch.tensor(r_lst, dtype=torch.float32, device=DEVICE),\n",
    "                torch.tensor(np.array(s_prime_lst), dtype=torch.float32, device=DEVICE),\n",
    "                torch.tensor(done_mask_lst, dtype=torch.float32, device=DEVICE))\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "def train_dqn(q_net, target_net, memory, optimizer, batch_size=BATCH_SIZE, gamma=GAMMA):\n",
    "    if memory.size() < batch_size: return\n",
    "\n",
    "    s, a, r, s_prime, done_mask = memory.sample(batch_size)\n",
    "\n",
    "    q_out = q_net(s)\n",
    "    q_a = q_out.gather(1, a)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        max_q_prime = target_net(s_prime).max(1, keepdim=True)[0]\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "\n",
    "    loss = F.smooth_l1_loss(q_a, target) # Huber Loss ÏÇ¨Ïö©\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 5. Î©îÏù∏ ÌïôÏäµ Î£®ÌîÑ (Main Loop)\n",
    "# ==========================================\n",
    "\n",
    "def train_vessel_dqn(n_episodes=300):\n",
    "    env = CTVesselEnv(DATA_ROOT, patch_size=PATCH_SIZE, max_steps=MAX_STEPS)\n",
    "\n",
    "    q_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "    target_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    memory = ReplayBuffer(BUFFER_LIMIT)\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=LR)\n",
    "\n",
    "    print_interval = 5\n",
    "    \n",
    "    print(\">>> Training Started...\")\n",
    "    \n",
    "    for ep in range(1, n_episodes + 1):\n",
    "        state, info = env.reset()\n",
    "        ep_reward = 0.0\n",
    "        ep_steps = 0\n",
    "        \n",
    "        # Epsilon Decay: 1.0 -> 0.01 (Ï†ÑÏ≤¥ ÏóêÌîºÏÜåÎìúÏùò 50% Íµ¨Í∞Ñ ÎèôÏïà Í∞êÏÜå)\n",
    "        epsilon = max(0.01, 1.0 - (ep / (n_episodes * 0.5)))\n",
    "\n",
    "        for t in range(MAX_STEPS):\n",
    "            action = q_net.sample_action(state, epsilon)\n",
    "            next_state, reward, done, _, info2 = env.step(action)\n",
    "\n",
    "            # Done Mask: Ï¢ÖÎ£å Ïãú 0.0, ÏßÑÌñâ Ï§ë 1.0\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "\n",
    "            memory.put((state, action, reward, next_state, done_mask))\n",
    "\n",
    "            state = next_state\n",
    "            ep_reward += reward\n",
    "            ep_steps += 1\n",
    "\n",
    "            # ÌïôÏäµ (Î∞∞Ïπò Îã®ÏúÑ ÏóÖÎç∞Ïù¥Ìä∏)\n",
    "            train_dqn(q_net, target_net, memory, optimizer, BATCH_SIZE)\n",
    "\n",
    "            if done: break\n",
    "        \n",
    "        # ÌÉÄÍ≤ü ÎÑ§Ìä∏ÏõåÌÅ¨ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "        if ep % 10 == 0:\n",
    "            target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "        # Î°úÍ∑∏ Ï∂úÎ†•\n",
    "        if ep % print_interval == 0:\n",
    "            print(f\"[Ep {ep:03d}] Score: {ep_reward:7.1f} | Steps: {ep_steps:4d} | \"\n",
    "                  f\"Eps: {epsilon:.2f} | Case: {info2.get('case', 'NA')}\")\n",
    "\n",
    "    print(\">>> Training Finished!\")\n",
    "    \n",
    "    # Î™®Îç∏ Ï†ÄÏû•\n",
    "    save_path = \"vessel_dqn_brush.pth\"\n",
    "    torch.save(q_net.state_dict(), save_path)\n",
    "    print(f\"‚úÖ Model saved to {save_path}\")\n",
    "\n",
    "    return q_net, env\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 6. Ï∂îÎ°† Î∞è ÏãúÍ∞ÅÌôî (Inference & Visualization)\n",
    "# ==========================================\n",
    "\n",
    "def run_inference_and_save(env, q_net, save_name=\"result_vis.nii.gz\"):\n",
    "    print(f\"\\n--- [Inference Test] {save_name} ---\")\n",
    "    \n",
    "    state, info = env.reset()\n",
    "    case_name = info['case']\n",
    "    print(f\"Case: {case_name}\")\n",
    "\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    \n",
    "    while not done:\n",
    "        # Epsilon=0 (Greedy)\n",
    "        action = q_net.sample_action(state, epsilon=0.0)\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        \n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "        \n",
    "    print(f\"Result -> Score: {total_reward:.1f}, Steps: {steps}\")\n",
    "\n",
    "    # Ï†ÄÏû•\n",
    "    save_dir = Path(\"inference_results\")\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # 1. AIÍ∞Ä ÏÉâÏπ†Ìïú Volume\n",
    "    visited_img = nib.Nifti1Image(env.visited_vol, affine=np.eye(4))\n",
    "    nib.save(visited_img, save_dir / f\"{case_name}_visited.nii.gz\")\n",
    "\n",
    "    # 2. Ï†ïÎãµ (Target)\n",
    "    target_img = nib.Nifti1Image(env.mask, affine=np.eye(4))\n",
    "    nib.save(target_img, save_dir / f\"{case_name}_target.nii.gz\")\n",
    "    \n",
    "    # 3. ÏõêÎ≥∏ CT\n",
    "    ct_img = nib.Nifti1Image(env.ct, affine=np.eye(4))\n",
    "    nib.save(ct_img, save_dir / f\"{case_name}_ct.nii.gz\")\n",
    "\n",
    "    print(f\"üíæ Saved to {save_dir}\")\n",
    "    print(\"Use ITK-SNAP to visualize (Overlay 'visited' as Segmentation)\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 7. Ïã§Ìñâ (Execution)\n",
    "# ==========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. ÌïôÏäµ Ïã§Ìñâ\n",
    "    q_net, env = train_vessel_dqn(n_episodes=300)\n",
    "    \n",
    "    # 2. Í≤∞Í≥º ÏãúÍ∞ÅÌôî Ï†ÄÏû• (Î∞îÎ°ú ÌôïÏù∏)\n",
    "    run_inference_and_save(env, q_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baa75a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõë ÌïôÏäµÏùÑ Ï§ëÎã®ÌïòÍ≥† ÌòÑÏû¨ ÏÉÅÌÉúÎ•º Ï†ÄÏû•Ìï©ÎãàÎã§...\n",
      "‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: vessel_dqn_early_stop.pth\n",
      "\n",
      "--- Í≤∞Í≥º ÏãúÍ∞ÅÌôî ÌååÏùº ÏÉùÏÑ± ÏãúÏûë ---\n",
      "\n",
      "--- [Inference Test] result_early_stop.nii.gz ---\n",
      "Case: 01015ug_94\n",
      "Result -> Score: 128.0, Steps: 128\n",
      "üíæ Saved to inference_results\n",
      "Use ITK-SNAP to visualize (Overlay 'visited' as Segmentation)\n",
      "\n",
      "üöÄ ÌôïÏù∏ Î∞©Î≤ï:\n",
      "1. ÏÉùÏÑ±Îêú 'inference_results' Ìè¥ÎçîÎ°ú Í∞ÄÏÑ∏Ïöî.\n",
      "2. '..._visited.nii.gz' ÏôÄ '..._ct.nii.gz' ÌååÏùºÏùÑ ITK-SNAPÏúºÎ°ú Ïó¥Ïñ¥Î≥¥ÏÑ∏Ïöî.\n"
     ]
    }
   ],
   "source": [
    "# === ÌïôÏäµ Ï§ëÍ∞ÑÏóê Î©àÏ∂îÍ≥† Ïã§ÌñâÌïòÎäî ÏΩîÎìú ===\n",
    "\n",
    "print(\"üõë ÌïôÏäµÏùÑ Ï§ëÎã®ÌïòÍ≥† ÌòÑÏû¨ ÏÉÅÌÉúÎ•º Ï†ÄÏû•Ìï©ÎãàÎã§...\")\n",
    "\n",
    "# 1. ÌòÑÏû¨ÍπåÏßÄ ÌïôÏäµÎêú Î™®Îç∏ Ï†ÄÏû• (Ïù¥Í≤å Ï†úÏùº Ï§ëÏöî!)\n",
    "save_path = \"vessel_dqn_early_stop.pth\"\n",
    "torch.save(q_net.state_dict(), save_path)\n",
    "print(f\"‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {save_path}\")\n",
    "\n",
    "# 2. Î∞îÎ°ú Í≤∞Í≥º ÎΩëÏïÑÎ≥¥Í∏∞ (Inference)\n",
    "# ÌïôÏäµ Îïå Ïïà Î≥∏ Îç∞Ïù¥ÌÑ∞(Test mode)Í∞Ä ÏïÑÎãàÎùº, ÏùºÎã® Ïûò ÎêòÎäîÏßÄ ÌôïÏù∏ÌïòÍ∏∞ ÏúÑÌï¥\n",
    "# ÌòÑÏû¨ ÌôòÍ≤Ω(env) Í∑∏ÎåÄÎ°ú ÌÖåÏä§Ìä∏Ìï¥Î¥ÖÎãàÎã§.\n",
    "print(\"\\n--- Í≤∞Í≥º ÏãúÍ∞ÅÌôî ÌååÏùº ÏÉùÏÑ± ÏãúÏûë ---\")\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî Ìï®Ïàò Ïã§Ìñâ (Î©îÎ™®Î¶¨Ïóê ÏûàÎäî q_net ÏÇ¨Ïö©)\n",
    "run_inference_and_save(env, q_net, save_name=\"result_early_stop.nii.gz\")\n",
    "\n",
    "print(\"\\nüöÄ ÌôïÏù∏ Î∞©Î≤ï:\")\n",
    "print(\"1. ÏÉùÏÑ±Îêú 'inference_results' Ìè¥ÎçîÎ°ú Í∞ÄÏÑ∏Ïöî.\")\n",
    "print(\"2. '..._visited.nii.gz' ÏôÄ '..._ct.nii.gz' ÌååÏùºÏùÑ ITK-SNAPÏúºÎ°ú Ïó¥Ïñ¥Î≥¥ÏÑ∏Ïöî.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efee5a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ï¥ù 10Ìöå ÎûúÎç§ ÌÖåÏä§Ìä∏ ÏãúÏûë (Ï†êÏàò Ï¢ãÏùÄ Í≤ÉÎßå Ï†ÄÏû•) ---\n",
      "[Test 1] Case: 01010ug_172 | Score: 128.0 | Steps: 128\n",
      "   >>> üíæ Ï†ÄÏû• ÏôÑÎ£å: 01010ug_172 ÏÑ∏Ìä∏ (visited, ct, target)\n",
      "[Test 2] Case: 01018ug_95 | Score: 115.9 | Steps: 128\n",
      "   >>> üíæ Ï†ÄÏû• ÏôÑÎ£å: 01018ug_95 ÏÑ∏Ìä∏ (visited, ct, target)\n",
      "[Test 3] Case: 01010ug_5 | Score: 128.0 | Steps: 128\n",
      "   >>> üíæ Ï†ÄÏû• ÏôÑÎ£å: 01010ug_5 ÏÑ∏Ìä∏ (visited, ct, target)\n",
      "[Test 4] Case: 01010ug_5 | Score: 32.3 | Steps: 128\n",
      "[Test 5] Case: 01018ug_75 | Score: 126.9 | Steps: 128\n",
      "   >>> üíæ Ï†ÄÏû• ÏôÑÎ£å: 01018ug_75 ÏÑ∏Ìä∏ (visited, ct, target)\n",
      "[Test 6] Case: 01018ug_90 | Score: 128.0 | Steps: 128\n",
      "   >>> üíæ Ï†ÄÏû• ÏôÑÎ£å: 01018ug_90 ÏÑ∏Ìä∏ (visited, ct, target)\n",
      "[Test 7] Case: 01010ug_3 | Score: 128.0 | Steps: 128\n",
      "   >>> üíæ Ï†ÄÏû• ÏôÑÎ£å: 01010ug_3 ÏÑ∏Ìä∏ (visited, ct, target)\n",
      "[Test 8] Case: 01015ug_75 | Score: 128.0 | Steps: 128\n",
      "   >>> üíæ Ï†ÄÏû• ÏôÑÎ£å: 01015ug_75 ÏÑ∏Ìä∏ (visited, ct, target)\n",
      "[Test 9] Case: 01011ug_513 | Score: -1.0 | Steps: 1\n",
      "[Test 10] Case: 01018ug_94 | Score: 128.0 | Steps: 128\n",
      "   >>> üíæ Ï†ÄÏû• ÏôÑÎ£å: 01018ug_94 ÏÑ∏Ìä∏ (visited, ct, target)\n"
     ]
    }
   ],
   "source": [
    "def run_inference_with_case_id(env, q_net, count):\n",
    "    save_dir = Path(\"inference_results_final\")\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"--- Ï¥ù {count}Ìöå ÎûúÎç§ ÌÖåÏä§Ìä∏ ÏãúÏûë (Ï†êÏàò Ï¢ãÏùÄ Í≤ÉÎßå Ï†ÄÏû•) ---\")\n",
    "    \n",
    "    for i in range(count):\n",
    "        state, info = env.reset()\n",
    "        \n",
    "        # [ÌïµÏã¨] ÌòÑÏû¨ ÌÖåÏä§Ìä∏ Ï§ëÏù∏ ÌôòÏûê ID Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        case_id = info['case'] \n",
    "        \n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        \n",
    "        # ÏóêÌîºÏÜåÎìú ÏßÑÌñâ (Greedy)\n",
    "        while not done:\n",
    "            action = q_net.sample_action(state, epsilon=0.0)\n",
    "            state, reward, done, _, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "            \n",
    "        print(f\"[Test {i+1}] Case: {case_id} | Score: {total_reward:.1f} | Steps: {steps}\")\n",
    "        \n",
    "        # Ï†êÏàòÍ∞Ä 100Ï†ê ÎÑòÎäî ÏÑ±Í≥µÏ†ÅÏù∏ ÏºÄÏù¥Ïä§Îßå Ï†ÄÏû•\n",
    "        if total_reward > 100:\n",
    "            # 1. AIÍ∞Ä Í∑∏Î¶∞ Í≤ΩÎ°ú (Visited)\n",
    "            vis_name = f\"{case_id}_visited_score_{int(total_reward)}.nii.gz\"\n",
    "            nib.save(nib.Nifti1Image(env.visited_vol, np.eye(4)), save_dir / vis_name)\n",
    "            \n",
    "            # 2. ÏõêÎ≥∏ CT (Î∞∞Í≤ΩÏö©) - Í∞ôÏù¥ Ï†ÄÏû•Ìï¥Îë†\n",
    "            ct_name = f\"{case_id}_ct.nii.gz\"\n",
    "            nib.save(nib.Nifti1Image(env.ct, np.eye(4)), save_dir / ct_name)\n",
    "            \n",
    "            # 3. Ï†ïÎãµ ÎßàÏä§ÌÅ¨ (ÎπÑÍµêÏö©)\n",
    "            target_name = f\"{case_id}_target.nii.gz\"\n",
    "            nib.save(nib.Nifti1Image(env.mask, np.eye(4)), save_dir / target_name)\n",
    "            \n",
    "            print(f\"   >>> üíæ Ï†ÄÏû• ÏôÑÎ£å: {case_id} ÏÑ∏Ìä∏ (visited, ct, target)\")\n",
    "\n",
    "# 10Î≤à ÏãúÎèÑÌï¥ÏÑú Ïûò Îêú Í≤ÉÎì§ ÎΩëÍ∏∞\n",
    "run_inference_with_case_id(env, q_net, count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622840e4",
   "metadata": {},
   "source": [
    "## 03. Centerline Î≥¥ÏÉÅ Ï∂îÍ∞Ä\n",
    "\n",
    "- aorta ÏóêÏÑúÎßå ÌÉêÏÉâÌïòÎäî Î¨∏Ï†ú\n",
    "- Î™®Îì† vessel Ïùò Ï§ëÏã¨ÏÑ†ÏùÑ Í∏∞Ï§ÄÏúºÎ°ú reward Ïû¨ÏÑ§Í≥Ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ecc97",
   "metadata": {},
   "source": [
    "### centerline Ï∂îÏ∂ú Î∞è Ï†ÄÏû•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47bfb288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generating Centerlines for 99 cases ===\n",
      "‚úî Centerline saved for case: 01010ug_1\n",
      "‚úî Centerline saved for case: 01010ug_11\n",
      "‚úî Centerline saved for case: 01010ug_133\n",
      "‚úî Centerline saved for case: 01010ug_134\n",
      "‚úî Centerline saved for case: 01010ug_135\n",
      "‚úî Centerline saved for case: 01010ug_136\n",
      "‚úî Centerline saved for case: 01010ug_164\n",
      "‚úî Centerline saved for case: 01010ug_165\n",
      "‚úî Centerline saved for case: 01010ug_166\n",
      "‚úî Centerline saved for case: 01010ug_167\n",
      "‚úî Centerline saved for case: 01010ug_168\n",
      "‚úî Centerline saved for case: 01010ug_169\n",
      "‚úî Centerline saved for case: 01010ug_170\n",
      "‚úî Centerline saved for case: 01010ug_171\n",
      "‚úî Centerline saved for case: 01010ug_172\n",
      "‚úî Centerline saved for case: 01010ug_174\n",
      "‚úî Centerline saved for case: 01010ug_176\n",
      "‚úî Centerline saved for case: 01010ug_177\n",
      "‚úî Centerline saved for case: 01010ug_2\n",
      "‚úî Centerline saved for case: 01010ug_3\n",
      "‚úî Centerline saved for case: 01010ug_4\n",
      "‚úî Centerline saved for case: 01010ug_5\n",
      "‚úî Centerline saved for case: 01010ug_6\n",
      "‚úî Centerline saved for case: 01010ug_7\n",
      "‚úî Centerline saved for case: 01010ug_8\n",
      "‚úî Centerline saved for case: 01011ug_500\n",
      "‚úî Centerline saved for case: 01011ug_501\n",
      "‚úî Centerline saved for case: 01011ug_502\n",
      "‚úî Centerline saved for case: 01011ug_503\n",
      "‚úî Centerline saved for case: 01011ug_504\n",
      "‚úî Centerline saved for case: 01011ug_505\n",
      "‚úî Centerline saved for case: 01011ug_506\n",
      "‚úî Centerline saved for case: 01011ug_507\n",
      "‚úî Centerline saved for case: 01011ug_508\n",
      "‚úî Centerline saved for case: 01011ug_509\n",
      "‚úî Centerline saved for case: 01011ug_510\n",
      "‚úî Centerline saved for case: 01011ug_511\n",
      "‚úî Centerline saved for case: 01011ug_512\n",
      "‚úî Centerline saved for case: 01011ug_513\n",
      "‚úî Centerline saved for case: 01011ug_514\n",
      "‚úî Centerline saved for case: 01011ug_515\n",
      "‚úî Centerline saved for case: 01011ug_516\n",
      "‚úî Centerline saved for case: 01011ug_517\n",
      "‚úî Centerline saved for case: 01011ug_519\n",
      "‚úî Centerline saved for case: 01011ug_520\n",
      "‚úî Centerline saved for case: 01011ug_521\n",
      "‚úî Centerline saved for case: 01011ug_522\n",
      "‚úî Centerline saved for case: 01011ug_523\n",
      "‚úî Centerline saved for case: 01011ug_525\n",
      "‚úî Centerline saved for case: 01011ug_526\n",
      "‚úî Centerline saved for case: 01011ug_527\n",
      "‚úî Centerline saved for case: 01011ug_528\n",
      "‚úî Centerline saved for case: 01011ug_529\n",
      "‚úî Centerline saved for case: 01011ug_530\n",
      "‚úî Centerline saved for case: 01015ug_100\n",
      "‚úî Centerline saved for case: 01015ug_70\n",
      "‚úî Centerline saved for case: 01015ug_71\n",
      "‚úî Centerline saved for case: 01015ug_72\n",
      "‚úî Centerline saved for case: 01015ug_74\n",
      "‚úî Centerline saved for case: 01015ug_75\n",
      "‚úî Centerline saved for case: 01015ug_76\n",
      "‚úî Centerline saved for case: 01015ug_79\n",
      "‚úî Centerline saved for case: 01015ug_89\n",
      "‚úî Centerline saved for case: 01015ug_90\n",
      "‚úî Centerline saved for case: 01015ug_91\n",
      "‚úî Centerline saved for case: 01015ug_92\n",
      "‚úî Centerline saved for case: 01015ug_93\n",
      "‚úî Centerline saved for case: 01015ug_94\n",
      "‚úî Centerline saved for case: 01015ug_95\n",
      "‚úî Centerline saved for case: 01015ug_96\n",
      "‚úî Centerline saved for case: 01015ug_97\n",
      "‚úî Centerline saved for case: 01015ug_98\n",
      "‚úî Centerline saved for case: 01015ug_99\n",
      "‚úî Centerline saved for case: 01018ug_105\n",
      "‚úî Centerline saved for case: 01018ug_70\n",
      "‚úî Centerline saved for case: 01018ug_71\n",
      "‚úî Centerline saved for case: 01018ug_72\n",
      "‚úî Centerline saved for case: 01018ug_73\n",
      "‚úî Centerline saved for case: 01018ug_75\n",
      "‚úî Centerline saved for case: 01018ug_76\n",
      "‚úî Centerline saved for case: 01018ug_77\n",
      "‚úî Centerline saved for case: 01018ug_78\n",
      "‚úî Centerline saved for case: 01018ug_79\n",
      "‚úî Centerline saved for case: 01018ug_80\n",
      "‚úî Centerline saved for case: 01018ug_81\n",
      "‚úî Centerline saved for case: 01018ug_82\n",
      "‚úî Centerline saved for case: 01018ug_84\n",
      "‚úî Centerline saved for case: 01018ug_85\n",
      "‚úî Centerline saved for case: 01018ug_86\n",
      "‚úî Centerline saved for case: 01018ug_87\n",
      "‚úî Centerline saved for case: 01018ug_88\n",
      "‚úî Centerline saved for case: 01018ug_89\n",
      "‚úî Centerline saved for case: 01018ug_90\n",
      "‚úî Centerline saved for case: 01018ug_91\n",
      "‚úî Centerline saved for case: 01018ug_94\n",
      "‚úî Centerline saved for case: 01018ug_95\n",
      "‚úî Centerline saved for case: 01018ug_96\n",
      "‚úî Centerline saved for case: 01018ug_97\n",
      "‚úî Centerline saved for case: 01018ug_98\n",
      "\n",
      "üéâ All centerlines generated!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "\n",
    "# üîÅ skeletonize_3d ÎòêÎäî skeletonize ÏûêÎèô fallback\n",
    "try:\n",
    "    from skimage.morphology import skeletonize_3d as skeletonize_centerline\n",
    "except ImportError:\n",
    "    from skimage.morphology import skeletonize as skeletonize_centerline\n",
    "\n",
    "\n",
    "# üîÅ ÏÉàÎ°úÏö¥ Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú (largest componentÎßå ÎÇ®Í∏¥ cleaned Î≤ÑÏ†Ñ)\n",
    "DATA_ROOT = Path(\"/Users/srpark/Projects/RL_project/data/processed/RL_cleaned\")\n",
    "\n",
    "MASK_NAME = \"whole_artery_cleaned.nii.gz\"   # ÎßàÏä§ÌÅ¨ ÌååÏùº Ïù¥Î¶Ñ\n",
    "SAVE_NAME = \"centerline.nii.gz\"     # Ï†ÄÏû•Ìï† centerline ÌååÏùº Ïù¥Î¶Ñ\n",
    "\n",
    "\n",
    "def generate_centerline(mask_volume: np.ndarray):\n",
    "    \"\"\"\n",
    "    mask_volume: binary vessel mask (0/1)\n",
    "    return: 3D skeleton (centerline) 0/1\n",
    "    \"\"\"\n",
    "    mask_bin = (mask_volume > 0.5).astype(np.uint8)\n",
    "\n",
    "    # skeletonize_centerline ÏùÄ skeletonize_3d ÎòêÎäî fallback skeletonize\n",
    "    centerline = skeletonize_centerline(mask_bin)\n",
    "\n",
    "    return centerline.astype(np.uint8)\n",
    "\n",
    "\n",
    "def process_all_cases(data_root: Path):\n",
    "    case_dirs = sorted([p for p in data_root.iterdir() if p.is_dir()])\n",
    "\n",
    "    print(f\"=== Generating Centerlines for {len(case_dirs)} cases ===\")\n",
    "\n",
    "    for case in case_dirs:\n",
    "        mask_path = case / MASK_NAME\n",
    "        save_path = case / SAVE_NAME\n",
    "\n",
    "        if not mask_path.exists():\n",
    "            print(f\"‚ö†Ô∏è No mask found in {case.name}, skipped.\")\n",
    "            continue\n",
    "\n",
    "        # Ïù¥ÎØ∏ centerlineÏù¥ ÏûàÏúºÎ©¥ Í±¥ÎÑàÎõ∞Í∏∞\n",
    "        if save_path.exists():\n",
    "            print(f\"‚úî Already exists: {case.name}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            mask_nii = nib.load(str(mask_path))\n",
    "            mask = mask_nii.get_fdata()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Load failed on {case.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # centerline ÏÉùÏÑ±\n",
    "        centerline = generate_centerline(mask)\n",
    "\n",
    "        # Ï†ÄÏû•\n",
    "        out_img = nib.Nifti1Image(centerline, affine=mask_nii.affine)\n",
    "        nib.save(out_img, save_path)\n",
    "\n",
    "        print(f\"‚úî Centerline saved for case: {case.name}\")\n",
    "\n",
    "    print(\"\\nüéâ All centerlines generated!\")\n",
    "\n",
    "\n",
    "# Ïã§Ìñâ\n",
    "process_all_cases(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a97f46",
   "metadata": {},
   "source": [
    "### ÏÑ§Í≥Ñ - Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è CT patch ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dde9092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import collections\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# =========================\n",
    "# 0. Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
    "# =========================\n",
    "\n",
    "DATA_ROOT   = Path(\"/Users/srpark/Projects/RL_project/data/processed/RL_cleaned\")\n",
    "CT_NAME     = \"ct.nii.gz\"\n",
    "MASK_NAME   = \"whole_artery_cleaned.nii.gz\"\n",
    "CENTER_NAME = \"centerline.nii.gz\"\n",
    "\n",
    "PATCH_SIZE   = (32, 32, 32)\n",
    "MAX_STEPS    = 1000\n",
    "BRUSH_RADIUS = 5\n",
    "\n",
    "BATCH_SIZE   = 32\n",
    "LR           = 1e-4\n",
    "GAMMA        = 0.99\n",
    "BUFFER_LIMIT = 50000\n",
    "\n",
    "# ÎîîÎ∞îÏù¥Ïä§\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "386b92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1. Î°úÎçî & Ïú†Ìã∏\n",
    "# =========================\n",
    "\n",
    "def load_case_with_centerline(\n",
    "    case_dir: Path,\n",
    "    ct_name: str = CT_NAME,\n",
    "    mask_name: str = MASK_NAME,\n",
    "    center_name: str = CENTER_NAME,\n",
    "):\n",
    "    \"\"\"\n",
    "    case_dir ÏïàÏóêÏÑú\n",
    "    - ct.nii.gz\n",
    "    - Whole_artery.nii.gz\n",
    "    - centerline.nii.gz\n",
    "    Î•º ÏùΩÏñ¥ÏÑú (ct, mask, centerline) Î∞òÌôò\n",
    "    \"\"\"\n",
    "    \n",
    "    ct_path   = case_dir / ct_name\n",
    "    mask_path = case_dir / mask_name\n",
    "    cent_path = case_dir / center_name\n",
    "\n",
    "    if not ct_path.exists():\n",
    "        raise FileNotFoundError(f\"CT not found: {ct_path}\")\n",
    "    if not mask_path.exists():\n",
    "        raise FileNotFoundError(f\"Mask not found: {mask_path}\")\n",
    "    if not cent_path.exists():\n",
    "        raise FileNotFoundError(f\"Centerline not found: {cent_path}\")\n",
    "\n",
    "    ct_nii   = nib.load(str(ct_path))\n",
    "    mask_nii = nib.load(str(mask_path))\n",
    "    cent_nii = nib.load(str(cent_path))\n",
    "\n",
    "    ct   = ct_nii.get_fdata().astype(np.float32)\n",
    "    mask = mask_nii.get_fdata().astype(np.float32)\n",
    "    cent = cent_nii.get_fdata().astype(np.float32)\n",
    "\n",
    "    assert ct.shape == mask.shape == cent.shape, \\\n",
    "        f\"Shape mismatch: ct{ct.shape}, mask{mask.shape}, center{cent.shape}\"\n",
    "\n",
    "    return ct, mask, cent\n",
    "\n",
    "\n",
    "def normalize_ct(ct: np.ndarray, hu_min=-200.0, hu_max=300.0):\n",
    "    ct = np.clip(ct, hu_min, hu_max)\n",
    "    ct = (ct - hu_min) / (hu_max - hu_min + 1e-8)\n",
    "    return ct.astype(np.float32)\n",
    "\n",
    "\n",
    "def get_patch(volume: np.ndarray, center, patch_size=PATCH_SIZE):\n",
    "    \"\"\"\n",
    "    volume: (D,H,W)\n",
    "    center: (z,y,x)\n",
    "    return: (pd,ph,pw)\n",
    "    \"\"\"\n",
    "    D, H, W = volume.shape\n",
    "    pd, ph, pw = patch_size\n",
    "    zc, yc, xc = center\n",
    "\n",
    "    z0, y0, x0 = zc - pd // 2, yc - ph // 2, xc - pw // 2\n",
    "    z1, y1, x1 = z0 + pd, y0 + ph, x0 + pw\n",
    "\n",
    "    patch = np.zeros((pd, ph, pw), dtype=volume.dtype)\n",
    "\n",
    "    z0_src, y0_src, x0_src = max(z0, 0), max(y0, 0), max(x0, 0)\n",
    "    z1_src, y1_src, x1_src = min(z1, D), min(y1, H), min(x1, W)\n",
    "\n",
    "    z0_dst, y0_dst, x0_dst = z0_src - z0, y0_src - y0, x0_src - x0\n",
    "\n",
    "    if z1_src > z0_src and y1_src > y0_src and x1_src > x0_src:\n",
    "        patch[\n",
    "            z0_dst:z0_dst + (z1_src - z0_src),\n",
    "            y0_dst:y0_dst + (y1_src - y0_src),\n",
    "            x0_dst:x0_dst + (x1_src - x0_src),\n",
    "        ] = volume[z0_src:z1_src, y0_src:y1_src, x0_src:x1_src]\n",
    "\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb139e",
   "metadata": {},
   "source": [
    "### Env ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "082496b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2. Centerline RL ÌôòÍ≤Ω\n",
    "# =========================\n",
    "\n",
    "class CTVesselCenterEnv:\n",
    "    def __init__(self, data_root: Path, patch_size=PATCH_SIZE, max_steps=MAX_STEPS):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.patch_size = patch_size\n",
    "        self.max_steps = max_steps\n",
    "        self.brush_radius = BRUSH_RADIUS\n",
    "\n",
    "        self.case_dirs = sorted([p for p in self.data_root.iterdir() if p.is_dir()])\n",
    "        if not self.case_dirs:\n",
    "            raise RuntimeError(f\"No case folders under {self.data_root}\")\n",
    "\n",
    "        # ÎÇ¥Î∂Ä ÏÉÅÌÉú\n",
    "        self.ct = None\n",
    "        self.mask = None\n",
    "        self.centerline = None\n",
    "        self.ct_norm = None\n",
    "\n",
    "        self.visited_vol = None       # ÎÇ¥Í∞Ä Ïπ†Ìïú ÌòàÍ¥Ä ÏòÅÏó≠\n",
    "        self.center_visited = None    # centerline Ï§ë Ïù¥ÎØ∏ Î∞üÏùÄ Í≥≥\n",
    "\n",
    "        self.D = self.H = self.W = None\n",
    "        self.pos = None\n",
    "        self.step_count = 0\n",
    "        self.current_case_dir = None\n",
    "\n",
    "    # ---------------------\n",
    "    # ÎÇ¥Î∂Ä Ìó¨Ìçº\n",
    "    # ---------------------\n",
    "    def _load_random_case(self):\n",
    "        while True:\n",
    "            case_dir = random.choice(self.case_dirs)\n",
    "            try:\n",
    "                ct, mask, cent = load_case_with_centerline(case_dir)\n",
    "            except Exception as e:\n",
    "                print(f\"[Skip] {case_dir.name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            mask_bin = (mask > 0.5).astype(np.uint8)\n",
    "            cent_bin = (cent > 0.5).astype(np.uint8)\n",
    "\n",
    "            if mask_bin.sum() == 0 or cent_bin.sum() == 0:\n",
    "                # ÌòàÍ¥ÄÏù¥ ÏóÜÍ±∞ÎÇò centerline ÎπÑÏñ¥ÏûàÏúºÎ©¥ Ïä§ÌÇµ\n",
    "                continue\n",
    "\n",
    "            self.ct = ct\n",
    "            self.mask = mask_bin\n",
    "            self.centerline = cent_bin\n",
    "            self.ct_norm = normalize_ct(ct)\n",
    "\n",
    "            self.visited_vol = np.zeros_like(self.mask, dtype=np.float32)\n",
    "            self.center_visited = np.zeros_like(self.centerline, dtype=np.float32)\n",
    "\n",
    "            self.D, self.H, self.W = self.ct.shape\n",
    "            self.current_case_dir = case_dir\n",
    "            break\n",
    "\n",
    "    def _sample_start_pos(self):\n",
    "        \"\"\"ÌòàÍ¥Ä ÎÇ¥Î∂Ä ÏïÑÎ¨¥ Í≥≥ÏóêÏÑú ÏãúÏûë (ÎÇòÏ§ëÏóê aorta Ï£ºÎ≥ÄÏúºÎ°ú Ï†úÌïú Í∞ÄÎä•)\"\"\"\n",
    "        vessel_indices = np.argwhere(self.mask > 0)\n",
    "        idx = vessel_indices[np.random.randint(len(vessel_indices))]\n",
    "        return tuple(idx)  # (z,y,x)\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"\n",
    "        state: (2, Dp, Hp, Wp)\n",
    "          ch0: CT normalized\n",
    "          ch1: visited_vol\n",
    "        \"\"\"\n",
    "        ct_patch  = get_patch(self.ct_norm, self.pos, self.patch_size)\n",
    "        vis_patch = get_patch(self.visited_vol, self.pos, self.patch_size)\n",
    "        state = np.stack([ct_patch, vis_patch], axis=0).astype(np.float32)\n",
    "        return state\n",
    "\n",
    "    def _move(self, z, y, x, action: int):\n",
    "        # 6Î∞©Ìñ• (z¬±1, y¬±1, x¬±1)\n",
    "        deltas = [\n",
    "            ( 1,  0,  0),  # +z\n",
    "            (-1,  0,  0),  # -z\n",
    "            ( 0,  1,  0),  # +y\n",
    "            ( 0, -1,  0),  # -y\n",
    "            ( 0,  0,  1),  # +x\n",
    "            ( 0,  0, -1),  # -x\n",
    "        ]\n",
    "        dz, dy, dx = deltas[action]\n",
    "        return z + dz, y + dy, x + dx\n",
    "\n",
    "    def _brush_and_count(self, center_pos):\n",
    "        \"\"\"\n",
    "        Î∏åÎü¨Ïãú ÏòÅÏó≠ ÏïàÏóêÏÑú,\n",
    "        - ÏÉàÎ°ú Ïπ†Ìï¥ÏßÑ ÌòàÍ¥Ä Î≥µÏÖÄ Ïàò Î∞òÌôò\n",
    "        - visited_vol ÏóÖÎç∞Ïù¥Ìä∏\n",
    "        \"\"\"\n",
    "        z, y, x = center_pos\n",
    "        r = self.brush_radius\n",
    "\n",
    "        z_min, z_max = max(0, z-r), min(self.D, z+r+1)\n",
    "        y_min, y_max = max(0, y-r), min(self.H, y+r+1)\n",
    "        x_min, x_max = max(0, x-r), min(self.W, x+r+1)\n",
    "\n",
    "        target_area  = self.mask[z_min:z_max, y_min:y_max, x_min:x_max]\n",
    "        visited_area = self.visited_vol[z_min:z_max, y_min:y_max, x_min:x_max]\n",
    "\n",
    "        newly_mask = (target_area == 1) & (visited_area == 0)\n",
    "        new_voxels = np.sum(newly_mask)\n",
    "\n",
    "        self.visited_vol[z_min:z_max, y_min:y_max, x_min:x_max][newly_mask] = 1.0\n",
    "\n",
    "        return int(new_voxels)\n",
    "\n",
    "    # ---------------------\n",
    "    # Gym Ïä§ÌÉÄÏùº API\n",
    "    # ---------------------\n",
    "    def reset(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "        self._load_random_case()\n",
    "        self.pos = self._sample_start_pos()\n",
    "        self.step_count = 0\n",
    "\n",
    "        # ÏãúÏûë ÏúÑÏπòÎèÑ Ìïú Î≤à Ïπ†Ìï¥ÎëêÍ∏∞\n",
    "        self._brush_and_count(self.pos)\n",
    "\n",
    "        state = self._get_state()\n",
    "        info = {\n",
    "            \"pos\": self.pos,\n",
    "            \"case\": self.current_case_dir.name,\n",
    "        }\n",
    "        return state, info\n",
    "\n",
    "    def step(self, action: int):\n",
    "        z, y, x = self.pos\n",
    "        nz, ny, nx = self._move(z, y, x, action)\n",
    "\n",
    "        # -------- 1) Î≥ºÎ•® Î∞ñ Ï≤¥ÌÅ¨ --------\n",
    "        if not (0 <= nz < self.D and 0 <= ny < self.H and 0 <= nx < self.W):\n",
    "            reward = -1.0\n",
    "            done = True\n",
    "            info = {\n",
    "                \"pos\": (nz, ny, nx),\n",
    "                \"case\": self.current_case_dir.name,\n",
    "                \"inside_vessel\": False,\n",
    "                \"on_centerline\": False,\n",
    "            }\n",
    "            return self._get_state(), reward, done, False, info\n",
    "\n",
    "        # -------- 2) ÌòàÍ¥Ä ÎÇ¥Î∂Ä Ï≤¥ÌÅ¨ --------\n",
    "        inside_vessel = bool(self.mask[nz, ny, nx] > 0)\n",
    "        if not inside_vessel:\n",
    "            reward = -1.0\n",
    "            done = True\n",
    "            info = {\n",
    "                \"pos\": (nz, ny, nx),\n",
    "                \"case\": self.current_case_dir.name,\n",
    "                \"inside_vessel\": False,\n",
    "                \"on_centerline\": False,\n",
    "            }\n",
    "            return self._get_state(), reward, done, False, info\n",
    "\n",
    "        # -------- 3) Î≥¥ÏÉÅ Í≥ÑÏÇ∞ --------\n",
    "        reward = 0.0\n",
    "        done = False\n",
    "\n",
    "        # 3-1. Î∏åÎü¨ÏãúÎ°ú ÏÉàÎ°ú Ïπ†Ìïú ÌòàÍ¥Ä Î≥µÏÖÄ Ïàò\n",
    "        new_voxels = self._brush_and_count((nz, ny, nx))\n",
    "        if new_voxels > 0:\n",
    "            reward += 0.01 * new_voxels  # coverage reward\n",
    "\n",
    "        # 3-2. centerline Î≥¥ÏÉÅ\n",
    "        on_center = bool(self.centerline[nz, ny, nx] > 0)\n",
    "        if on_center:\n",
    "            if self.center_visited[nz, ny, nx] == 0:\n",
    "                # Ï≤òÏùå Î∞üÏùÄ centerline ‚Üí ÌÅ∞ Î≥¥ÏÉÅ\n",
    "                reward += 10.0\n",
    "                self.center_visited[nz, ny, nx] = 1.0\n",
    "            else:\n",
    "                # Ïù¥ÎØ∏ Î∞üÏïòÎçò centerline ‚Üí ÏûëÏùÄ Î≥¥ÏÉÅ\n",
    "                reward += 0.1\n",
    "        else:\n",
    "            # centerlineÏù¥ ÏïÑÎãå Í≥≥ ‚Üí ÏÇ¥Ïßù ÌéòÎÑêÌã∞\n",
    "            reward -= 0.05\n",
    "\n",
    "        self.pos = (nz, ny, nx)\n",
    "        self.step_count += 1\n",
    "\n",
    "        if self.step_count >= self.max_steps:\n",
    "            done = True\n",
    "\n",
    "        info = {\n",
    "            \"pos\": self.pos,\n",
    "            \"case\": self.current_case_dir.name,\n",
    "            \"inside_vessel\": inside_vessel,\n",
    "            \"on_centerline\": on_center,\n",
    "        }\n",
    "\n",
    "        return self._get_state(), reward, done, False, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86d6bf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state shape: (2, 32, 32, 32) case: {'pos': (np.int64(351), np.int64(310), np.int64(164)), 'case': '01011ug_509'}\n",
      "reward: -0.05 done: False info: {'pos': (np.int64(352), np.int64(310), np.int64(164)), 'case': '01011ug_509', 'inside_vessel': True, 'on_centerline': False}\n"
     ]
    }
   ],
   "source": [
    "env = CTVesselCenterEnv(DATA_ROOT)\n",
    "s, info = env.reset()\n",
    "print(\"state shape:\", s.shape, \"case:\", info)\n",
    "\n",
    "next_s, r, done, _, info2 = env.step(0)\n",
    "print(\"reward:\", r, \"done:\", done, \"info:\", info2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c9700",
   "metadata": {},
   "source": [
    "### ÏÑ§Í≥Ñ - 3D DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb6328bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# === 3D CNN Q-network ===\n",
    "class CnnQNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ÏûÖÎ†•:  (B, 2, 32, 32, 32)  # 2Ï±ÑÎÑê (CT, visited)\n",
    "    Ï∂úÎ†•:  (B, 6)              # 6Í∞ú action Ïóê ÎåÄÌïú QÍ∞í\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=2, n_actions=6):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool  = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 32 -> 16 -> 8 -> 4 Î°ú Ï§ÑÏñ¥Îì¶ (pool 3Î≤à)\n",
    "        # ÏµúÏ¢Ö feature map ÌÅ¨Í∏∞: (64, 4, 4, 4)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 2, 32, 32, 32)\n",
    "        x = self.pool(F.relu(self.conv1(x)))   # (B,16,16,16,16)\n",
    "        x = self.pool(F.relu(self.conv2(x)))   # (B,32, 8, 8, 8)\n",
    "        x = self.pool(F.relu(self.conv3(x)))   # (B,64, 4, 4, 4)\n",
    "        x = torch.flatten(x, 1)                # (B, 64*4*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)                        # (B, n_actions)\n",
    "        return x\n",
    "\n",
    "    def sample_action(self, obs_np: np.ndarray, epsilon: float):\n",
    "        \"\"\"\n",
    "        obs_np : numpy state (2, 32, 32, 32)\n",
    "        epsilon: epsilon-greedy ÌÉêÏÉâ ÎπÑÏú®\n",
    "        \"\"\"\n",
    "        # Î¨¥ÏûëÏúÑ ÌÉêÏÉâ\n",
    "        if random.random() < epsilon:\n",
    "            return random.randint(0, self.fc2.out_features - 1)\n",
    "\n",
    "        # greedy action (QÍ∞í Í∏∞Î∞ò)\n",
    "        obs_t = torch.from_numpy(obs_np).float().unsqueeze(0).to(DEVICE)  # (1,2,32,32,32)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.forward(obs_t)  # (1,6)\n",
    "            action = q_values.argmax(dim=1).item()\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43920e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state shape: (2, 32, 32, 32) | case: {'pos': (np.int64(292), np.int64(225), np.int64(256)), 'case': '01015ug_91'}\n",
      "sampled action: 5\n",
      "Q-values shape: torch.Size([1, 6])\n",
      "Q-values: [[-0.00940971 -0.04117823 -0.0544397   0.01041314  0.03447653  0.05736012]]\n"
     ]
    }
   ],
   "source": [
    "# Env Îäî Ïù¥ÎØ∏ ÏúÑÏóêÏÑú ÎßåÎì§Ïñ¥ Îëî Í±∏ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©\n",
    "env = CTVesselCenterEnv(DATA_ROOT)\n",
    "\n",
    "state, info = env.reset()\n",
    "print(\"state shape:\", state.shape, \"| case:\", info)\n",
    "\n",
    "# Q-network ÏÉùÏÑ±\n",
    "q_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "\n",
    "# ÎçîÎØ∏ epsilon-greedy action ÎΩëÍ∏∞\n",
    "epsilon = 0.5\n",
    "action = q_net.sample_action(state, epsilon)\n",
    "print(\"sampled action:\", action)\n",
    "\n",
    "# QÍ∞í ÏßÅÏ†ë ÌôïÏù∏\n",
    "with torch.no_grad():\n",
    "    s_t = torch.from_numpy(state).float().unsqueeze(0).to(DEVICE)\n",
    "    q_values = q_net(s_t)\n",
    "    print(\"Q-values shape:\", q_values.shape)\n",
    "    print(\"Q-values:\", q_values.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e5a2bc",
   "metadata": {},
   "source": [
    "### Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ba84109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "\n",
    "# Î¶¨ÌîåÎ†àÏù¥ Î≤ÑÌçº\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=50_000):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def put(self, transition):\n",
    "        \"\"\"\n",
    "        transition: (state, action, reward, next_state, done_mask)\n",
    "        done_mask: doneÏù¥Î©¥ 0.0, ÏïÑÎãàÎ©¥ 1.0\n",
    "        \"\"\"\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        mini_batch = random.sample(self.buffer, batch_size)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "\n",
    "        for (s, a, r, s_prime, done_mask) in mini_batch:\n",
    "            s_lst.append(s)              # (2,32,32,32) numpy\n",
    "            a_lst.append([a])            # Ï†ïÏàò action -> (1,) ÌòïÌÉú\n",
    "            r_lst.append([r])            # Ïä§ÏπºÎùº reward\n",
    "            s_prime_lst.append(s_prime)  # Îã§Ïùå state\n",
    "            done_mask_lst.append([done_mask])\n",
    "\n",
    "        s      = torch.tensor(np.array(s_lst),      dtype=torch.float32, device=DEVICE)\n",
    "        a      = torch.tensor(a_lst,                dtype=torch.int64,   device=DEVICE)\n",
    "        r      = torch.tensor(r_lst,                dtype=torch.float32, device=DEVICE)\n",
    "        sPrime = torch.tensor(np.array(s_prime_lst),dtype=torch.float32, device=DEVICE)\n",
    "        d_mask = torch.tensor(done_mask_lst,        dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "        return s, a, r, sPrime, d_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7660a967",
   "metadata": {},
   "source": [
    "### DQN ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f60c4f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### test ÏΩîÎìú\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "GAMMA      = 0.99\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def train_dqn(q_net, target_net, memory, optimizer, batch_size=BATCH_SIZE, gamma=GAMMA):\n",
    "    \"\"\"\n",
    "    Î¶¨ÌîåÎ†àÏù¥ Î≤ÑÌçºÏóêÏÑú ÎØ∏ÎãàÎ∞∞ÏπòÎ•º Í∫ºÎÇ¥ÏÑú\n",
    "    DQN lossÎ•º Í≥ÑÏÇ∞ÌïòÍ≥† Ìïú Î≤à gradient step ÌïòÎäî Ìï®Ïàò.\n",
    "    \"\"\"\n",
    "    if memory.size() < batch_size:\n",
    "        return None  # ÏÉòÌîåÏù¥ ÏïÑÏßÅ Î∂ÄÏ°±ÌïòÎ©¥ ÌïôÏäµÌïòÏßÄ ÏïäÏùå\n",
    "\n",
    "    s, a, r, s_prime, done_mask = memory.sample(batch_size)\n",
    "\n",
    "    # ÌòÑÏû¨ Q(s,a)\n",
    "    q_out = q_net(s)              # (B, n_actions)\n",
    "    q_a   = q_out.gather(1, a)    # (B, 1)\n",
    "\n",
    "    # ÌÉÄÍπÉ Q = r + gamma * max_a' Q_target(s', a') * done_mask\n",
    "    with torch.no_grad():\n",
    "        max_q_prime = target_net(s_prime).max(1, keepdim=True)[0]  # (B,1)\n",
    "        target = r + gamma * max_q_prime * done_mask               # (B,1)\n",
    "\n",
    "    loss = F.smooth_l1_loss(q_a, target)  # Huber loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eaec4b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer size after rollout: 50\n",
      "One training step loss: 0.371529757976532\n"
     ]
    }
   ],
   "source": [
    "# 1) ÌôòÍ≤Ω & ÎÑ§Ìä∏ÏõåÌÅ¨ & Î≤ÑÌçº & ÏòµÌã∞ÎßàÏù¥Ï†Ä Ï§ÄÎπÑ\n",
    "env = CTVesselCenterEnv(DATA_ROOT)\n",
    "q_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "target_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "memory = ReplayBuffer(capacity=50_000)\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=1e-4)\n",
    "\n",
    "# 2) ÌôòÍ≤ΩÏóêÏÑú Î™á Ïä§ÌÖù Íµ¥Î¶¨Î©¥ÏÑú Î≤ÑÌçº Ï±ÑÏö∞Í∏∞\n",
    "state, info = env.reset()\n",
    "epsilon = 1.0  # Ï¥àÎ∞òÏóî ÎûúÎç§ÌïòÍ≤å ÎßéÏù¥ ÌÉêÏÉâ\n",
    "\n",
    "for t in range(50):   # 50 step Ï†ïÎèÑÎßå\n",
    "    action = q_net.sample_action(state, epsilon)\n",
    "    next_state, reward, done, _, _ = env.step(action)\n",
    "\n",
    "    done_mask = 0.0 if done else 1.0\n",
    "    memory.put((state, action, reward, next_state, done_mask))\n",
    "\n",
    "    state = next_state\n",
    "    if done:\n",
    "        state, info = env.reset()\n",
    "\n",
    "print(\"Buffer size after rollout:\", memory.size())\n",
    "\n",
    "# 3) DQN Ìïú Î≤à ÏóÖÎç∞Ïù¥Ìä∏\n",
    "loss_val = train_dqn(q_net, target_net, memory, optimizer)\n",
    "\n",
    "print(\"One training step loss:\", loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7f428a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ÌïòÏù¥Ìçº ÌååÎùºÎØ∏ÌÑ∞ Î∞è Î©îÏù∏ ÌïôÏäµ Î£®ÌîÑ\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# ==== ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ====\n",
    "NUM_EPISODES      = 200          # Ï†ÑÏ≤¥ ÏóêÌîºÏÜåÎìú Ïàò\n",
    "MAX_STEPS_PER_EP  = 1000         # ÏóêÌîºÏÜåÎìúÎãπ ÏµúÎåÄ Ïä§ÌÖù\n",
    "EPS_START         = 1.0          # epsilon ÏãúÏûëÍ∞í\n",
    "EPS_END           = 0.05         # epsilon ÏµúÏÜåÍ∞í\n",
    "EPS_DECAY         = 0.99         # Îß§ ÏóêÌîºÏÜåÎìú ÌõÑ epsilon *= EPS_DECAY\n",
    "TARGET_UPDATE_INT = 5           # ÌÉÄÍπÉ ÎÑ§Ìä∏ÏõåÌÅ¨ ÏóÖÎç∞Ïù¥Ìä∏ Ï£ºÍ∏∞ (ÏóêÌîºÏÜåÎìú Îã®ÏúÑ)\n",
    "PRINT_INTERVAL    = 5           # Î°úÍ∑∏ Ï∂úÎ†• Ï£ºÍ∏∞\n",
    "\n",
    "\n",
    "def train_vessel_dqn_centerline(\n",
    "    num_episodes=NUM_EPISODES,\n",
    "    max_steps_per_ep=MAX_STEPS_PER_EP,\n",
    "):\n",
    "    # 1) ÌôòÍ≤Ω, ÎÑ§Ìä∏ÏõåÌÅ¨, Î≤ÑÌçº, ÏòµÌã∞ÎßàÏù¥Ï†Ä Ï§ÄÎπÑ\n",
    "    env = CTVesselCenterEnv(DATA_ROOT)\n",
    "\n",
    "    q_net      = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "    target_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    memory    = ReplayBuffer(capacity=50_000)\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=1e-4)\n",
    "\n",
    "    epsilon = EPS_START\n",
    "\n",
    "    print(\">>> Training started...\")\n",
    "    reward_history = []\n",
    "\n",
    "    for ep in range(1, num_episodes + 1):\n",
    "        state, info = env.reset()\n",
    "        ep_reward = 0.0\n",
    "        ep_steps  = 0\n",
    "        last_info = info\n",
    "\n",
    "        while True:\n",
    "            # 1) epsilon-greedy ÌñâÎèô ÏÑ†ÌÉù\n",
    "            action = q_net.sample_action(state, epsilon)\n",
    "\n",
    "            # 2) ÌôòÍ≤Ω Ìïú Ïä§ÌÖù ÏßÑÌñâ\n",
    "            next_state, reward, done, _, step_info = env.step(action)\n",
    "            last_info = step_info  # ÎßàÏßÄÎßâ stepÏùò case Ï†ïÎ≥¥Ïö©\n",
    "\n",
    "            # 3) transition Î≤ÑÌçºÏóê Ï†ÄÏû•\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "            memory.put((state, action, reward, next_state, done_mask))\n",
    "\n",
    "            state = next_state\n",
    "            ep_reward += reward\n",
    "            ep_steps  += 1\n",
    "\n",
    "            # 4) DQN ÏóÖÎç∞Ïù¥Ìä∏ (Í≤ΩÌóòÏù¥ Ïñ¥Îäê Ï†ïÎèÑ ÏåìÏù¥Î©¥)\n",
    "            train_dqn(q_net, target_net, memory, optimizer)\n",
    "\n",
    "            # 5) ÏóêÌîºÏÜåÎìú Ï¢ÖÎ£å Ï°∞Í±¥\n",
    "            if done or ep_steps >= max_steps_per_ep:\n",
    "                break\n",
    "\n",
    "        # 6) epsilon decay\n",
    "        epsilon = max(EPS_END, epsilon * EPS_DECAY)\n",
    "\n",
    "        # 7) ÌÉÄÍπÉ ÎÑ§Ìä∏ÏõåÌÅ¨ ÎèôÍ∏∞Ìôî\n",
    "        if ep % TARGET_UPDATE_INT == 0:\n",
    "            target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "        reward_history.append(ep_reward)\n",
    "\n",
    "        # 8) Î°úÍ∑∏ Ï∂úÎ†•\n",
    "        if ep % PRINT_INTERVAL == 0:\n",
    "            case_name = last_info.get(\"case\", \"NA\") if isinstance(last_info, dict) else \"NA\"\n",
    "            avg_recent = sum(reward_history[-PRINT_INTERVAL:]) / len(reward_history[-PRINT_INTERVAL:])\n",
    "            print(\n",
    "                f\"[Ep {ep:03d}] \"\n",
    "                f\"reward={ep_reward:7.1f} (avg {avg_recent:6.1f}), \"\n",
    "                f\"steps={ep_steps:4d}, \"\n",
    "                f\"eps={epsilon:4.2f}, \"\n",
    "                f\"buffer={memory.size():5d}, \"\n",
    "                f\"case={case_name}\"\n",
    "            )\n",
    "\n",
    "    print(\">>> Training finished!\")\n",
    "    return q_net, target_net, env, reward_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd366eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Training started...\n",
      "[Ep 005] reward=   -1.1 (avg   29.7), steps=   2, eps=0.95, buffer=  839, case=01015ug_91\n",
      "[Ep 010] reward=   10.6 (avg   74.7), steps=  60, eps=0.90, buffer= 1305, case=01015ug_91\n",
      "[Ep 015] reward=   62.8 (avg   34.2), steps= 278, eps=0.86, buffer= 1928, case=01018ug_97\n",
      "[Ep 020] reward=   17.3 (avg   44.5), steps=  50, eps=0.82, buffer= 2517, case=01015ug_72\n",
      "[Ep 025] reward=    0.8 (avg   33.9), steps=   9, eps=0.78, buffer= 2919, case=01011ug_530\n",
      "[Ep 030] reward=  122.7 (avg   60.4), steps= 232, eps=0.74, buffer= 3502, case=01011ug_515\n",
      "[Ep 035] reward=   48.0 (avg   32.5), steps= 107, eps=0.70, buffer= 3865, case=01010ug_133\n",
      "[Ep 040] reward=  281.4 (avg  129.9), steps= 547, eps=0.67, buffer= 4990, case=01011ug_501\n",
      "[Ep 045] reward=  262.6 (avg  135.4), steps= 566, eps=0.64, buffer= 6265, case=01011ug_508\n",
      "[Ep 050] reward=  483.2 (avg  395.6), steps= 729, eps=0.61, buffer= 9305, case=01010ug_174\n",
      "[Ep 055] reward=  776.1 (avg  497.2), steps=1000, eps=0.58, buffer=13415, case=01011ug_509\n",
      "[Ep 060] reward=   -0.2 (avg  127.9), steps=   3, eps=0.55, buffer=14257, case=01011ug_522\n",
      "[Ep 065] reward=    8.7 (avg  469.2), steps=   8, eps=0.52, buffer=17737, case=01015ug_91\n",
      "[Ep 070] reward=  535.2 (avg  343.9), steps= 765, eps=0.49, buffer=19818, case=01011ug_527\n",
      "[Ep 075] reward=  437.9 (avg  466.5), steps= 507, eps=0.47, buffer=22931, case=01010ug_135\n",
      "[Ep 080] reward=   -1.0 (avg  371.1), steps=   1, eps=0.45, buffer=25817, case=01010ug_136\n",
      "[Ep 085] reward=  303.9 (avg  200.6), steps= 338, eps=0.43, buffer=27301, case=01015ug_72\n",
      "[Ep 090] reward=  309.9 (avg  213.4), steps= 592, eps=0.40, buffer=28959, case=01010ug_169\n",
      "[Ep 095] reward=  722.0 (avg  558.0), steps= 692, eps=0.38, buffer=33128, case=01018ug_79\n",
      "[Ep 100] reward=  879.8 (avg  478.3), steps=1000, eps=0.37, buffer=36725, case=01015ug_76\n",
      "[Ep 105] reward=  664.6 (avg  216.9), steps=1000, eps=0.35, buffer=38641, case=01018ug_81\n",
      "[Ep 110] reward=  158.6 (avg  318.3), steps=1000, eps=0.33, buffer=40927, case=01011ug_523\n",
      "[Ep 115] reward=  644.3 (avg  602.5), steps=1000, eps=0.31, buffer=44618, case=01010ug_166\n",
      "[Ep 120] reward=  160.0 (avg  346.6), steps= 345, eps=0.30, buffer=47561, case=01010ug_164\n",
      "[Ep 125] reward=  298.7 (avg  438.2), steps= 786, eps=0.28, buffer=50000, case=01015ug_90\n",
      "[Ep 130] reward=   10.0 (avg  238.0), steps=  67, eps=0.27, buffer=50000, case=01010ug_166\n",
      "[Ep 135] reward=  400.5 (avg  560.3), steps= 629, eps=0.26, buffer=50000, case=01011ug_500\n",
      "[Ep 140] reward=  621.8 (avg  440.0), steps=1000, eps=0.24, buffer=50000, case=01011ug_513\n",
      "[Ep 145] reward=   75.0 (avg  430.3), steps=1000, eps=0.23, buffer=50000, case=01011ug_508\n",
      "[Ep 150] reward=   -1.0 (avg  304.0), steps=   1, eps=0.22, buffer=50000, case=01010ug_176\n",
      "[Ep 155] reward=   31.0 (avg  333.9), steps=  35, eps=0.21, buffer=50000, case=01015ug_90\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m q_net, target_net, env, reward_hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_vessel_dqn_centerline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNUM_EPISODES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps_per_ep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMAX_STEPS_PER_EP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 57\u001b[0m, in \u001b[0;36mtrain_vessel_dqn_centerline\u001b[0;34m(num_episodes, max_steps_per_ep)\u001b[0m\n\u001b[1;32m     54\u001b[0m ep_steps  \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# 4) DQN ÏóÖÎç∞Ïù¥Ìä∏ (Í≤ΩÌóòÏù¥ Ïñ¥Îäê Ï†ïÎèÑ ÏåìÏù¥Î©¥)\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[43mtrain_dqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# 5) ÏóêÌîºÏÜåÎìú Ï¢ÖÎ£å Ï°∞Í±¥\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done \u001b[38;5;129;01mor\u001b[39;00m ep_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_steps_per_ep:\n",
      "Cell \u001b[0;32mIn[45], line 34\u001b[0m, in \u001b[0;36mtrain_dqn\u001b[0;34m(q_net, target_net, memory, optimizer, batch_size, gamma)\u001b[0m\n\u001b[1;32m     31\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "q_net, target_net, env, reward_hist = train_vessel_dqn_centerline(\n",
    "    num_episodes = NUM_EPISODES,\n",
    "    max_steps_per_ep = MAX_STEPS_PER_EP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36448143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!\n"
     ]
    }
   ],
   "source": [
    "torch.save(q_net.state_dict(), \"checkpoint_centerline.pth\")\n",
    "print(\"saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "febcf85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ trained weights loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#### ÌïôÏäµÎêú Í∞ÄÏ§ëÏπò Î∂àÎü¨Ïò§Í∏∞ ÌÖåÏä§Ìä∏\n",
    "# 1) Î™®Îç∏ ÏÉùÏÑ±\n",
    "q_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "\n",
    "# 2) Ï†ÄÏû•Îêú Í∞ÄÏ§ëÏπò Î°úÎìú\n",
    "state_dict = torch.load(\"checkpoint_centerline.pth\", map_location=DEVICE)\n",
    "q_net.load_state_dict(state_dict)\n",
    "\n",
    "# 3) inference Î™®Îìú ÏÑ§Ï†ï\n",
    "q_net.eval()\n",
    "\n",
    "print(\"‚úÖ trained weights loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9ce362e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[plot] case=01015ug_100, traj_len=8\n",
      "  ‚Üí saved: results/traj_10cases/traj_00_01015ug_100.png\n",
      "[plot] case=01011ug_527, traj_len=16\n",
      "  ‚Üí saved: results/traj_10cases/traj_01_01011ug_527.png\n",
      "[plot] case=01011ug_508, traj_len=9\n",
      "  ‚Üí saved: results/traj_10cases/traj_02_01011ug_508.png\n",
      "[plot] case=01010ug_1, traj_len=2\n",
      "  ‚Üí saved: results/traj_10cases/traj_03_01010ug_1.png\n",
      "[plot] case=01018ug_86, traj_len=2\n",
      "  ‚Üí saved: results/traj_10cases/traj_04_01018ug_86.png\n",
      "[plot] case=01018ug_90, traj_len=27\n",
      "  ‚Üí saved: results/traj_10cases/traj_05_01018ug_90.png\n",
      "[plot] case=01011ug_516, traj_len=24\n",
      "  ‚Üí saved: results/traj_10cases/traj_06_01011ug_516.png\n",
      "[plot] case=01010ug_172, traj_len=11\n",
      "  ‚Üí saved: results/traj_10cases/traj_07_01010ug_172.png\n",
      "[plot] case=01015ug_89, traj_len=5\n",
      "  ‚Üí saved: results/traj_10cases/traj_08_01015ug_89.png\n",
      "[plot] case=01011ug_526, traj_len=4\n",
      "  ‚Üí saved: results/traj_10cases/traj_09_01011ug_526.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1) greedy rollout (Œµ=0) Î°ú Ìïú ÏºÄÏù¥Ïä§ÏóêÏÑú trajectory ÎΩëÍ∏∞\n",
    "# --------------------------------------------------\n",
    "def rollout_greedy(env, q_net, max_steps=500):\n",
    "    \"\"\"\n",
    "    env  : CTVesselCenterEnv (Ïù¥ÎØ∏ DATA_ROOT Î°ú ÎßåÎì§Ïñ¥Ï†∏ ÏûàÎã§Í≥† Í∞ÄÏ†ï)\n",
    "    q_net: ÌïôÏäµÎêú CnnQNet (Í∞ÄÏ§ëÏπò load ÏôÑÎ£å ÏÉÅÌÉú)\n",
    "    \"\"\"\n",
    "    state, info = env.reset()          # ÎûúÎç§ ÏºÄÏù¥Ïä§ ÌïòÎÇò ÏÑ†ÌÉù + ÏãúÏûëÏ†ê ÏÉòÌîå\n",
    "    traj = [tuple(info[\"pos\"])]        # (z, y, x)\n",
    "    done = False\n",
    "    steps = 0\n",
    "\n",
    "    while not done and steps < max_steps:\n",
    "        action = q_net.sample_action(state, epsilon=0.0)  # ÏàúÏàò greedy\n",
    "        state, reward, done, _, info2 = env.step(action)\n",
    "        traj.append(tuple(info2[\"pos\"]))\n",
    "        steps += 1\n",
    "\n",
    "    traj = np.array(traj)\n",
    "    return traj, info\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2) centerline + trajectory 3D plot (Ìïú ÏºÄÏù¥Ïä§)\n",
    "# --------------------------------------------------\n",
    "def plot_centerline_trajectory(env, q_net,\n",
    "                               max_steps=500,\n",
    "                               local_only=True,\n",
    "                               pad=40):\n",
    "    \"\"\"\n",
    "    local_only=True  : trajectory Ï£ºÎ≥ÄÎßå ÏûòÎùºÏÑú centerline ÌëúÏãú\n",
    "    local_only=False : Ï†ÑÏ≤¥ centerline ÌëúÏãú\n",
    "    \"\"\"\n",
    "    traj, info0 = rollout_greedy(env, q_net, max_steps=max_steps)\n",
    "    case_name = info0[\"case\"]\n",
    "\n",
    "    # env ÏïàÏóê ÏûàÎäî centerline Î≥ºÎ•® Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "    centerline_vol = getattr(env, \"centerline_vol\", env.centerline)\n",
    "    cl_idx = np.argwhere(centerline_vol > 0)   # (Nc, 3) : (z, y, x)\n",
    "\n",
    "    # ---- trajectory Ï£ºÎ≥ÄÎßå Î≥¥Í∏∞ ÏòµÏÖò ----\n",
    "    if local_only:\n",
    "        z_min, y_min, x_min = traj.min(axis=0) - pad\n",
    "        z_max, y_max, x_max = traj.max(axis=0) + pad\n",
    "\n",
    "        mask = (\n",
    "            (cl_idx[:, 0] >= z_min) & (cl_idx[:, 0] <= z_max) &\n",
    "            (cl_idx[:, 1] >= y_min) & (cl_idx[:, 1] <= y_max) &\n",
    "            (cl_idx[:, 2] >= x_min) & (cl_idx[:, 2] <= x_max)\n",
    "        )\n",
    "        cl_plot = cl_idx[mask]\n",
    "    else:\n",
    "        cl_plot = cl_idx\n",
    "\n",
    "    # ---- 3D figure ÏÉùÏÑ± ----\n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # centerline (ÏòÖÏùÄ Ï†ê)\n",
    "    if len(cl_plot) > 0:\n",
    "        ax.scatter(\n",
    "            cl_plot[:, 2], cl_plot[:, 1], cl_plot[:, 0],\n",
    "            s=1, alpha=0.05, label=\"centerline\"\n",
    "        )\n",
    "\n",
    "    # trajectory (ÍµµÏùÄ ÏÑ†)\n",
    "    ax.plot(\n",
    "        traj[:, 2], traj[:, 1], traj[:, 0],\n",
    "        linewidth=3, color=\"blue\", label=\"trajectory\"\n",
    "    )\n",
    "\n",
    "    # ÏãúÏûë / ÎÅùÏ†ê\n",
    "    ax.scatter(traj[0, 2],  traj[0, 1],  traj[0, 0],\n",
    "               s=40, c=\"green\", label=\"start\")\n",
    "    ax.scatter(traj[-1, 2], traj[-1, 1], traj[-1, 0],\n",
    "               s=40, c=\"red\",   label=\"end\")\n",
    "\n",
    "    ax.set_xlabel(\"x (col)\")\n",
    "    ax.set_ylabel(\"y (row)\")\n",
    "    ax.set_zlabel(\"z (slice)\")\n",
    "    ax.set_title(f\"3D trajectory on centerline | case {case_name}, len={len(traj)}\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    print(f\"[plot] case={case_name}, traj_len={len(traj)}\")\n",
    "    return fig, case_name\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3) ÎûúÎç§ 10ÏºÄÏù¥Ïä§ ÏãúÍ∞ÅÌôî + PNG Ï†ÄÏû•\n",
    "# --------------------------------------------------\n",
    "def visualize_random_cases(env, q_net,\n",
    "                           num_cases=10,\n",
    "                           max_steps=500,\n",
    "                           save_dir=\"results/traj_10cases\",\n",
    "                           local_only=True):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for i in range(num_cases):\n",
    "        fig, case_name = plot_centerline_trajectory(\n",
    "            env, q_net,\n",
    "            max_steps=max_steps,\n",
    "            local_only=local_only\n",
    "        )\n",
    "\n",
    "        # ÌååÏùº Ïù¥Î¶Ñ: traj_00_ÏºÄÏù¥Ïä§Ïù¥Î¶Ñ.png Ïù¥Îü∞ ÏãùÏúºÎ°ú Ï†ÄÏû•\n",
    "        save_path = os.path.join(save_dir, f\"traj_{i:02d}_{case_name}.png\")\n",
    "        fig.savefig(save_path, dpi=150)\n",
    "        plt.close(fig)\n",
    "        print(f\"  ‚Üí saved: {save_path}\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4) Ïã§Ï†ú Ïã§Ìñâ\n",
    "#    (q_net, env Îäî Ïù¥ÎØ∏ ÏúÑÏóêÏÑú ÏÉùÏÑ± + Í∞ÄÏ§ëÏπò load Í∞Ä ÎÅùÎÇú ÏÉÅÌÉúÎùºÍ≥† Í∞ÄÏ†ï)\n",
    "# --------------------------------------------------\n",
    "visualize_random_cases(\n",
    "    env,\n",
    "    q_net,\n",
    "    num_cases=10,          # Î≥¥Í≥† Ïã∂ÏùÄ ÏºÄÏù¥Ïä§ Ïàò\n",
    "    max_steps=500,         # Ìïú trajectory ÏµúÎåÄ Í∏∏Ïù¥\n",
    "    save_dir=\"results/traj_10cases\",\n",
    "    local_only=True        # Ï£ºÎ≥ÄÎßå Î≥ºÏßÄ / Ï†ÑÏ≤¥ centerline Î≥ºÏßÄ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2686e152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06144293 -0.05346137  0.00885756  0.04749939 -0.02548346  0.02451901]]\n"
     ]
    }
   ],
   "source": [
    "state, _ = env.reset()\n",
    "q_values = q_net(torch.from_numpy(state).float().unsqueeze(0).to(DEVICE))\n",
    "print(q_values.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76f395ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy best action counts: Counter({0: 98, 3: 2})\n"
     ]
    }
   ],
   "source": [
    "# Ïó¨Îü¨ stateÏóêÏÑú QÍ∞í Ìå®ÌÑ¥Ïù¥ ÎòëÍ∞ôÏùÄÏßÄ Î≥¥Í∏∞\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "best_actions = []\n",
    "for _ in range(100):\n",
    "    s, _ = env.reset()\n",
    "    q = q_net(torch.from_numpy(s).float().unsqueeze(0).to(DEVICE))\n",
    "    a = q.argmax(dim=1).item()\n",
    "    best_actions.append(a)\n",
    "\n",
    "print(\"greedy best action counts:\", Counter(best_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ef7c3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy counts (Í≥†Ï†ï state): [   0    0    0 1000    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Í≥†Ï†ïÎêú ÏÉÅÌÉúÏóêÏÑú greedy action Î∂ÑÌè¨ ÌôïÏù∏\n",
    "counts = np.zeros(6, dtype=int)\n",
    "s, _ = env.reset()\n",
    "for _ in range(1000):\n",
    "    a = q_net.sample_action(s, epsilon=0.0)\n",
    "    counts[a] += 1\n",
    "print(\"greedy counts (Í≥†Ï†ï state):\", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf919b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained: [[ 0.06249352 -0.05253318  0.00406158  0.04704229 -0.02798536  0.02615421]]\n",
      "random : [[-0.03136034  0.02224334  0.02839084  0.06291301  0.05760475  0.01807821]]\n"
     ]
    }
   ],
   "source": [
    "# Í∞ôÏùÄ Íµ¨Ï°∞Ïùò ÎûúÎç§ Ï¥àÍ∏∞Ìôî ÎÑ§Ìä∏ÏõåÌÅ¨\n",
    "rand_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "s, _ = env.reset()\n",
    "\n",
    "q_trained = q_net(torch.from_numpy(s).float().unsqueeze(0).to(DEVICE))\n",
    "q_random  = rand_net(torch.from_numpy(s).float().unsqueeze(0).to(DEVICE))\n",
    "\n",
    "print(\"trained:\", q_trained.cpu().detach().numpy())\n",
    "print(\"random :\", q_random.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a7daf",
   "metadata": {},
   "source": [
    "## 04. CNN Íµ¨Ï°∞ Î≥ÄÍ≤Ω Î∞è sparse Ìïú reward ÏàòÏ†ï\n",
    "- centerline Î∞©Ìñ•Í≥º action Î∞©Ìñ•Ïóê Îî∞Î•∏ cos similarity Í∏∞Î∞ò reward Ï∂îÍ∞Ä "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c112cf86",
   "metadata": {},
   "source": [
    "### Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cc3ad61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï¥ù ÏºÄÏù¥Ïä§ Ïàò: 99\n",
      "train:  69Í∞ú ‚Üí /Users/srpark/Projects/RL_project/data/processed/RL_cleaned/splits/train.txt\n",
      "  val:  14Í∞ú ‚Üí /Users/srpark/Projects/RL_project/data/processed/RL_cleaned/splits/val.txt\n",
      " test:  16Í∞ú ‚Üí /Users/srpark/Projects/RL_project/data/processed/RL_cleaned/splits/test.txt\n",
      "\n",
      "ÏòàÏãú train 5Í∞ú: ['01018ug_73', '01011ug_506', '01015ug_89', '01015ug_100', '01015ug_72']\n",
      "ÏòàÏãú  val 5Í∞ú: ['01018ug_86', '01018ug_72', '01018ug_87', '01010ug_8', '01018ug_85']\n",
      "ÏòàÏãú test 5Í∞ú: ['01010ug_136', '01010ug_170', '01011ug_528', '01018ug_88', '01010ug_166']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "DATA_ROOT = Path(\"/Users/srpark/Projects/RL_project/data/processed/RL_cleaned\")\n",
    "SPLIT_DIR = DATA_ROOT / \"splits\"\n",
    "SPLIT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "CT_NAME   = \"ct.nii.gz\"\n",
    "MASK_NAME = \"whole_artery_cleaned.nii.gz\"\n",
    "\n",
    "def create_splits(\n",
    "    data_root: Path,\n",
    "    train_ratio: float = 0.7,\n",
    "    val_ratio: float = 0.15,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    CT/mask ÌååÏùºÏù¥ ÏûàÎäî Ìè¥ÎçîÎßå ÏºÄÏù¥Ïä§Î°ú Î≥¥Í≥† train/val/test split ÏÉùÏÑ±\n",
    "    \"\"\"\n",
    "    # üîç 1) ÏºÄÏù¥Ïä§ Ìè¥Îçî ÏàòÏßë (ct + mask ÏûàÎäî Ìè¥ÎçîÎßå)\n",
    "    case_dirs = []\n",
    "    for d in data_root.iterdir():\n",
    "        if not d.is_dir():\n",
    "            continue\n",
    "        ct_path   = d / CT_NAME\n",
    "        mask_path = d / MASK_NAME\n",
    "        if ct_path.exists() and mask_path.exists():\n",
    "            case_dirs.append(d)\n",
    "\n",
    "    case_dirs = sorted(case_dirs)\n",
    "    case_names = [d.name for d in case_dirs]\n",
    "    print(f\"Ï¥ù ÏºÄÏù¥Ïä§ Ïàò: {len(case_names)}\")\n",
    "\n",
    "    # 2) ÏÖîÌîå\n",
    "    random.seed(seed)\n",
    "    random.shuffle(case_names)\n",
    "\n",
    "    # 3) ÎπÑÏú®ÎåÄÎ°ú ÎÇòÎàÑÍ∏∞\n",
    "    n_total = len(case_names)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val   = int(n_total * val_ratio)\n",
    "\n",
    "    train_ids = case_names[:n_train]\n",
    "    val_ids   = case_names[n_train:n_train+n_val]\n",
    "    test_ids  = case_names[n_train+n_val:]\n",
    "\n",
    "    # 4) Ï†ÄÏû•\n",
    "    def _save(split_name, ids):\n",
    "        path = SPLIT_DIR / f\"{split_name}.txt\"\n",
    "        with open(path, \"w\") as f:\n",
    "            for cid in ids:\n",
    "                f.write(cid + \"\\n\")\n",
    "        print(f\"{split_name:>5}: {len(ids):3d}Í∞ú ‚Üí {path}\")\n",
    "\n",
    "    _save(\"train\", train_ids)\n",
    "    _save(\"val\",   val_ids)\n",
    "    _save(\"test\",  test_ids)\n",
    "\n",
    "    return train_ids, val_ids, test_ids\n",
    "\n",
    "# Îã§Ïãú ÏÉùÏÑ±\n",
    "train_ids, val_ids, test_ids = create_splits(DATA_ROOT, train_ratio=0.7, val_ratio=0.15, seed=2025)\n",
    "\n",
    "print(\"\\nÏòàÏãú train 5Í∞ú:\", train_ids[:5])\n",
    "print(\"ÏòàÏãú  val 5Í∞ú:\", val_ids[:5])\n",
    "print(\"ÏòàÏãú test 5Í∞ú:\", test_ids[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd55fb7",
   "metadata": {},
   "source": [
    "### Í∏∞Î≥∏ÏÑ§Ï†ï / Îç∞Ïù¥ÌÑ∞ import / CT Ï†ÑÏ≤òÎ¶¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bfa1a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.9.1\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. Import & Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
    "# ============================================================\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "\n",
    "# ----- Îç∞Ïù¥ÌÑ∞ / split Í≤ΩÎ°ú -----\n",
    "DATA_ROOT = Path(\"/Users/srpark/Projects/RL_project/data/processed/RL_cleaned\")  # ‚úÖ ÌïÑÏöîÌïòÎ©¥ Ïó¨Í∏∞Îßå ÏàòÏ†ï\n",
    "SPLIT_DIR = DATA_ROOT / \"splits\"  # train.txt, val.txt, test.txt Í∞Ä ÏûàÎäî Ìè¥Îçî\n",
    "\n",
    "CT_NAME        = \"ct.nii.gz\"\n",
    "MASK_NAME      = \"whole_artery_cleaned.nii.gz\"\n",
    "CENTERLINE_NAME = \"centerline.nii.gz\"\n",
    "\n",
    "# ----- Device ÏÑ†ÌÉù -----\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b17cfda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. split Î°ú case Î™©Î°ù ÏùΩÍ∏∞\n",
    "# ============================================================\n",
    "\n",
    "def read_split_ids(split_dir: Path, split_name: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    split_name: 'train' / 'val' / 'test'\n",
    "    txt ÌååÏùºÏóêÏÑú case_id Î¶¨Ïä§Ìä∏Î•º ÏùΩÏñ¥Ïò¥.\n",
    "    \"\"\"\n",
    "    path = split_dir / f\"{split_name}.txt\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"{path} not found\")\n",
    "\n",
    "    ids = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                ids.append(line)\n",
    "    return ids\n",
    "\n",
    "\n",
    "def get_case_dirs(data_root: Path, case_ids: List[str]) -> List[Path]:\n",
    "    case_dirs = []\n",
    "    for cid in case_ids:\n",
    "        cdir = data_root / cid\n",
    "        if not cdir.is_dir():\n",
    "            print(f\"‚ö†Ô∏è case dir missing: {cdir}\")\n",
    "            continue\n",
    "        case_dirs.append(cdir)\n",
    "    return case_dirs\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. NIfTI Î°úÎî© & Ï†ÑÏ≤òÎ¶¨ Ïú†Ìã∏\n",
    "# ============================================================\n",
    "\n",
    "def load_case(case_dir: Path,\n",
    "              ct_name: str = CT_NAME,\n",
    "              mask_name: str = MASK_NAME,\n",
    "              center_name: str = CENTERLINE_NAME):\n",
    "    \"\"\"ct / mask / centerline NIfTIÎ•º Î™®Îëê ÏùΩÏñ¥Ïò¥.\"\"\"\n",
    "    ct_path   = case_dir / ct_name\n",
    "    mask_path = case_dir / mask_name\n",
    "    ctr_path  = case_dir / center_name\n",
    "\n",
    "    if not ct_path.exists():   raise FileNotFoundError(ct_path)\n",
    "    if not mask_path.exists(): raise FileNotFoundError(mask_path)\n",
    "    if not ctr_path.exists():  raise FileNotFoundError(ctr_path)\n",
    "\n",
    "    ct_nii   = nib.load(str(ct_path))\n",
    "    mask_nii = nib.load(str(mask_path))\n",
    "    ctr_nii  = nib.load(str(ctr_path))\n",
    "\n",
    "    ct   = ct_nii.get_fdata().astype(np.float32)\n",
    "    mask = mask_nii.get_fdata().astype(np.float32)\n",
    "    ctr  = ctr_nii.get_fdata().astype(np.float32)\n",
    "\n",
    "    assert ct.shape == mask.shape == ctr.shape, f\"shape mismatch in {case_dir.name}\"\n",
    "\n",
    "    return ct, mask, ctr\n",
    "\n",
    "\n",
    "def normalize_ct(ct: np.ndarray, hu_min=-200.0, hu_max=300.0) -> np.ndarray:\n",
    "    \"\"\"HU windowing ‚Üí 0~1\"\"\"\n",
    "    ct = np.clip(ct, hu_min, hu_max)\n",
    "    ct = (ct - hu_min) / (hu_max - hu_min + 1e-8)\n",
    "    return ct.astype(np.float32)\n",
    "\n",
    "\n",
    "def get_patch(volume: np.ndarray, center: Tuple[int, int, int],\n",
    "              patch_size: Tuple[int, int, int] = PATCH_SIZE) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    volume: (D,H,W)\n",
    "    center: (z,y,x)\n",
    "    return: (pd,ph,pw)\n",
    "    \"\"\"\n",
    "    D, H, W = volume.shape\n",
    "    pd, ph, pw = patch_size\n",
    "    zc, yc, xc = center\n",
    "\n",
    "    z0, y0, x0 = zc - pd // 2, yc - ph // 2, xc - pw // 2\n",
    "    z1, y1, x1 = z0 + pd, y0 + ph, x0 + pw\n",
    "\n",
    "    patch = np.zeros((pd, ph, pw), dtype=volume.dtype)\n",
    "\n",
    "    z0s, y0s, x0s = max(z0, 0), max(y0, 0), max(x0, 0)\n",
    "    z1s, y1s, x1s = min(z1, D), min(y1, H), min(x1, W)\n",
    "\n",
    "    z0d, y0d, x0d = z0s - z0, y0s - y0, x0s - x0\n",
    "\n",
    "    if z1s > z0s and y1s > y0s and x1s > x0s:\n",
    "        patch[z0d:z0d+(z1s-z0s),\n",
    "              y0d:y0d+(y1s-y0s),\n",
    "              x0d:x0d+(x1s-x0s)] = volume[z0s:z1s, y0s:y1s, x0s:x1s]\n",
    "\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d2a15",
   "metadata": {},
   "source": [
    "### Centerline Î∞©Ìñ• Ï∂îÏ†ï + cosine Í≥ÑÏÇ∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5e12b541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centerline points: 1642 voxels\n",
      "Start pos: (np.int64(271), np.int64(232), np.int64(42)) | case: 01018ug_105\n",
      "Next pos: (np.int64(272), np.int64(232), np.int64(42))\n",
      "Tangent vec near p1: [ 0.16741001  0.33026265 -0.92892436]\n",
      "Cosine(centerline_dir, move_dir) = 0.16741000551157248\n"
     ]
    }
   ],
   "source": [
    "## Cos similarity test\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree  # Ïù¥ÎØ∏ ÏÑ§ÏπòÎêòÏñ¥ ÏûàÏùÑ Í±∞Í≥†, ÏóÜÏúºÎ©¥ pip install scipy\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1) centerline Ï¢åÌëú ÎΩëÏïÑÏÑú KDTree ÎßåÎì§Í∏∞\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# env ÏïàÏóê centerline Î≥ºÎ•®Ïù¥ ÏûàÎã§Í≥† Í∞ÄÏ†ï\n",
    "centerline_vol = env.centerline if hasattr(env, \"centerline\") else env.centerline_vol\n",
    "\n",
    "# centerline_vol > 0 Ïù∏ Î≥µÏÖÄÎì§Ïùò (z,y,x) Ï¢åÌëúÎì§\n",
    "cl_coords = np.argwhere(centerline_vol > 0)   # shape: (N, 3)\n",
    "\n",
    "print(f\"Centerline points: {cl_coords.shape[0]} voxels\")\n",
    "\n",
    "# ÏµúÍ∑ºÏ†ë ÌÉêÏÉâÏùÑ ÏúÑÌïú KDTree\n",
    "cl_tree = cKDTree(cl_coords)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) Ìï¥Îãπ ÏúÑÏπò Í∑ºÏ≤òÏùò centerline Î∞©Ìñ•(tangent) Ï∂îÏ†ï Ìï®Ïàò\n",
    "#    - PCA Î∞©Ïãù: Ï£ºÎ≥Ä Î™á Í∞úÏùò centerline Ï†êÏúºÎ°ú Ï£ºÏÑ±Î∂Ñ Î∞©Ìñ•(Ï≤´ PC)ÏùÑ tangent Î°ú ÏÇ¨Ïö©\n",
    "# ---------------------------------------------------\n",
    "def estimate_tangent(centerline_coords: np.ndarray,\n",
    "                     centerline_tree: cKDTree,\n",
    "                     pos: tuple,\n",
    "                     k: int = 5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    pos: (z, y, x) voxel Ï¢åÌëú\n",
    "    k  : Ï£ºÎ≥Ä Î™á Í∞úÏùò centerline Ï†êÏùÑ ÏÇ¨Ïö©Ìï†ÏßÄ (local window ÌÅ¨Í∏∞)\n",
    "    return: tangent vector (Í∏∏Ïù¥ 3Ïùò numpy array)\n",
    "    \"\"\"\n",
    "    pos = np.array(pos, dtype=float)\n",
    "\n",
    "    # centerline ÏÉÅÏóêÏÑú pos Ïóê Í∞ÄÏû• Í∞ÄÍπåÏö¥ kÍ∞úÏùò Ï†ê Ï∞æÍ∏∞\n",
    "    k = min(k, len(centerline_coords))\n",
    "    dists, idxs = centerline_tree.query(pos, k=k)\n",
    "\n",
    "    # idxs Í∞Ä scalar Í∞Ä Îê† Ïàò ÏûàÏñ¥ÏÑú Î≥¥Ï†ï\n",
    "    if np.isscalar(idxs):\n",
    "        local_pts = centerline_coords[[idxs]]  # (1,3)\n",
    "    else:\n",
    "        local_pts = centerline_coords[idxs]    # (k,3)\n",
    "\n",
    "    # Ï£ºÎ≥Ä Ï†êÎì§Ïù¥ ÏµúÏÜå 2Í∞úÎäî ÏûàÏñ¥Ïïº Î∞©Ìñ•ÏùÑ Ï∂îÏ†ïÌï† Ïàò ÏûàÏùå\n",
    "    if local_pts.shape[0] < 2:\n",
    "        # Î∞©Ìñ•Ïù¥ Ï†ïÏùò Ïïà ÎêòÎ©¥ 0Î≤°ÌÑ∞ Î∞òÌôò\n",
    "        return np.zeros(3, dtype=float)\n",
    "\n",
    "    # PCA(SVD) Î°ú 1Ï∞® Ï£ºÏÑ±Î∂Ñ = ÌòàÍ¥Ä ÏßÑÌñâ Î∞©Ìñ• Í∑ºÏÇ¨\n",
    "    mean = local_pts.mean(axis=0)\n",
    "    X = local_pts - mean\n",
    "    # (k,3) -> SVD\n",
    "    U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    tangent = Vt[0]   # shape: (3,)  Ï≤´ Î≤àÏß∏ Ï£ºÏÑ±Î∂Ñ\n",
    "\n",
    "    return tangent\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3) Ïù¥Îèô Î≤°ÌÑ∞ÏôÄ tangent Í∞Ñ cosine similarity Í≥ÑÏÇ∞ Ìï®Ïàò\n",
    "# ---------------------------------------------------\n",
    "def cosine_to_centerline(prev_pos, next_pos, tangent_vec) -> float:\n",
    "    \"\"\"\n",
    "    prev_pos: (z,y,x) Ïù¥Ï†Ñ ÏúÑÏπò\n",
    "    next_pos: (z,y,x) Îã§Ïùå ÏúÑÏπò\n",
    "    tangent_vec: centerline Î∞©Ìñ• Î≤°ÌÑ∞(3,)\n",
    "    return: cosine similarity [-1, 1]\n",
    "    \"\"\"\n",
    "    prev_pos = np.array(prev_pos, dtype=float)\n",
    "    next_pos = np.array(next_pos, dtype=float)\n",
    "    move_vec = next_pos - prev_pos  # agent Ïù¥Îèô Î∞©Ìñ•\n",
    "\n",
    "    # Í∏∏Ïù¥Í∞Ä 0Ïù∏ Î≤°ÌÑ∞Î©¥ Ï†ïÏùò Î∂àÍ∞Ä ‚Üí 0ÏúºÎ°ú Ï≤òÎ¶¨\n",
    "    if np.linalg.norm(move_vec) == 0 or np.linalg.norm(tangent_vec) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    v1 = move_vec / np.linalg.norm(move_vec)\n",
    "    v2 = tangent_vec / np.linalg.norm(tangent_vec)\n",
    "    cos = float(np.dot(v1, v2))\n",
    "\n",
    "    # ÏàòÏπòÏò§Ï∞® Î∞©ÏßÄÏö© clip\n",
    "    cos = float(np.clip(cos, -1.0, 1.0))\n",
    "    return cos\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4) Í∞ÑÎã® ÌÖåÏä§Ìä∏: envÏóêÏÑú Ìïú Ïä§ÌÖù Íµ¥Î†§Î≥¥Í≥† cosine Í∞í Ï∞çÏñ¥Î≥¥Í∏∞\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# 1) ÌôòÍ≤Ω Î¶¨ÏÖã ‚Üí ÏãúÏûë ÏúÑÏπò\n",
    "state, info = env.reset()\n",
    "p0 = tuple(info[\"pos\"])   # (z,y,x)\n",
    "print(\"Start pos:\", p0, \"| case:\", info.get(\"case\", \"NA\"))\n",
    "\n",
    "# 2) ÏòàÏãúÎ°ú action ÌïòÎÇò ÏÑ†ÌÉù (ÏûÑÏãúÎ°ú 0Î≤à Ïï°ÏÖò)\n",
    "#   - Ïó¨Í∏∞ÏÑúÎäî Îã®Ïàú ÌÖåÏä§Ìä∏Ïö©Ïù¥ÎØÄÎ°ú q_net ÏóÜÏù¥ random ÏúºÎ°úÎèÑ Í∞ÄÎä•\n",
    "test_action = 0  # ÎòêÎäî random.randint(0,5)\n",
    "\n",
    "# env ÎÇ¥Î∂Ä stepÏùÑ Ïç®ÏÑú next_pos ÏñªÍ∏∞\n",
    "state2, reward, done, _, info2 = env.step(test_action)\n",
    "p1 = tuple(info2[\"pos\"])  # (nz,ny,nx)\n",
    "\n",
    "print(\"Next pos:\", p1)\n",
    "\n",
    "# 3) tangent vector Ï∂îÏ†ï (p1 Ï£ºÎ≥Ä centerline Î∞©Ìñ•)\n",
    "tangent = estimate_tangent(cl_coords, cl_tree, p1, k=5)\n",
    "print(\"Tangent vec near p1:\", tangent)\n",
    "\n",
    "# 4) ÏΩîÏÇ¨Ïù∏ Í∞í Í≥ÑÏÇ∞\n",
    "cos_val = cosine_to_centerline(p0, p1, tangent)\n",
    "print(\"Cosine(centerline_dir, move_dir) =\", cos_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "33f85748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2. Centerline Í¥ÄÎ†® Ïú†Ìã∏\n",
    "# =========================\n",
    "\n",
    "def build_centerline_kdtree(centerline_vol: np.ndarray):\n",
    "    \"\"\"\n",
    "    centerline_vol > 0 Ïù∏ Ï¢åÌëúÎì§Î°ú KDTree ÏÉùÏÑ±\n",
    "    return: (coords, tree)\n",
    "      - coords: (N,3) array (z, y, x)\n",
    "    \"\"\"\n",
    "    coords = np.argwhere(centerline_vol > 0)\n",
    "    if coords.shape[0] == 0:\n",
    "        raise RuntimeError(\"Centerline volume is empty.\")\n",
    "    tree = cKDTree(coords)\n",
    "    return coords, tree\n",
    "\n",
    "\n",
    "def estimate_tangent(coords: np.ndarray,\n",
    "                     tree: cKDTree,\n",
    "                     pos: tuple,\n",
    "                     k: int = 5):\n",
    "    \"\"\"\n",
    "    ÌòÑÏû¨ ÏúÑÏπò pos Í∑ºÏ≤òÏùò centerline Ï†êÎì§ÏùÑ Ïù¥Ïö©Ìï¥ tangent vector Ï∂îÏ†ï\n",
    "    coords: (N,3)\n",
    "    pos: (z, y, x)\n",
    "    \"\"\"\n",
    "    pos_arr = np.array(pos, dtype=np.float32)\n",
    "    dist, idx = tree.query(pos_arr, k=k)\n",
    "    neighbors = coords[idx]    # (k, 3)\n",
    "\n",
    "    # Ï§ëÏã¨ÏóêÏÑú Ïù¥ÏõÉÎì§Ïùò Î∞©Ìñ• ÌèâÍ∑†\n",
    "    vecs = neighbors - pos_arr[None, :]\n",
    "    v = vecs.mean(axis=0)\n",
    "\n",
    "    norm = np.linalg.norm(v) + 1e-8\n",
    "    return v / norm\n",
    "\n",
    "\n",
    "def cosine_to_centerline(prev_pos: tuple,\n",
    "                         new_pos: tuple,\n",
    "                         tangent_vec: np.ndarray):\n",
    "    \"\"\"\n",
    "    prev_pos -> new_pos Î°úÏùò Ïù¥Îèô Î∞©Ìñ•Í≥º centerline tangentÍ∞Ñ cosine Í≥ÑÏÇ∞\n",
    "    \"\"\"\n",
    "    p0 = np.array(prev_pos, dtype=np.float32)\n",
    "    p1 = np.array(new_pos,  dtype=np.float32)\n",
    "    move_vec = p1 - p0\n",
    "\n",
    "    mv_norm = np.linalg.norm(move_vec)\n",
    "    if mv_norm < 1e-8:\n",
    "        return 0.0\n",
    "\n",
    "    move_vec = move_vec / (mv_norm + 1e-8)\n",
    "    t = tangent_vec / (np.linalg.norm(tangent_vec) + 1e-8)\n",
    "\n",
    "    cos_val = float(np.dot(move_vec, t))\n",
    "    return cos_val  # -1 ~ +1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbcbc23",
   "metadata": {},
   "source": [
    "### Env ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0031384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- RL / DQN ÏÑ§Ï†ï -----\n",
    "PATCH_SIZE = (32, 32, 32)\n",
    "BRUSH_RADIUS = 1         # centerline Ï£ºÎ≥Ä ÏÇ¥ÏßùÎßå Ïπ†ÌïòÍ∏∞\n",
    "MAX_STEPS_PER_EP = 800\n",
    "\n",
    "GAMMA = 0.99\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_LIMIT = 50000\n",
    "\n",
    "NUM_EPISODES = 300\n",
    "TARGET_UPDATE_EP = 10        # Î™á episodeÎßàÎã§ target net ÎèôÍ∏∞Ìôî\n",
    "VAL_INTERVAL_EP = 20         # Î™á episodeÎßàÎã§ validation ÏàòÌñâ\n",
    "\n",
    "EPS_START = 1.0\n",
    "EPS_END   = 0.05\n",
    "EPS_DECAY_EP = int(NUM_EPISODES * 0.7)   # 70% ÎèôÏïà ÏÑ†Ìòï Í∞êÏÜå\n",
    "\n",
    "# ----- Î≥¥ÏÉÅ Ìï®Ïàò Í¥ÄÎ†® -----\n",
    "R_DIR_SCALE = 1.0   # ÏùºÎã® 1.0Î∂ÄÌÑ∞ ÏãúÏûë, ÌïÑÏöîÌïòÎ©¥ 2.0, 3.0ÏúºÎ°ú ÌÇ§ÏõåÎ≥¥Í∏∞\n",
    "R_OUT       = -1.0  # Î∞ñÏúºÎ°ú ÎÇòÍ∞îÏùÑ Îïå Ìå®ÎÑêÌã∞\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0a51c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3. Env Ï†ïÏùò\n",
    "# =========================\n",
    "\n",
    "class CTVesselCenterEnv:\n",
    "    \"\"\"\n",
    "    state: (2, 32, 32, 32)\n",
    "      - ch0: normalized CT patch\n",
    "      - ch1: visited volume patch (ÎÇ¥Í∞Ä segmentation Ìïú Í≤∞Í≥º)\n",
    "\n",
    "    reward:\n",
    "      - volume Î∞ñ / vessel Î∞ñ : -1, done\n",
    "      - vessel ÎÇ¥Î∂Ä:\n",
    "          reward = |cos(centerline_dir, move_dir)|   (0 ~ 1.0)\n",
    "      - brush(visited_vol)ÏùÄ state ÏóÖÎç∞Ïù¥Ìä∏ Ïö©ÎèÑÎßå, rewardÏóêÎäî ÏòÅÌñ• ÏóÜÏùå\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 data_root: Path,\n",
    "                 patch_size=PATCH_SIZE,\n",
    "                 max_steps=MAX_STEPS,\n",
    "                 brush_radius=BRUSH_RADIUS):\n",
    "\n",
    "        self.data_root    = Path(data_root)\n",
    "        self.patch_size   = patch_size\n",
    "        self.max_steps    = max_steps\n",
    "        self.brush_radius = brush_radius\n",
    "\n",
    "        self.case_dirs = sorted([p for p in self.data_root.iterdir() if p.is_dir()])\n",
    "        if not self.case_dirs:\n",
    "            raise RuntimeError(f\"No case folders found under {self.data_root}\")\n",
    "\n",
    "        print(f\"Found {len(self.case_dirs)} cases under {self.data_root}\")\n",
    "\n",
    "        # episode-specific ÏÉÅÌÉú\n",
    "        self.ct            = None\n",
    "        self.mask          = None\n",
    "        self.centerline    = None\n",
    "        self.ct_norm       = None\n",
    "        self.visited_vol   = None\n",
    "\n",
    "        self.D = self.H = self.W = None\n",
    "        self.pos          = None\n",
    "        self.step_count   = 0\n",
    "        self.current_case_dir = None\n",
    "\n",
    "        # centerline KDTreeÏö©\n",
    "        self.centerline_coords = None\n",
    "        self.centerline_tree   = None\n",
    "\n",
    "    # ---------- ÎÇ¥Î∂Ä Ïú†Ìã∏ ----------\n",
    "\n",
    "    def _load_random_case(self):\n",
    "        \"\"\"Îç∞Ïù¥ÌÑ∞ÏÖãÏóêÏÑú ÎûúÎç§ ÏºÄÏù¥Ïä§ Î°úÎìú\"\"\"\n",
    "        while True:\n",
    "            case_dir = random.choice(self.case_dirs)\n",
    "            try:\n",
    "                ct, mask, cl = load_case(case_dir)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] skip {case_dir.name} - load error: {e}\")\n",
    "                continue\n",
    "\n",
    "            if mask.sum() == 0 or cl.sum() == 0:\n",
    "                print(f\"[WARN] skip {case_dir.name} - empty mask/centerline\")\n",
    "                continue\n",
    "\n",
    "            self.ct         = ct\n",
    "            self.mask       = mask.astype(np.uint8)\n",
    "            self.centerline = cl.astype(np.uint8)\n",
    "            self.ct_norm    = normalize_ct(ct)\n",
    "\n",
    "            self.visited_vol = np.zeros_like(self.mask, dtype=np.float32)\n",
    "\n",
    "            self.D, self.H, self.W = self.ct.shape\n",
    "            self.current_case_dir = case_dir\n",
    "\n",
    "            # centerline KDTree\n",
    "            coords, tree = build_centerline_kdtree(self.centerline)\n",
    "            self.centerline_coords = coords\n",
    "            self.centerline_tree   = tree\n",
    "\n",
    "            break  # ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Î°úÎìúÌñàÏúºÎ©¥ Ï¢ÖÎ£å\n",
    "\n",
    "    def _sample_start_pos(self):\n",
    "        \"\"\"ÏãúÏûë ÏúÑÏπò: centerline ÏúÑÏóêÏÑú ÎûúÎç§ ÏÑ†ÌÉù\"\"\"\n",
    "        cl_indices = self.centerline_coords\n",
    "        idx = np.random.randint(len(cl_indices))\n",
    "        return tuple(cl_indices[idx])\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"2Ï±ÑÎÑê state Î∞òÌôò: [CT patch, visited patch]\"\"\"\n",
    "        ct_patch  = get_patch(self.ct_norm,    self.pos, self.patch_size)\n",
    "        vis_patch = get_patch(self.visited_vol, self.pos, self.patch_size)\n",
    "        state = np.stack([ct_patch, vis_patch], axis=0).astype(np.float32)\n",
    "        return state\n",
    "\n",
    "    def _move(self, z, y, x, action):\n",
    "        \"\"\"\n",
    "        action: 0~5 (6Î∞©Ìñ•)\n",
    "          0: +z, 1: -z\n",
    "          2: +y, 3: -y\n",
    "          4: +x, 5: -x\n",
    "        \"\"\"\n",
    "        deltas = [\n",
    "            (1, 0, 0),   # +z\n",
    "            (-1, 0, 0),  # -z\n",
    "            (0, 1, 0),   # +y\n",
    "            (0, -1, 0),  # -y\n",
    "            (0, 0, 1),   # +x\n",
    "            (0, 0, -1),  # -x\n",
    "        ]\n",
    "        dz, dy, dx = deltas[action]\n",
    "        return z + dz, y + dy, x + dx\n",
    "\n",
    "    def _apply_brush_vessel(self, center_pos):\n",
    "        \"\"\"\n",
    "        vessel mask Í∏∞Ï§ÄÏúºÎ°ú Î∂ìÏπ†:\n",
    "          - Whole_artery mask == 1 Ïù¥Î©¥ÏÑú\n",
    "          - ÏïÑÏßÅ visited == 0 Ïù∏ voxelÎßå 1Î°ú Ï±ÑÏö¥Îã§\n",
    "        return: ÏÉàÎ°ú Ï±ÑÏö¥ voxel Í∞úÏàò (debugÏö©)\n",
    "        \"\"\"\n",
    "        z, y, x = center_pos\n",
    "        r = self.brush_radius\n",
    "\n",
    "        z_min, z_max = max(0, z-r), min(self.D, z+r+1)\n",
    "        y_min, y_max = max(0, y-r), min(self.H, y+r+1)\n",
    "        x_min, x_max = max(0, x-r), min(self.W, x+r+1)\n",
    "\n",
    "        target  = self.mask[z_min:z_max, y_min:y_max, x_min:x_max]\n",
    "        visited = self.visited_vol[z_min:z_max, y_min:y_max, x_min:x_max]\n",
    "\n",
    "        newly = (target == 1) & (visited == 0)\n",
    "        new_count = int(newly.sum())\n",
    "\n",
    "        visited[newly] = 1.0\n",
    "        self.visited_vol[z_min:z_max, y_min:y_max, x_min:x_max] = visited\n",
    "        return new_count\n",
    "\n",
    "    # ---------- Gym Ïä§ÌÉÄÏùº Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ ----------\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "        self._load_random_case()\n",
    "        self.pos = self._sample_start_pos()\n",
    "        self.step_count = 0\n",
    "\n",
    "        # ÏãúÏûë ÏúÑÏπòÎèÑ ÌïúÎ≤à Î∂ìÏπ†\n",
    "        self._apply_brush_vessel(self.pos)\n",
    "\n",
    "        state = self._get_state()\n",
    "        info = {\n",
    "            \"pos\":  self.pos,\n",
    "            \"case\": self.current_case_dir.name,\n",
    "        }\n",
    "        return state, info\n",
    "\n",
    "    def step(self, action: int):\n",
    "        z, y, x = self.pos\n",
    "        nz, ny, nx = self._move(z, y, x, action)\n",
    "\n",
    "        # 1) Î≥ºÎ•® Î∞ñ ‚Üí Ï¶âÏãú Ï¢ÖÎ£å\n",
    "        if not (0 <= nz < self.D and 0 <= ny < self.H and 0 <= nx < self.W):\n",
    "            reward = -1.0\n",
    "            done = True\n",
    "            return self._get_state(), reward, done, False, {\n",
    "                \"pos\": self.pos,\n",
    "                \"case\": self.current_case_dir.name,\n",
    "                \"reason\": \"out_of_volume\"\n",
    "            }\n",
    "\n",
    "        # 2) vessel mask Î∞ñ ‚Üí Ï¶âÏãú Ï¢ÖÎ£å\n",
    "        if self.mask[nz, ny, nx] == 0:\n",
    "            self.pos = (nz, ny, nx)\n",
    "            reward = -1.0\n",
    "            done = True\n",
    "            return self._get_state(), reward, done, False, {\n",
    "                \"pos\": self.pos,\n",
    "                \"case\": self.current_case_dir.name,\n",
    "                \"reason\": \"out_of_vessel\"\n",
    "            }\n",
    "\n",
    "        # 3) vessel ÎÇ¥Î∂Ä (Ï†ïÏÉÅ Ïù¥Îèô)\n",
    "        # (A) centerline tangent Ï∂îÏ†ï\n",
    "        tangent = estimate_tangent(\n",
    "            self.centerline_coords,\n",
    "            self.centerline_tree,\n",
    "            (nz, ny, nx),\n",
    "            k=5\n",
    "        )\n",
    "\n",
    "        # (B) Ïù¥Îèô Î∞©Ìñ•Í≥ºÏùò cosine\n",
    "        cos_val = cosine_to_centerline(\n",
    "            (z, y, x),\n",
    "            (nz, ny, nx),\n",
    "            tangent\n",
    "        )\n",
    "\n",
    "        # (C) Î∞©Ìñ•ÏÑ± Î≥¥ÏÉÅ (Ï†àÎåìÍ∞í ÏÇ¨Ïö©)\n",
    "        r_dir = abs(cos_val)\n",
    "\n",
    "        # (D) brushÎäî state ÏóÖÎç∞Ïù¥Ìä∏Îßå Îã¥Îãπ\n",
    "        self._apply_brush_vessel((nz, ny, nx))\n",
    "\n",
    "        reward = r_dir\n",
    "        done = False\n",
    "\n",
    "        # ÏÉÅÌÉú ÏóÖÎç∞Ïù¥Ìä∏\n",
    "        self.pos = (nz, ny, nx)\n",
    "        self.step_count += 1\n",
    "\n",
    "        if self.step_count >= self.max_steps:\n",
    "            done = True\n",
    "\n",
    "        return self._get_state(), reward, done, False, {\n",
    "            \"pos\": self.pos,\n",
    "            \"case\": self.current_case_dir.name,\n",
    "            \"reason\": \"normal\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0bd4e49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 cases under /Users/srpark/Projects/RL_project/data/processed/RL_cleaned\n",
      "(2, 32, 32, 32) {'pos': (np.int64(266), np.int64(270), np.int64(47)), 'case': '01011ug_508'}\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = Path(\"/Users/srpark/Projects/RL_project/data/processed/RL_cleaned\")\n",
    "env = CTVesselCenterEnv(DATA_ROOT)\n",
    "s, info = env.reset()\n",
    "print(s.shape, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7b4de11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ train IDs: 69Í∞ú, ÏòàÏãú 5Í∞ú: ['01018ug_73', '01011ug_506', '01015ug_89', '01015ug_100', '01015ug_72']\n",
      "üîπ train case dirs: 69Í∞ú\n",
      "    /Users/srpark/Projects/RL_project/data/processed/RL_cleaned/01018ug_73\n",
      "    /Users/srpark/Projects/RL_project/data/processed/RL_cleaned/01011ug_506\n",
      "    /Users/srpark/Projects/RL_project/data/processed/RL_cleaned/01015ug_89\n",
      "Found 100 cases under /Users/srpark/Projects/RL_project/data/processed/RL_cleaned\n",
      "‚ú® Train-env created! (cases = 69)\n",
      "state shape: (2, 32, 32, 32)\n",
      "start case: 01015ug_89 | start pos: (np.int64(202), np.int64(398), np.int64(18))\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1) split ÎîîÎ†âÌÜ†Î¶¨ / data root\n",
    "SPLIT_DIR = Path(\"/Users/srpark/Projects/RL_project/data/processed/RL_cleaned/splits\")\n",
    "DATA_ROOT = Path(\"/Users/srpark/Projects/RL_project/data/processed/RL_cleaned\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2) train split ID ÏùΩÍ∏∞\n",
    "# --------------------------------------------------\n",
    "train_ids = read_split_ids(SPLIT_DIR, \"train\")\n",
    "print(f\"üîπ train IDs: {len(train_ids)}Í∞ú, ÏòàÏãú 5Í∞ú:\", train_ids[:5])\n",
    "\n",
    "# ID ‚Üí Ïã§Ï†ú case Ìè¥Îçî Í≤ΩÎ°ú\n",
    "train_case_dirs = get_case_dirs(DATA_ROOT, train_ids)\n",
    "print(f\"üîπ train case dirs: {len(train_case_dirs)}Í∞ú\")\n",
    "for p in train_case_dirs[:3]:\n",
    "    print(\"   \", p)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3) EnvÎ•º train set Ï†ÑÏö©ÏúºÎ°ú ÏÉùÏÑ±\n",
    "#    (env.case_dirs Î•º train Ï†ÑÏö©ÏúºÎ°ú ÍµêÏ≤¥)\n",
    "# --------------------------------------------------\n",
    "\n",
    "def make_train_env(env_class, data_root: Path, train_dirs):\n",
    "    env = env_class(data_root)\n",
    "    env.case_dirs = train_dirs  # üîë Ïó¨Í∏∞ÏÑú train setÎßå ÏÇ¨Ïö©ÌïòÍ≤å Í≥†Ï†ï\n",
    "    print(f\"‚ú® Train-env created! (cases = {len(env.case_dirs)})\")\n",
    "    return env\n",
    "\n",
    "train_env = make_train_env(CTVesselCenterEnv, DATA_ROOT, train_case_dirs)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4) sanity check\n",
    "# --------------------------------------------------\n",
    "s, info = train_env.reset()\n",
    "print(\"state shape:\", s.shape)\n",
    "print(\"start case:\", info[\"case\"], \"| start pos:\", info[\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66411f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. 3D CNN Q-network & ReplayBuffer & train_step\n",
    "# ============================================================\n",
    "\n",
    "class CnnQNet(nn.Module):\n",
    "    def __init__(self, in_channels=2, n_actions=6):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),  # (2,32,32,32) -> (32,16,16,16)\n",
    "\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),  # -> (64,8,8,8)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 8 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_actions)   # Q-values\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        q = self.fc(x)\n",
    "        return q\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_action(self, state, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        state: np array (2,32,32,32)\n",
    "        \"\"\"\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.randint(0, 6)\n",
    "\n",
    "        s = torch.from_numpy(state).float().unsqueeze(0).to(DEVICE)\n",
    "        q = self.forward(s)\n",
    "        return int(torch.argmax(q, dim=1).item())\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=50000):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, s, a, r, ns, done):\n",
    "        self.buffer.append((s, a, r, ns, done))\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        idx = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        s, a, r, ns, done = zip(*(self.buffer[i] for i in idx))\n",
    "        return (\n",
    "            np.array(s, dtype=np.float32),\n",
    "            np.array(a, dtype=np.int64),\n",
    "            np.array(r, dtype=np.float32),\n",
    "            np.array(ns, dtype=np.float32),\n",
    "            np.array(done, dtype=np.float32),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666ce16b",
   "metadata": {},
   "source": [
    "### ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "744b151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "def train_dqn(\n",
    "    env,\n",
    "    num_episodes=3000,\n",
    "    max_steps_per_ep=500,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    "    lr=1e-4,\n",
    "    epsilon_start=0.9,\n",
    "    epsilon_end=0.05,\n",
    "    epsilon_decay=2000,\n",
    "    ckpt_dir=\"checkpoints_centerline\",\n",
    "    ckpt_every=100,          # Î™á ÏóêÌîºÏÜåÎìúÎßàÎã§ weight Ï†ÄÏû•Ìï†ÏßÄ\n",
    "):\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "    q_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "    target_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=lr)\n",
    "    buffer = ReplayBuffer(capacity=50000)\n",
    "\n",
    "    eps = epsilon_start\n",
    "    global_step = 0\n",
    "\n",
    "    reward_hist = []\n",
    "    best_avg10 = -1e9\n",
    "    best_ckpt_path = os.path.join(ckpt_dir, \"best_model.pth\")\n",
    "\n",
    "    print(\">>> Training DQN started...\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    for ep in range(1, num_episodes+1):\n",
    "        state, info = env.reset()\n",
    "        total_reward = 0.0\n",
    "\n",
    "        for step in range(max_steps_per_ep):\n",
    "            # epsilon decay (step Í∏∞Î∞ò)\n",
    "            eps = epsilon_end + (epsilon_start - epsilon_end) * \\\n",
    "                  np.exp(-1.0 * global_step / epsilon_decay)\n",
    "\n",
    "            action = q_net.sample_action(state, eps)\n",
    "\n",
    "            next_state, reward, done, _, info2 = env.step(action)\n",
    "\n",
    "            buffer.push(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            global_step += 1\n",
    "\n",
    "            # --- DQN update ---\n",
    "            if len(buffer) >= batch_size:\n",
    "                s, a, r, ns, d = buffer.sample(batch_size)\n",
    "\n",
    "                s_t  = torch.from_numpy(s).to(DEVICE)\n",
    "                a_t  = torch.from_numpy(a).to(DEVICE)\n",
    "                r_t  = torch.from_numpy(r).to(DEVICE)\n",
    "                ns_t = torch.from_numpy(ns).to(DEVICE)\n",
    "                d_t  = torch.from_numpy(d).to(DEVICE)\n",
    "\n",
    "                q = q_net(s_t).gather(1, a_t.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    q_next = target_net(ns_t).max(1)[0]\n",
    "                    target = r_t + gamma * q_next * (1 - d_t)\n",
    "\n",
    "                loss = F.smooth_l1_loss(q, target)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # ÌÉÄÍπÉ ÎÑ§Ìä∏ÏõåÌÅ¨Îäî ÏùºÏ†ï stepÎßàÎã§ ÎèôÍ∏∞Ìôî\n",
    "            if global_step % 500 == 0:\n",
    "                target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        reward_hist.append(total_reward)\n",
    "\n",
    "        # ---- Î°úÍ∑∏ Ï∂úÎ†• ----\n",
    "        if ep % 10 == 0:\n",
    "            avg10 = float(np.mean(reward_hist[-10:]))\n",
    "            elapsed = time.time() - t0\n",
    "            print(f\"[Ep {ep:04d}] \"\n",
    "                  f\"reward={total_reward:7.1f} (avg10={avg10:7.1f}), \"\n",
    "                  f\"steps={step+1:4d}, eps={eps:0.2f}, \"\n",
    "                  f\"buffer={len(buffer):5d}, case={info['case']}, \"\n",
    "                  f\"time={elapsed/60:4.1f} min\")\n",
    "\n",
    "            # best model Í∞±Ïã†\n",
    "            if avg10 > best_avg10:\n",
    "                best_avg10 = avg10\n",
    "                torch.save(q_net.state_dict(), best_ckpt_path)\n",
    "                print(f\"   ‚Ü≥ ‚úÖ best model updated (avg10={best_avg10:.1f})\")\n",
    "\n",
    "        # ---- ÏóêÌîºÏÜåÎìú Îã®ÏúÑ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• ----\n",
    "        if ep % ckpt_every == 0:\n",
    "            ckpt_path = os.path.join(ckpt_dir, f\"ep{ep:04d}.pth\")\n",
    "            torch.save(q_net.state_dict(), ckpt_path)\n",
    "            print(f\"   ‚Ü≥ üíæ checkpoint saved to {ckpt_path}\")\n",
    "\n",
    "    # ÌïôÏäµ ÎÅùÎÇú ÌõÑ ÏµúÏ¢Ö weight Ï†ÄÏû•\n",
    "    final_path = os.path.join(ckpt_dir, \"final_model.pth\")\n",
    "    torch.save(q_net.state_dict(), final_path)\n",
    "    print(f\"\\n>>> Training completed! Final model saved to {final_path}\")\n",
    "    print(f\"    Best model (avg10={best_avg10:.1f}) saved to {best_ckpt_path}\")\n",
    "\n",
    "    # ---- reward curve ÏãúÍ∞ÅÌôî & Ï†ÄÏû• ----\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(reward_hist, label=\"episode reward\")\n",
    "    if len(reward_hist) >= 10:\n",
    "        # 10-episode moving average\n",
    "        ma = np.convolve(reward_hist, np.ones(10)/10, mode=\"valid\")\n",
    "        plt.plot(range(9, 9+len(ma)), ma, label=\"moving avg (10ep)\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Training Reward Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    curve_path = os.path.join(ckpt_dir, \"reward_curve.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(curve_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"üìà Reward curve saved to {curve_path}\")\n",
    "\n",
    "    # reward historyÎèÑ ÎÇòÏ§ëÏóê Î∂ÑÏÑùÏö©ÏúºÎ°ú Ï†ÄÏû•\n",
    "    np.save(os.path.join(ckpt_dir, \"reward_hist.npy\"), np.array(reward_hist))\n",
    "\n",
    "    return q_net, target_net, reward_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8969ed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Training DQN started...\n",
      "[Ep 0010] reward=   -0.0 (avg10=    3.4), steps=   2, eps=0.86, buffer=  105, case=01010ug_169, time= 1.1 min\n",
      "   ‚Ü≥ ‚úÖ best model updated (avg10=3.4)\n",
      "[Ep 0020] reward=   48.4 (avg10=    8.3), steps=  97, eps=0.78, buffer=  299, case=01011ug_505, time= 4.2 min\n",
      "   ‚Ü≥ ‚úÖ best model updated (avg10=8.3)\n",
      "[Ep 0030] reward=   -0.2 (avg10=    6.5), steps=   3, eps=0.73, buffer=  453, case=01010ug_133, time= 6.7 min\n",
      "[Ep 0040] reward=   -0.4 (avg10=   19.4), steps=   5, eps=0.61, buffer=  825, case=01018ug_78, time=12.1 min\n",
      "   ‚Ü≥ ‚úÖ best model updated (avg10=19.4)\n",
      "[Ep 0050] reward=  548.5 (avg10=   62.5), steps= 822, eps=0.39, buffer= 1824, case=01011ug_526, time=26.1 min\n",
      "   ‚Ü≥ ‚úÖ best model updated (avg10=62.5)\n",
      "   ‚Ü≥ üíæ checkpoint saved to checkpoints_centerline/ep0050.pth\n",
      "[Ep 0060] reward=    0.8 (avg10=    2.5), steps=   5, eps=0.38, buffer= 1903, case=01018ug_94, time=27.5 min\n",
      "[Ep 0070] reward=    0.1 (avg10=   83.8), steps=   5, eps=0.22, buffer= 3193, case=01018ug_94, time=45.5 min\n",
      "   ‚Ü≥ ‚úÖ best model updated (avg10=83.8)\n",
      "[Ep 0080] reward=   -0.0 (avg10=    1.0), steps=   2, eps=0.22, buffer= 3245, case=01018ug_71, time=46.7 min\n",
      "[Ep 0090] reward=    0.7 (avg10=   16.0), steps=   6, eps=0.19, buffer= 3595, case=01011ug_511, time=51.9 min\n",
      "[Ep 0100] reward=   -0.0 (avg10=   92.1), steps=   2, eps=0.12, buffer= 4870, case=01011ug_511, time=69.9 min\n",
      "   ‚Ü≥ ‚úÖ best model updated (avg10=92.1)\n",
      "   ‚Ü≥ üíæ checkpoint saved to checkpoints_centerline/ep0100.pth\n",
      "[Ep 0110] reward=  888.8 (avg10=  102.7), steps=1000, eps=0.09, buffer= 6118, case=01015ug_93, time=87.4 min\n",
      "   ‚Ü≥ ‚úÖ best model updated (avg10=102.7)\n",
      "[Ep 0120] reward=    1.0 (avg10=   34.2), steps=   3, eps=0.08, buffer= 6656, case=01018ug_98, time=95.3 min\n",
      "[Ep 0130] reward=    7.0 (avg10=   75.4), steps=  17, eps=0.07, buffer= 7821, case=01018ug_75, time=111.6 min\n",
      "[Ep 0140] reward=  216.2 (avg10=   36.6), steps= 296, eps=0.06, buffer= 8469, case=01018ug_73, time=121.1 min\n",
      "[Ep 0150] reward=   -1.0 (avg10=  129.4), steps=   1, eps=0.06, buffer=10129, case=01010ug_133, time=144.2 min\n",
      "   ‚Ü≥ ‚úÖ best model updated (avg10=129.4)\n",
      "   ‚Ü≥ üíæ checkpoint saved to checkpoints_centerline/ep0150.pth\n",
      "[Ep 0160] reward=  938.0 (avg10=  161.6), steps=1000, eps=0.05, buffer=12371, case=01010ug_7, time=175.6 min\n",
      "   ‚Ü≥ ‚úÖ best model updated (avg10=161.6)\n",
      "[Ep 0170] reward=   -0.8 (avg10=  339.8), steps=   2, eps=0.05, buffer=16571, case=01018ug_75, time=234.2 min\n",
      "   ‚Ü≥ ‚úÖ best model updated (avg10=339.8)\n",
      "[Ep 0180] reward=   42.0 (avg10=   28.5), steps=  58, eps=0.05, buffer=17023, case=01018ug_91, time=240.8 min\n",
      "[Ep 0190] reward=    1.9 (avg10=  112.5), steps=  23, eps=0.05, buffer=18482, case=01018ug_96, time=261.5 min\n",
      "[Ep 0200] reward=  758.9 (avg10=  148.2), steps=1000, eps=0.05, buffer=20758, case=01011ug_521, time=293.5 min\n",
      "   ‚Ü≥ üíæ checkpoint saved to checkpoints_centerline/ep0200.pth\n",
      "[Ep 0210] reward=    1.2 (avg10=   41.6), steps=   4, eps=0.05, buffer=21653, case=01011ug_530, time=306.4 min\n",
      "[Ep 0220] reward=   -0.2 (avg10=   32.9), steps=   2, eps=0.05, buffer=22180, case=01011ug_527, time=314.2 min\n",
      "[Ep 0230] reward=    7.1 (avg10=  164.6), steps=  26, eps=0.05, buffer=24287, case=01011ug_522, time=343.8 min\n",
      "[Ep 0240] reward=    0.3 (avg10=  161.4), steps=   5, eps=0.05, buffer=27096, case=01018ug_70, time=383.2 min\n",
      "[Ep 0250] reward=   37.7 (avg10=  167.1), steps=  51, eps=0.05, buffer=29521, case=01010ug_4, time=417.4 min\n",
      "   ‚Ü≥ üíæ checkpoint saved to checkpoints_centerline/ep0250.pth\n",
      "[Ep 0260] reward=  333.6 (avg10=  205.4), steps= 531, eps=0.05, buffer=33178, case=01011ug_509, time=468.7 min\n",
      "[Ep 0270] reward=  195.1 (avg10=  117.4), steps= 337, eps=0.05, buffer=35280, case=01011ug_515, time=498.3 min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train_env Îäî Ïù¥ÎØ∏ train split Ï†ÑÏö©ÏúºÎ°ú ÎßåÎì§Ïñ¥Ï†∏ ÏûàÎã§Í≥† Í∞ÄÏ†ï\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m q_net, target_net, reward_hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dqn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps_per_ep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoints_centerline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# 100ÏóêÌîºÏÜåÎìúÎßàÎã§ ep0100.pth, ep0200.pth ... Ï†ÄÏû•\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[106], line 51\u001b[0m, in \u001b[0;36mtrain_dqn\u001b[0;34m(env, num_episodes, max_steps_per_ep, batch_size, gamma, lr, epsilon_start, epsilon_end, epsilon_decay, ckpt_dir, ckpt_every)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_steps_per_ep):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# epsilon decay (step Í∏∞Î∞ò)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     eps \u001b[38;5;241m=\u001b[39m epsilon_end \u001b[38;5;241m+\u001b[39m (epsilon_start \u001b[38;5;241m-\u001b[39m epsilon_end) \u001b[38;5;241m*\u001b[39m \\\n\u001b[1;32m     49\u001b[0m           np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m global_step \u001b[38;5;241m/\u001b[39m epsilon_decay)\n\u001b[0;32m---> 51\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mq_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     next_state, reward, done, _, info2 \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     55\u001b[0m     buffer\u001b[38;5;241m.\u001b[39mpush(state, action, reward, next_state, done)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/rl_project/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[104], line 44\u001b[0m, in \u001b[0;36mCnnQNet.sample_action\u001b[0;34m(self, state, epsilon)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m epsilon:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(s)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(torch\u001b[38;5;241m.\u001b[39margmax(q, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_env Îäî Ïù¥ÎØ∏ train split Ï†ÑÏö©ÏúºÎ°ú ÎßåÎì§Ïñ¥Ï†∏ ÏûàÎã§Í≥† Í∞ÄÏ†ï\n",
    "q_net, target_net, reward_hist = train_dqn(\n",
    "    env=train_env,\n",
    "    num_episodes=500,\n",
    "    max_steps_per_ep=1000,\n",
    "    ckpt_dir=\"checkpoints_centerline\",\n",
    "    ckpt_every=50,   # 100ÏóêÌîºÏÜåÎìúÎßàÎã§ ep0100.pth, ep0200.pth ... Ï†ÄÏû•\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ee60ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(q_net.state_dict(), \"ex05_checkpoint_centerline_latest.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f43432",
   "metadata": {},
   "source": [
    "### validation set ÌôïÏù∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3039d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. 3D CNN Q-network & ReplayBuffer & train_step\n",
    "# ============================================================\n",
    "\n",
    "class CnnQNet(nn.Module):\n",
    "    def __init__(self, in_channels=2, n_actions=6):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),  # (2,32,32,32) -> (32,16,16,16)\n",
    "\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),  # -> (64,8,8,8)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 8 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_actions)   # Q-values\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        q = self.fc(x)\n",
    "        return q\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_action(self, state, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        state: np array (2,32,32,32)\n",
    "        \"\"\"\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.randint(0, 6)\n",
    "\n",
    "        s = torch.from_numpy(state).float().unsqueeze(0).to(DEVICE)\n",
    "        q = self.forward(s)\n",
    "        return int(torch.argmax(q, dim=1).item())\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=50000):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, s, a, r, ns, done):\n",
    "        self.buffer.append((s, a, r, ns, done))\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        idx = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        s, a, r, ns, done = zip(*(self.buffer[i] for i in idx))\n",
    "        return (\n",
    "            np.array(s, dtype=np.float32),\n",
    "            np.array(a, dtype=np.int64),\n",
    "            np.array(r, dtype=np.float32),\n",
    "            np.array(ns, dtype=np.float32),\n",
    "            np.array(done, dtype=np.float32),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f38a891f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ model checkpoint loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "q_net = CnnQNet(in_channels=2, n_actions=6).to(DEVICE)\n",
    "state_dict = torch.load(\"checkpoints_centerline/ep0250.pth\", map_location=DEVICE)\n",
    "q_net.load_state_dict(state_dict)\n",
    "q_net.eval()\n",
    "\n",
    "print(\"‚úÖ model checkpoint loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "08114db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set ÏºÄÏù¥Ïä§ Ïàò: 14\n",
      "ÏòàÏãú 5Í∞ú: ['01018ug_86', '01018ug_72', '01018ug_87', '01010ug_8', '01018ug_85']\n",
      "Found 100 cases under /Users/srpark/Projects/RL_project/data/processed/RL_cleaned\n",
      "[01018ug_86] steps= 200, end_reason=normal\n",
      "[01018ug_72] steps= 200, end_reason=normal\n",
      "[01018ug_87] steps= 200, end_reason=normal\n",
      "[01010ug_8] steps= 200, end_reason=normal\n",
      "[01018ug_85] steps=   2, end_reason=out_of_vessel\n",
      "[01015ug_92] steps= 200, end_reason=normal\n",
      "[01015ug_97] steps= 200, end_reason=normal\n",
      "[01010ug_134] steps=   4, end_reason=out_of_vessel\n",
      "[01010ug_164] steps= 200, end_reason=normal\n",
      "[01011ug_529] steps= 200, end_reason=normal\n",
      "[01018ug_81] steps= 200, end_reason=normal\n",
      "[01018ug_84] steps= 200, end_reason=normal\n",
      "[01011ug_502] steps= 200, end_reason=normal\n",
      "[01010ug_174] steps=   1, end_reason=out_of_vessel\n",
      "\n",
      "‚úÖ val set inference ÏôÑÎ£å!\n",
      "PNG ÌååÏùº ÏúÑÏπò: val_traj_ep0250/traj_*.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "# =========================================\n",
    "# 1) val split ÏùΩÏñ¥ÏÑú case ÎîîÎ†âÌÜ†Î¶¨ Î¶¨Ïä§Ìä∏ ÎßåÎì§Í∏∞\n",
    "# =========================================\n",
    "SPLIT_DIR = DATA_ROOT / \"splits\"\n",
    "\n",
    "val_ids = read_split_ids(SPLIT_DIR, \"val\")\n",
    "val_case_dirs = get_case_dirs(DATA_ROOT, val_ids)\n",
    "\n",
    "print(f\"val set ÏºÄÏù¥Ïä§ Ïàò: {len(val_case_dirs)}\")\n",
    "print(\"ÏòàÏãú 5Í∞ú:\", [p.name for p in val_case_dirs[:5]])\n",
    "\n",
    "# =========================================\n",
    "# 2) ÌèâÍ∞ÄÏö© env ÏÉùÏÑ± (train envÏôÄ ÎèôÏùº + case_dirsÎßå valÎ°ú Ï†úÌïú)\n",
    "# =========================================\n",
    "env_val = CTVesselCenterEnv(\n",
    "    data_root=DATA_ROOT,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    max_steps=MAX_STEPS,\n",
    "    brush_radius=BRUSH_RADIUS,\n",
    ")\n",
    "\n",
    "# train ÎïåÎäî Ï†ÑÏ≤¥ caseÍ∞Ä Îì§Ïñ¥Í∞Ä ÏûàÏóàÏùÑ ÌÖêÎç∞,\n",
    "# Ïó¨Í∏∞ÏÑúÎäî val ÏºÄÏù¥Ïä§Îßå Ïì∞ÎèÑÎ°ù ÎçÆÏñ¥Ïì∞Í∏∞\n",
    "env_val.case_dirs = val_case_dirs\n",
    "\n",
    "# =========================================\n",
    "# 3) greedy rollout + info\n",
    "# =========================================\n",
    "def rollout_greedy_with_info(env, q_net, max_steps=200):\n",
    "    state, info = env.reset()\n",
    "    traj = [tuple(info[\"pos\"])]\n",
    "    done = False\n",
    "    last_info = info\n",
    "    steps = 0\n",
    "\n",
    "    while (not done) and steps < max_steps:\n",
    "        s_t = torch.from_numpy(state).float().unsqueeze(0).to(DEVICE)\n",
    "        q_values = q_net(s_t)         # (1, 6)\n",
    "        action = q_values.argmax(dim=1).item()  # ‚Üê greedy ÏÑ†ÌÉù\n",
    "\n",
    "        state, reward, done, _, info2 = env.step(action)\n",
    "        traj.append(tuple(info2[\"pos\"]))\n",
    "        last_info = info2\n",
    "        steps += 1\n",
    "\n",
    "    return np.array(traj), info, last_info, steps\n",
    "\n",
    "# =========================================\n",
    "# 4) centerline + trajectory 3D plot & Ï†ÄÏû•\n",
    "# =========================================\n",
    "def plot_centerline_and_traj(env, traj, case_name,\n",
    "                             local_only=True, pad=40,\n",
    "                             save_path=None):\n",
    "    \"\"\"\n",
    "    env.centerline Í≥º Ï£ºÏñ¥ÏßÑ trajÎ•º Ìï®Íªò 3DÎ°ú Í∑∏Î¶º.\n",
    "    local_only=True Ïù¥Î©¥ trajectory Í∑ºÏ≤òÎßå ÏûòÎùºÏÑú Í∑∏Î¶º.\n",
    "    \"\"\"\n",
    "    cl_vol = env.centerline\n",
    "    cl_idx = np.argwhere(cl_vol > 0)   # (Nc, 3) : (z,y,x)\n",
    "\n",
    "    zt, yt, xt = traj[:, 0], traj[:, 1], traj[:, 2]\n",
    "\n",
    "    if local_only:\n",
    "        z_min, z_max = max(0, zt.min() - pad), min(cl_vol.shape[0], zt.max() + pad)\n",
    "        y_min, y_max = max(0, yt.min() - pad), min(cl_vol.shape[1], yt.max() + pad)\n",
    "        x_min, x_max = max(0, xt.min() - pad), min(cl_vol.shape[2], xt.max() + pad)\n",
    "\n",
    "        sel = (\n",
    "            (cl_idx[:, 0] >= z_min) & (cl_idx[:, 0] <= z_max) &\n",
    "            (cl_idx[:, 1] >= y_min) & (cl_idx[:, 1] <= y_max) &\n",
    "            (cl_idx[:, 2] >= x_min) & (cl_idx[:, 2] <= x_max)\n",
    "        )\n",
    "        cl_plot = cl_idx[sel]\n",
    "    else:\n",
    "        cl_plot = cl_idx\n",
    "\n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # centerline\n",
    "    if len(cl_plot) > 0:\n",
    "        ax.scatter(\n",
    "            cl_plot[:, 2], cl_plot[:, 1], cl_plot[:, 0],\n",
    "            s=1, alpha=0.05, label=\"centerline\"\n",
    "        )\n",
    "\n",
    "    # trajectory\n",
    "    ax.plot(traj[:, 2], traj[:, 1], traj[:, 0],\n",
    "            linewidth=3, label=\"trajectory\")\n",
    "\n",
    "    # start / end\n",
    "    ax.scatter(traj[0, 2], traj[0, 1], traj[0, 0],\n",
    "               s=40, c=\"green\", label=\"start\")\n",
    "    ax.scatter(traj[-1, 2], traj[-1, 1], traj[-1, 0],\n",
    "               s=40, c=\"red\", label=\"end\")\n",
    "\n",
    "    ax.set_xlabel(\"x (col)\")\n",
    "    ax.set_ylabel(\"y (row)\")\n",
    "    ax.set_zlabel(\"z (slice)\")\n",
    "    ax.set_title(f\"3D trajectory on centerline | case {case_name}\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.view_init(elev=25, azim=-60)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        fig.savefig(save_path, dpi=150)\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# =========================================\n",
    "# 5) Ï†ÑÏ≤¥ val setÏóê ÎåÄÌï¥ inference + PNG Ï†ÄÏû•\n",
    "# =========================================\n",
    "save_dir = \"val_traj_ep0250\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for cdir in val_case_dirs:\n",
    "    # Ïù¥ ÏºÄÏù¥Ïä§Îßå ÏÇ¨Ïö©ÌïòÎèÑÎ°ù env ÎÇ¥Î∂Ä case_dirsÎ•º 1Í∞úÎ°ú Ïû†Ïãú Ï†úÌïú\n",
    "    env_val.case_dirs = [cdir]\n",
    "\n",
    "    traj, info0, last_info, steps = rollout_greedy_with_info(\n",
    "        env_val, q_net, max_steps=200\n",
    "    )\n",
    "    case_name = cdir.name\n",
    "    reason = last_info.get(\"reason\", \"unknown\")\n",
    "\n",
    "    save_path = os.path.join(save_dir, f\"traj_{case_name}.png\")\n",
    "    plot_centerline_and_traj(\n",
    "        env_val, traj, case_name,\n",
    "        local_only=True, pad=40,\n",
    "        save_path=save_path\n",
    "    )\n",
    "\n",
    "    results.append((case_name, steps, reason))\n",
    "    print(f\"[{case_name}] steps={steps:4d}, end_reason={reason}\")\n",
    "\n",
    "print(\"\\n‚úÖ val set inference ÏôÑÎ£å!\")\n",
    "print(f\"PNG ÌååÏùº ÏúÑÏπò: {save_dir}/traj_*.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b231671",
   "metadata": {},
   "source": [
    "## 05. Reward ÏàòÏ†ï"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791dcbf2",
   "metadata": {},
   "source": [
    "- Centerline cosine similarity + distance Í∞ÄÏ§ëÏπò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd98d769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1241fc5d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
