{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd806616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: mps\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# A-1 : ê¸°ë³¸ ì„¸íŒ… (ê³ ì •) \n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt   # centerline distance map\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f34f4caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train(ex): ['01018ug_73', '01011ug_506', '01015ug_89'] total case : 69\n",
      "Val  (ex): ['01018ug_86', '01018ug_72', '01018ug_87'] total case : 14\n",
      "Test (ex): ['01010ug_136', '01010ug_170', '01011ug_528'] total case : 16\n",
      "train_case_dirs (ex): [PosixPath('/Users/srpark/Projects/RL_project/data/processed/RL_cleaned_v2/01018ug_73')] train_case_dirs :  69\n",
      "val_case_dirs   (ex): [PosixPath('/Users/srpark/Projects/RL_project/data/processed/RL_cleaned_v2/01018ug_86')] val_case_dirs :  14\n",
      "test_case_dirs  (ex): [PosixPath('/Users/srpark/Projects/RL_project/data/processed/RL_cleaned_v2/01010ug_136')] test_case_dirs :  16\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# A-2. ë°ì´í„° ê²½ë¡œ & split íŒŒì¼ ì½ê¸° & ë°ì´í„° ë¡œë”© (ê³ ì •)\n",
    "# ============================================\n",
    "\n",
    "# ----- ë°ì´í„° / split ê²½ë¡œ -----\n",
    "DATA_ROOT = Path(\"/Users/srpark/Projects/RL_project/data/processed/RL_cleaned_v2\")\n",
    "SPLIT_DIR = DATA_ROOT / \"splits\"\n",
    "\n",
    "CT_NAME        = \"ct.nii.gz\"\n",
    "MASK_NAME      = \"whole_artery_cleaned.nii.gz\"\n",
    "CENTERLINE_NAME = \"centerline_v1.nii.gz\"\n",
    "\n",
    "# split íŒŒì¼ì—ì„œ ì¼€ì´ìŠ¤ ID ì½ê¸° í•¨ìˆ˜\n",
    "def read_split_ids(split_dir: Path, split_name: str) -> List[str]:\n",
    "    path = split_dir / f\"{split_name}.txt\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"{path} not found\")\n",
    "\n",
    "    ids = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                ids.append(line)\n",
    "    return ids\n",
    "\n",
    "# ì¼€ì´ìŠ¤ ID ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„í•  ìƒì„± \n",
    "train_ids = read_split_ids(SPLIT_DIR, \"train\")\n",
    "val_ids   = read_split_ids(SPLIT_DIR, \"val\")\n",
    "test_ids  = read_split_ids(SPLIT_DIR, \"test\")\n",
    "\n",
    "print(\"Train(ex):\", train_ids[:3], \"total case :\", len(train_ids))\n",
    "print(\"Val  (ex):\", val_ids[:3], \"total case :\", len(val_ids))\n",
    "print(\"Test (ex):\", test_ids[:3], \"total case :\", len(test_ids))\n",
    "\n",
    "\n",
    "# ì¼€ì´ìŠ¤ ID ë¦¬ìŠ¤íŠ¸ë¡œ ì¼€ì´ìŠ¤ ë””ë ‰í† ë¦¬ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜\n",
    "def get_case_dirs(data_root: Path, ids: List[str]):\n",
    "    out = []\n",
    "    for cid in ids:\n",
    "        cdir = data_root / cid\n",
    "        if cdir.is_dir():\n",
    "            out.append(cdir)\n",
    "    return out\n",
    "\n",
    "# ì¼€ì´ìŠ¤ ë””ë ‰í† ë¦¬ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "train_case_dirs = get_case_dirs(DATA_ROOT, train_ids)\n",
    "val_case_dirs = get_case_dirs(DATA_ROOT, val_ids)\n",
    "test_case_dirs = get_case_dirs(DATA_ROOT, test_ids)\n",
    "\n",
    "print(\"train_case_dirs (ex):\", train_case_dirs[:1], \"train_case_dirs : \" ,len(train_case_dirs))\n",
    "print(\"val_case_dirs   (ex):\", val_case_dirs[:1], \"val_case_dirs : \" ,len(val_case_dirs))\n",
    "print(\"test_case_dirs  (ex):\", test_case_dirs[:1], \"test_case_dirs : \" ,len(test_case_dirs))\n",
    "\n",
    "# ë°ì´í„° ë¡œë”© í•¨ìˆ˜\n",
    "def load_case(case_dir: Path,\n",
    "              ct_name: str = CT_NAME,\n",
    "              mask_name: str = MASK_NAME,\n",
    "              center_name: str = CENTERLINE_NAME):\n",
    "    \"\"\"ct / mask / centerline NIfTIë¥¼ ëª¨ë‘ ì½ì–´ì˜´.\"\"\"\n",
    "    ct_path   = case_dir / ct_name\n",
    "    mask_path = case_dir / mask_name\n",
    "    cl_path  = case_dir / center_name\n",
    "\n",
    "    if not ct_path.exists():   raise FileNotFoundError(ct_path)\n",
    "    if not mask_path.exists(): raise FileNotFoundError(mask_path)\n",
    "    if not cl_path.exists():  raise FileNotFoundError(cl_path)\n",
    "\n",
    "    ct_nii   = nib.load(str(ct_path))\n",
    "    mask_nii = nib.load(str(mask_path))\n",
    "    cl_nii  = nib.load(str(cl_path))\n",
    "\n",
    "    ct   = ct_nii.get_fdata().astype(np.float32)\n",
    "    mask = mask_nii.get_fdata().astype(np.float32)\n",
    "    cl  = cl_nii.get_fdata().astype(np.float32)\n",
    "\n",
    "    assert ct.shape == mask.shape == cl.shape, f\"shape mismatch in {case_dir.name}\"\n",
    "\n",
    "    return ct, mask, cl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf37ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# B-1. ê³µí†µ ìœ í‹¸í•¨ìˆ˜ (CT normalization, patch ì¶”ì¶œ)\n",
    "# ============================================\n",
    "\n",
    "############### CT ì •ê·œí™” í•¨ìˆ˜\n",
    "'''\n",
    "ct: ì›ë³¸ CT ë³¼ë¥¨\n",
    "hu_min: ìœˆë„ìš° í•˜í•œ (ê¸°ë³¸: -200 ì—°ë¶€ì¡°ì§)\n",
    "hu_max: ìœˆë„ìš° ìƒí•œ (ê¸°ë³¸: 300 ì¡°ì˜í˜ˆê´€)\n",
    "'''\n",
    "def normalize_ct(ct: np.ndarray, hu_min=-200.0, hu_max=300.0) -> np.ndarray:\n",
    "    ct_windowed = np.clip(ct, hu_min, hu_max)\n",
    "    ct_normalized = (ct_windowed - hu_min) / (hu_max - hu_min)\n",
    "    return ct_normalized.astype(np.float32)\n",
    "\n",
    "############### 3D íŒ¨ì¹˜ ì¶”ì¶œ í•¨ìˆ˜\n",
    "\n",
    "    \"\"\"\n",
    "    volumeì—ì„œ centerë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•˜ëŠ” 3D íŒ¨ì¹˜ ì¶”ì¶œ.    \n",
    "    í•­ìƒ size=patch_size ì¸ íŒ¨ì¹˜ë¥¼ ë°˜í™˜.\n",
    "    boundary ë²—ì–´ë‚˜ë©´ zero-padding ìë™ ì²˜ë¦¬.\n",
    "    \"\"\"\n",
    "\n",
    "def get_patch(volume: np.ndarray,\n",
    "              center: tuple[int, int, int],\n",
    "              patch_size: int | tuple[int, int, int]):\n",
    "    \n",
    "    # ì´ˆê¸°ì„¤ì •\n",
    "    D, H, W = volume.shape\n",
    "    if isinstance(patch_size, int):\n",
    "        pd = ph = pw = patch_size\n",
    "    else:\n",
    "        pd, ph, pw = patch_size\n",
    "\n",
    "    zc, yc, xc = center     # ì¤‘ì‹¬ ì¢Œí‘œ\n",
    "    \n",
    "    # ë°˜ê²½ ê³„ì‚°\n",
    "    rd, rh, rw = pd // 2, ph // 2, pw // 2\n",
    "    \n",
    "    # íŒ¨ì¹˜ ë°°ì—´ (zero initialized)\n",
    "    patch = np.zeros((pd, ph, pw), dtype=volume.dtype)\n",
    "\n",
    "    # volumeì—ì„œ ê°€ì ¸ì˜¬ ì‹¤ì œ ì¢Œí‘œ ë²”ìœ„\n",
    "    z0 = max(zc - rd, 0)      # ìŒìˆ˜ ë°©ì§€\n",
    "    z1 = min(zc + rd, D)      # ê°€ì¥ìë¦¬ ì œí•œ\n",
    "    y0 = max(yc - rh, 0)      # ìŒìˆ˜ ë°©ì§€\n",
    "    y1 = min(yc + rh, H)      # ê°€ì¥ìë¦¬ ì œí•œ\n",
    "    x0 = max(xc - rw, 0)      # ìŒìˆ˜ ë°©ì§€\n",
    "    x1 = min(xc + rw, W)      # ê°€ì¥ìë¦¬ ì œí•œ\n",
    "    \n",
    "    # patch ë‚´ë¶€ ìœ„ì¹˜\n",
    "    pz0 = rd - (zc - z0)    # íŒ¨ì¹˜ ë‚´ ì‹œì‘ ì¸ë±ìŠ¤\n",
    "    py0 = rh - (yc - y0)    # íŒ¨ì¹˜ ë‚´ ì‹œì‘ ì¸ë±ìŠ¤\n",
    "    px0 = rw - (xc - x0)    # íŒ¨ì¹˜ ë‚´ ì‹œì‘ ì¸ë±ìŠ¤\n",
    "\n",
    "    # ì‹¤ì œ ë¶™ì¼ ë¶€ë¶„ì˜ shape\n",
    "    src = volume[z0:z1, y0:y1, x0:x1] # volume ì—ì„œ ê°€ëŠ¥í•œ ë¶€ë¶„ ì¶”ì¶œ   \n",
    "    dz, dy, dx = src.shape\n",
    "\n",
    "    # zero-initialize í–ˆë˜ patchì— ì‹¤ì œê°’ ë„£ì–´ì£¼ê¸° (ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ìœ ì§€=padding)\n",
    "    patch[pz0:pz0+dz, py0:py0+dy, px0:px0+dx] = src\n",
    "\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2673d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# B-2. Centerline ê´€ë ¨ ìœ í‹¸\n",
    "# =========================\n",
    "\n",
    "# -----------------------------\n",
    "# KDTree ìƒì„±\n",
    "# -----------------------------\n",
    "\n",
    "def build_centerline_kdtree(centerline_vol: np.ndarray):\n",
    "    \"\"\"\n",
    "    centerline_vol > 0 ì¸ ì¢Œí‘œë“¤ë¡œ KDTree ìƒì„±\n",
    "    return: (coords, tree)\n",
    "      - coords: (N,3) array (z, y, x)\n",
    "    \"\"\"\n",
    "    coords = np.argwhere(centerline_vol > 0)  # centerline voxel ì˜ ëª¨ë“  ì¢Œí‘œ\n",
    "    if coords.shape[0] == 0:\n",
    "        raise RuntimeError(\"Centerline volume is empty.\")\n",
    "    \n",
    "    # cKDTree(k-Dimensional Tree)\n",
    "    tree = cKDTree(coords)  # ì¢Œí‘œë“¤ ê°„ì˜ ìµœê·¼ì ‘ ì´ì›ƒ ê²€ìƒ‰ì„ ë¹ ë¥´ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ìë£Œêµ¬ì¡°\n",
    "    return coords, tree\n",
    "\n",
    "# -----------------------------\n",
    "# agentê°€ ì´ë™í•œ ì¢Œí‘œ ì£¼ë³€ K ê°œì˜ centerline ìœ„ì˜ ì ë“¤ì˜ ì£¼ì„±ë¶„ ë°©í–¥ ê³„ì‚°\n",
    "# -----------------------------\n",
    "def estimate_tangent(coords: np.ndarray,\n",
    "                     tree: cKDTree,\n",
    "                     pos: tuple,\n",
    "                     k: int = 7) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    í˜„ì¬ ìœ„ì¹˜ pos ì£¼ë³€ì˜ centerline ì ë“¤ì„ ëª¨ì•„ì„œ\n",
    "    PCA(ì£¼ì„±ë¶„) ê¸°ë°˜ìœ¼ë¡œ tangent ë°©í–¥ ì¶”ì •.\n",
    "    \n",
    "    - coords: (N,3) centerline voxel ì¢Œí‘œ (z,y,x)\n",
    "    - pos   : (z,y,x)\n",
    "    - k     : ì£¼ë³€ ëª‡ ê°œì˜ ì´ì›ƒì„ ë³¼ì§€ \n",
    "    \"\"\"\n",
    "    pos_arr = np.array(pos, dtype=np.float32)\n",
    "\n",
    "    # ì´ì›ƒ kê°œ ì°¾ê¸°\n",
    "    \n",
    "    k_use = min(k, coords.shape[0])            # ì£¼ë³€ ì´ì›ƒ ê°œìˆ˜ëŠ” ì „ì²´ ì  ê°œìˆ˜ë³´ë‹¤ í´ ìˆ˜ ì—†ìŒ\n",
    "    _, idx = tree.query(pos_arr, k_use)        # pos_arr ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ k_use ê°œì˜ ì  ì¸ë±ìŠ¤\n",
    "    neigh = coords[idx]                        # k_use ê°œì˜ ì  ì¸ë±ìŠ¤ ì˜ ì¢Œí‘œê°’ ë°˜í™˜\n",
    "\n",
    "    # ì´ì›ƒë“¤ì„ í‰ê·  ê¸°ì¤€ìœ¼ë¡œ ì¤‘ì‹¬í™” (centered)\n",
    "    mean = neigh.mean(axis=0, keepdims=True)  # (1,3)\n",
    "    centered = neigh - mean                   # (k,3)\n",
    "\n",
    "    # ëª¨ë“  ì ì´ ê±°ì˜ ê°™ì€ ìœ„ì¹˜ì— ìˆìœ¼ë©´ ë°©í–¥ ì •ì˜ê°€ ì•ˆ ë¨\n",
    "    try:\n",
    "        _, s, vh = np.linalg.svd(centered, full_matrices=False)  # vh: (3,3)\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ íŠ¹ì´ê°’ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ë°©í–¥ì´ ë¶ˆëª…í™•\n",
    "        if s[0] < 1e-6:\n",
    "            return None\n",
    "            \n",
    "        # vh[0]ì€ ì´ë¯¸ ì •ê·œí™”ë˜ì–´ ìˆìŒ (SVDì˜ íŠ¹ì„±)\n",
    "        return vh[0].astype(np.float32)        # ì²« ë²ˆì§¸ í–‰: ì£¼ì„±ë¶„ ë°©í–¥\n",
    "        \n",
    "    except np.linalg.LinAlgError:\n",
    "        return None\n",
    "\n",
    "# -----------------------------\n",
    "# cos similarity ê³„ì‚° í•¨ìˆ˜ (ì´ì „ ìœ„ì¹˜, action í›„ ìœ„ì¹˜, tangent ë²¡í„°)\n",
    "# -----------------------------\n",
    "def cosine_to_centerline(prev_pos: tuple,\n",
    "                         new_pos: tuple,\n",
    "                         tangent_vec: np.ndarray):\n",
    "    \"\"\"\n",
    "    prev_pos -> new_pos ë¡œì˜ ì´ë™ ë°©í–¥ê³¼ centerline tangentê°„ cosine ê³„ì‚°\n",
    "    \"\"\"\n",
    "    # 1. ì¢Œí‘œë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜\n",
    "    p0 = np.array(prev_pos, dtype=np.float32)\n",
    "    p1 = np.array(new_pos,  dtype=np.float32)\n",
    "    \n",
    "    # 2. [ì´ë™ ë²¡í„°] ì´ë²ˆ í„´ì— ë‚´ê°€ ì›€ì§ì¸ ë°©í–¥ (ë‚˜ì¤‘ ìœ„ì¹˜ - ì²˜ìŒ ìœ„ì¹˜)\n",
    "    move_vec = p1 - p0\n",
    "\n",
    "    # 3. ì´ë™ ê±°ë¦¬ ê³„ì‚° \n",
    "    mv_norm = np.linalg.norm(move_vec)\n",
    "    \n",
    "    # 4. ë§Œì•½ ì›€ì§ì´ì§€ ì•Šì•˜ë‹¤ë©´(ê±°ë¦¬=0), ìœ ì‚¬ë„ëŠ” 0ì…ë‹ˆë‹¤\n",
    "    if mv_norm < 1e-8:\n",
    "        return 0.0\n",
    "\n",
    "    # 5. [ì •ê·œí™”] ì´ë™ ë²¡í„°ì˜ ê¸¸ì´ë¥¼ 1ë¡œ ë§Œë“­ë‹ˆë‹¤. (ë°©í–¥ë§Œ ë¹„êµí•˜ê¸° ìœ„í•´)\n",
    "    move_vec = move_vec / mv_norm\n",
    "    \n",
    "    # 6. ì •ë‹µ ë²¡í„°(tangent)ë„ ê¸¸ì´ë¥¼ 1ë¡œ ë§Œë“­ë‹ˆë‹¤. (ì´ë¯¸ ë˜ì–´ìˆì„ í…Œì§€ë§Œ ì•ˆì „ì¥ì¹˜)\n",
    "    t = tangent_vec / (np.linalg.norm(tangent_vec) + 1e-8)\n",
    "\n",
    "    # 7. [ë‚´ì (Dot Product)] ë‘ ë²¡í„°ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ êµ¬í•©ë‹ˆë‹¤.\n",
    "    # ê²°ê³¼ê°’ ë²”ìœ„: -1.0 ~ 1.0\n",
    "    # 1.0: ì™„ì „ ê°™ì€ ë°©í–¥ / 0.0: ì§ê° / -1.0: ì™„ì „ ë°˜ëŒ€ ë°©í–¥\n",
    "    \n",
    "    cos_val = float(np.dot(move_vec, t))\n",
    "    return cos_val  # -1 ~ +1\n",
    "\n",
    "# -----------------------------\n",
    "# ì´ë™ ì (point)ê³¼ centerline ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ì  ê±°ë¦¬\n",
    "# -----------------------------\n",
    "def point_to_centerline_distance(pos: tuple,\n",
    "                                 tree: cKDTree) -> float:\n",
    "    \"\"\"\n",
    "    í˜„ì¬ ìœ„ì¹˜ posì—ì„œ centerlineê¹Œì§€ì˜ ìµœì†Œ ê±°ë¦¬\n",
    "    pos: (z, y, x)\n",
    "    \"\"\"\n",
    "    pos_arr = np.array(pos, dtype=np.float32)\n",
    "    dist, _ = tree.query(pos_arr, k=1)\n",
    "    return float(dist)\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# ì´ë™ ë²¡í„°(ì„ ë¶„)ì™€ centerline ì‚¬ì´ ê±°ë¦¬\n",
    "# -----------------------------------------\n",
    "def segment_to_centerline_distance(prev_pos: tuple,\n",
    "                                   new_pos: tuple,\n",
    "                                   tree: cKDTree,\n",
    "                                   n_samples: int = 5) -> float:\n",
    "    \"\"\"\n",
    "    prev_pos -> new_pos ë¡œ ì´ë™í•˜ëŠ” ì„ ë¶„ì„ ë”°ë¼ n_samples ê°œì˜ ì ì„ ì°ì–´ì„œ\n",
    "    ê° ì ì—ì„œ centerlineê¹Œì§€ì˜ ê±°ë¦¬ ì¤‘ ìµœì†Œê°’ì„ ë¦¬í„´.\n",
    "\n",
    "    - prev_pos, new_pos: (z, y, x)\n",
    "    - ì‹¤ì œë¡œëŠ” \"ì´ë™ ê¶¤ì  ì „ì²´ê°€ centerlineì—ì„œ ì–¼ë§ˆë‚˜ ë–¨ì–´ì ¸ ìˆëŠ”ì§€\"ë¥¼ ë³´ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©.\n",
    "    \"\"\"\n",
    "    p0 = np.array(prev_pos, dtype=np.float32)\n",
    "    p1 = np.array(new_pos,  dtype=np.float32)\n",
    "\n",
    "    # ì„ ë¶„ ìœ„ì˜ sampling (0~1 ì‚¬ì´ ê· ë“±)\n",
    "    ts = np.linspace(0.0, 1.0, n_samples)\n",
    "    min_dist = float(\"inf\")\n",
    "\n",
    "    for t in ts:\n",
    "        p = (1.0 - t) * p0 + t * p1\n",
    "        dist, _ = tree.query(p, k=1)\n",
    "        if dist < min_dist:\n",
    "            min_dist = float(dist)\n",
    "\n",
    "    return float(min_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f76c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# B-3. ê³µí†µ ì‹œê°í™”í•¨ìˆ˜  \n",
    "# ============================================\n",
    "\n",
    "def plot_trajectory_3d(centerline_vol, traj, case_name, save_path=None):\n",
    "    \"\"\"\n",
    "    centerline_vol : (D,H,W) centerline mask (0/1)\n",
    "    traj           : (T,3) array of (z,y,x)\n",
    "    case_name      : str\n",
    "    save_path      : if provided, PNG ì €ì¥\n",
    "    \"\"\"\n",
    "    # centerline coords\n",
    "    cl_coords = np.argwhere(centerline_vol > 0)\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # centerline\n",
    "    ax.scatter(\n",
    "        cl_coords[:,2],  # x\n",
    "        cl_coords[:,1],  # y\n",
    "        cl_coords[:,0],  # z\n",
    "        c='skyblue', s=3, alpha=0.3, label=\"centerline\"\n",
    "    )\n",
    "\n",
    "    # traj\n",
    "    traj = np.array(traj)\n",
    "    ax.plot(\n",
    "        traj[:,2], traj[:,1], traj[:,0],\n",
    "        c='red', linewidth=3, label=\"trajectory\"\n",
    "    )\n",
    "\n",
    "    # start / end\n",
    "    ax.scatter(traj[0,2], traj[0,1], traj[0,0], c='green', s=80, label=\"start\")\n",
    "    ax.scatter(traj[-1,2], traj[-1,1], traj[-1,0], c='yellow', s=80, label=\"end\")\n",
    "\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_zlabel(\"z\")\n",
    "    ax.set_title(f\"3D Trajectory vs Centerline | {case_name}\")\n",
    "    ax.legend()\n",
    "\n",
    "    # view angle\n",
    "    ax.view_init(elev=30, azim=-60)\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=150)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "414856d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# C-1. ê°•í™”í•™ìŠµ í™˜ê²½ (action space = 26, reward : direction + distance + revisit penalty)\n",
    "# ============================================\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Sequence\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "# =========================================\n",
    "# í™˜ê²½ ì„¤ì • í´ë˜ìŠ¤ \n",
    "# ==========================================\n",
    " \n",
    "\"\"\"\n",
    "    3D CT í˜ˆê´€ ì¶”ì ìš© í™˜ê²½ (6 ë°©í–¥: Â±z, Â±y, Â±x)\n",
    "    \n",
    "    state  : (2, patch, patch, patch)\n",
    "             - ch0 : ì •ê·œí™”ëœ CT patch\n",
    "             - ch1 : visited patch (ì´ë¯¸ ì§€ë‚˜ê°„ voxel = 1.0 + brush_radius)\n",
    "    action : (ì´ 26ê°œ)\n",
    "             0: +z, 1: -z, 2: +y, 3: -y, 4: +x, 5: -x\n",
    "    reward :\n",
    "      - volume ë°– : íŒ¨ë„í‹° (out_penalty)\n",
    "      - vessel ë‚´ë¶€ ì´ë™ ì‹œ   :\n",
    "          * ë°©í–¥ ë³´ìƒ r_dir   = |cos(move, tangent)|\n",
    "          * ê±°ë¦¬ ë³´ìƒ r_dist  = exp(-dist^2 / (2 Ïƒ^2))\n",
    "          * ìƒˆ voxel ë°©ë¬¸ X   : revisit_penalty ì¶”ê°€\n",
    "\"\"\"\n",
    "ENV_CONFIG = {\n",
    "    \"patch_size\": (32, 32, 32),\n",
    "    \"max_steps\": 1000,\n",
    "    \"brush_radius\": 2,\n",
    "    \"sigma_dist\": 5.0,\n",
    "    \"w_dir\": 0.3,\n",
    "    \"w_dist\": 0.7,\n",
    "    \"revisit_penalty\": -1.0,\n",
    "    \"out_penalty\": -1.0,\n",
    "}\n",
    "\n",
    "\n",
    "class CTVesselEnv5:\n",
    "    def __init__(self, data_root=None, case_dirs=None, mode: str = None, augment: bool = None, config = ENV_CONFIG):\n",
    "            \n",
    "        # í´ë˜ìŠ¤ ë³€ìˆ˜ ì„¤ì •\n",
    "        self.patch_size      = config[\"patch_size\"]\n",
    "        self.max_steps       = config[\"max_steps\"]\n",
    "        self.brush_radius    = config[\"brush_radius\"]\n",
    "        self.sigma_dist      = config[\"sigma_dist\"]\n",
    "        self.w_dir           = config[\"w_dir\"]\n",
    "        self.w_dist          = config[\"w_dist\"]\n",
    "        self.revisit_penalty = config[\"revisit_penalty\"]\n",
    "        self.out_penalty     = config[\"out_penalty\"]\n",
    "        \n",
    "        self.augment = augment     # âœ… ì¸ìì—ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "        self.mode    = mode        # âœ… ì¸ìì—ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "        \n",
    "        # ---------- action ì •ì˜ (26 ë°©í–¥: 3x3x3 ì´ì›ƒ, ìê¸° ìì‹  ì œì™¸) ----------\n",
    "        # action: 0 ~ 25\n",
    "        self.deltas = []\n",
    "        for dz in (-1, 0, 1):\n",
    "            for dy in (-1, 0, 1):\n",
    "                for dx in (-1, 0, 1):\n",
    "                    if dz == 0 and dy == 0 and dx == 0:\n",
    "                        continue  # (0,0,0)ì€ ì œì™¸\n",
    "                    self.deltas.append((dz, dy, dx))\n",
    "        self.deltas = np.array(self.deltas, dtype=int)\n",
    "        self.n_actions = len(self.deltas)  # 26\n",
    "        \n",
    "        # ---------- case ëª©ë¡ ì„¤ì • ----------\n",
    "        if case_dirs is not None:\n",
    "            # ì´ë¯¸ train/val split í•´ì„œ list[Path]ë¡œ ë„˜ê²¨ì¤€ ê²½ìš° (ì§€ê¸ˆ ë„¤ ì…‹ì—…)\n",
    "            self.case_dirs = [Path(p) for p in case_dirs]\n",
    "            if not self.case_dirs:\n",
    "                raise RuntimeError(\"case_dirs is empty.\")\n",
    "            self.data_root = self.case_dirs[0].parent\n",
    "            print(f\"[Env5] Using explicit case_dirs: {len(self.case_dirs)} cases.\")\n",
    "        else:\n",
    "            # ì˜›ë‚  ìŠ¤íƒ€ì¼: data_root ì•„ë˜ì—ì„œ split_ratioë¡œ ë‚˜ëˆ”\n",
    "            if data_root is None:\n",
    "                raise ValueError(\"Either data_root or case_dirs must be provided.\")\n",
    "\n",
    "            self.data_root = Path(data_root)\n",
    "            all_cases = sorted([p for p in self.data_root.iterdir() if p.is_dir()])\n",
    "            if not all_cases:\n",
    "                raise RuntimeError(f\"No case folders under {self.data_root}\")\n",
    "\n",
    "            split_idx = int(len(all_cases) * split_ratio)\n",
    "            if mode == \"train\":\n",
    "                self.case_dirs = all_cases[:split_idx]\n",
    "                print(f\"[Train Env5] {len(self.case_dirs)} cases used.\")\n",
    "            else:\n",
    "                self.case_dirs = all_cases[split_idx:]\n",
    "                print(f\"[Eval Env5] {len(self.case_dirs)} cases used.\")\n",
    "\n",
    "            if not self.case_dirs:\n",
    "                raise RuntimeError(f\"No cases assigned for mode={mode}\")\n",
    "\n",
    "        # ---------- ì—í”¼ì†Œë“œë³„ ìƒíƒœ ë³€ìˆ˜ ----------\n",
    "        self.ct = None\n",
    "        self.mask = None\n",
    "        self.centerline = None\n",
    "        self.ct_norm = None\n",
    "        self.visited_vol = None\n",
    "\n",
    "        # ê±°ë¦¬/centerline ê´€ë ¨ ë§µ\n",
    "        self.dist_map = None           # centerlineê¹Œì§€ì˜ voxel ê±°ë¦¬\n",
    "        self.centerline_coords = None  # (N,3) ì¢Œí‘œ\n",
    "        self.centerline_tree = None    # KDTree\n",
    "\n",
    "        self.D = self.H = self.W = None\n",
    "        self.pos = None                # í˜„ì¬ ìœ„ì¹˜ (z,y,x)\n",
    "        self.step_count = 0\n",
    "        self.current_case_dir = None\n",
    "\n",
    "    # =====================================================\n",
    "    # Data augmentation (ì•ˆì „í•œ ë²”ìœ„ ë‚´ì—ì„œë§Œ)\n",
    "    # =====================================================\n",
    "      \n",
    "    def _safe_augment(self, ct, mask, cl):\n",
    "        \n",
    "        \"\"\"\n",
    "        spacing ì™œê³¡ì´ ì‹¬í•œ transposeëŠ” ì“°ì§€ ì•Šê³ ,\n",
    "        zì¶• ê³ ì • ìƒíƒœì—ì„œ (y,x) í‰ë©´ ë‚´ íšŒì „/flipë§Œ ì ìš©.\n",
    "        \"\"\"\n",
    "        \n",
    "        # (1) axial plane íšŒì „ (0,90,180,270ë„)\n",
    "        k = random.choice([0, 1, 2, 3])\n",
    "        if k != 0:\n",
    "            ct = np.rot90(ct, k, axes=(1, 2))\n",
    "            mask = np.rot90(mask, k, axes=(1, 2))\n",
    "            cl = np.rot90(cl, k, axes=(1, 2))\n",
    "\n",
    "        '''\n",
    "        # (2) ì¢Œìš° flip (yì¶•)\n",
    "        if random.random() < 0.5:\n",
    "            ct = np.flip(ct, axis=1)\n",
    "            mask = np.flip(mask, axis=1)\n",
    "            cl = np.flip(cl, axis=1)\n",
    "\n",
    "        # (3) ìƒí•˜ flip (xì¶•)\n",
    "        if random.random() < 0.5:\n",
    "            ct = np.flip(ct, axis=2)\n",
    "            mask = np.flip(mask, axis=2)\n",
    "            cl = np.flip(cl, axis=2)\n",
    "        '''\n",
    "        \n",
    "        return ct, mask, cl\n",
    "\n",
    "    # =====================================================\n",
    "    # ì¼€ì´ìŠ¤ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "    # ====================================================\n",
    "    def _load_random_case(self):\n",
    "        \"\"\"í•™ìŠµ/í‰ê°€ìš© ì¼€ì´ìŠ¤ ì¤‘ í•˜ë‚˜ë¥¼ ëœë¤ ë¡œë“œ\"\"\"\n",
    "        while True:\n",
    "            case_dir = random.choice(self.case_dirs)\n",
    "            try:\n",
    "                ct, mask, cl = load_case(case_dir)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] load failed at {case_dir.name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            if mask.sum() == 0:\n",
    "                # vessel mask ì—†ëŠ” ì¼€ì´ìŠ¤ëŠ” ìŠ¤í‚µ\n",
    "                print(f\"[WARN] empty vessel mask: {case_dir.name}\")\n",
    "                continue\n",
    "            if cl.sum() == 0:\n",
    "                # centerline ì—†ëŠ” ì¼€ì´ìŠ¤ëŠ” ìŠ¤í‚µ\n",
    "                print(f\"[WARN] empty centerline: {case_dir.name}\")\n",
    "                continue\n",
    "\n",
    "            # âœ… trainì¼ ë•Œë§Œ augmentation ì ìš©\n",
    "            if self.augment:\n",
    "                ct, mask, cl = self._safe_augment(ct, mask, cl)\n",
    "\n",
    "            self.ct = ct.astype(np.float32)\n",
    "            self.mask = (mask > 0.5).astype(np.uint8)\n",
    "            self.centerline = (cl > 0).astype(np.uint8)              # centerlineì€ ëŠì–´ì§€ë©´ í°ì¼ ë‚¨. threshold = 0 ë¡œ í•´ì•¼ ì•ˆì „\n",
    "            self.ct_norm = normalize_ct(self.ct)\n",
    "            self.visited_vol = np.zeros_like(self.mask, dtype=np.float32)    # visited_vol (0.0 ì´ˆê¸°í™”)\n",
    "\n",
    "            self.D, self.H, self.W = self.ct.shape\n",
    "            self.current_case_dir = case_dir\n",
    "\n",
    "            # centerline KDTree & ì¢Œí‘œ\n",
    "            self.centerline_coords, self.centerline_tree = build_centerline_kdtree(self.centerline)\n",
    "            \n",
    "            # centerlineê¹Œì§€ì˜ voxel ê±°ë¦¬ ë§µ (DT)   # centerline==1 ì¸ ê³³ì—ì„œëŠ” 0, ë©€ì–´ì§ˆìˆ˜ë¡ ì¦ê°€\n",
    "            self.dist_map = distance_transform_edt(1 - self.centerline)\n",
    "\n",
    "            break  # ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìœ¼ë©´ ì¢…ë£Œ\n",
    "            \n",
    "    # ====================================================\n",
    "    # ì‹œì‘ ìœ„ì¹˜: centerline ìœ„ì—ì„œ ëœë¤ ìƒ˜í”Œë§\n",
    "    # ====================================================\n",
    "    def _sample_start_pos(self):\n",
    "        idx = np.random.randint(len(self.centerline_coords))\n",
    "        return tuple(self.centerline_coords[idx])\n",
    "\n",
    "    # ====================================================\n",
    "    # í˜„ì¬ ìœ„ì¹˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ 2ì±„ë„ íŒ¨ì¹˜ ì¶”ì¶œ\n",
    "    # ====================================================\n",
    "    def _get_state(self):\n",
    "        ct_patch = get_patch(self.ct_norm, self.pos, self.patch_size)\n",
    "        vis_patch = get_patch(self.visited_vol, self.pos, self.patch_size)\n",
    "        state = np.stack([ct_patch, vis_patch], axis=0).astype(np.float32)\n",
    "        return state\n",
    "    \n",
    "    # =====================================================\n",
    "    # 26ë°©í–¥ ì¤‘ í•˜ë‚˜ë¡œ 1 voxel ì´ë™\n",
    "    # =====================================================\n",
    "    def _move(self, z, y, x, action: int):\n",
    "        dz, dy, dx = self.deltas[action]\n",
    "        return z + dz, y + dy, x + dx\n",
    "    \n",
    "    # =====================================================\n",
    "    # í˜„ì¬ ìœ„ì¹˜ì—ì„œ brush ì ìš© (ë°©ë¬¸ ì²˜ë¦¬)\n",
    "    # =====================================================\n",
    "    def _apply_brush(self, center_pos):\n",
    "        '''\n",
    "        ë¶“ ë°˜ê²½(brush_radius) ë‚´ì—ì„œ:\n",
    "          - vessel mask == 1 ì´ë©´ì„œ\n",
    "          - visited_vol == 0 ì¸ ìœ„ì¹˜ë§Œ 1ë¡œ ì±„ì›€\n",
    "        return: ìƒˆë¡œ ë°©ë¬¸í•œ voxel ê°œìˆ˜\n",
    "        '''\n",
    "        z, y, x = center_pos\n",
    "        r = self.brush_radius\n",
    "\n",
    "        z_min, z_max = max(0, z - r), min(self.D, z + r + 1)\n",
    "        y_min, y_max = max(0, y - r), min(self.H, y + r + 1)\n",
    "        x_min, x_max = max(0, x - r), min(self.W, x + r + 1)\n",
    "\n",
    "        target = self.mask[z_min:z_max, y_min:y_max, x_min:x_max]           # [center position + brush ì˜ì—­] ì¤‘ vessel mask ì— í•´ë‹¹í•˜ëŠ” ê³³ --- a\n",
    "        visited = self.visited_vol[z_min:z_max, y_min:y_max, x_min:x_max]   # [center position + brush ì˜ì—­] ì¤‘ visited_vol ì— í•´ë‹¹í•˜ëŠ” ê³³ --- b\n",
    "\n",
    "        newly = (target == 1) & (visited == 0)                              # a ì´ë©´ì„œ b ê°€ ì•„ë‹Œ ê³³ (ìƒˆë¡œ ë°©ë¬¸í•œ ê³³)\n",
    "        new_count = int(newly.sum())                                        # ìƒˆë¡œ ë°©ë¬¸í•œ voxel ê°œìˆ˜                               \n",
    "\n",
    "        # ì‹¤ì œ ë°©ë¬¸ í‘œì‹œ ì—…ë°ì´íŠ¸\n",
    "        self.visited_vol[z_min:z_max, y_min:y_max, x_min:x_max][newly] = 1.0    # visited_vol ì—ì„œ newly ì¸ ê³³ì„ 1.0 ìœ¼ë¡œ ì±„ì›€\n",
    "        \n",
    "        return new_count\n",
    "\n",
    "    # =====================================================\n",
    "    # ìƒˆ ì—í”¼ì†Œë“œ ì‹œì‘\n",
    "    # =====================================================\n",
    "    def reset(self, seed: int | None = None):\n",
    "        \n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "        self._load_random_case()\n",
    "        self.pos = self._sample_start_pos()\n",
    "        self.step_count = 0\n",
    "\n",
    "        # ì‹œì‘ ìœ„ì¹˜ ì£¼ë³€ë„ ë°©ë¬¸ ì²˜ë¦¬\n",
    "        self._apply_brush(self.pos)\n",
    "\n",
    "        state = self._get_state()\n",
    "        info = {\n",
    "            \"pos\": self.pos,\n",
    "            \"case\": self.current_case_dir.name,\n",
    "            \"reason\": \"reset\",\n",
    "        }\n",
    "        return state, info\n",
    "\n",
    "    # =====================================================\n",
    "    # í•œ step ì§„í–‰ \n",
    "    # =====================================================\n",
    "    def step(self, action: int):\n",
    "        \"\"\"\n",
    "        í•œ step ì§„í–‰:\n",
    "          - actionì— ë”°ë¼ ìœ„ì¹˜ ì´ë™\n",
    "          - ë³´ìƒ ê³„ì‚°\n",
    "          - done ì—¬ë¶€ íŒë‹¨\n",
    "        \"\"\"\n",
    "        z, y, x = self.pos\n",
    "        nz, ny, nx = self._move(z, y, x, action)\n",
    "\n",
    "        # ê¸°ë³¸ info\n",
    "        info = {\n",
    "            \"case\": self.current_case_dir.name,\n",
    "        }\n",
    "        # ---------- ë³´ìƒ ë° ì¢…ë£Œ ì¡°ê±´ íŒë‹¨ ----------\n",
    "        # ---------- 1) volume ë°–ìœ¼ë¡œ ë‚˜ê°€ë©´ (out_penalty + ì¦‰ì‹œ ì¢…ë£Œ ) ----------\n",
    "        if not (0 <= nz < self.D and 0 <= ny < self.H and 0 <= nx < self.W):\n",
    "            reward = self.out_penalty\n",
    "            done = True                             # episode ì¢…ë£Œ\n",
    "            info[\"pos\"] = self.pos                  # ë§ˆì§€ë§‰ ìœ íš¨ ìœ„ì¹˜\n",
    "            info[\"reason\"] = \"out_of_volume\"\n",
    "            return self._get_state(), reward, done, False, info\n",
    "\n",
    "        # ---------- 2) vessel mask ë°– (out_penalty + ì¦‰ì‹œ ì¢…ë£Œ ) ----------\n",
    "        if self.mask[nz, ny, nx] == 0:\n",
    "            reward = self.out_penalty\n",
    "            done = True                             # episode ì¢…ë£Œ\n",
    "            self.pos = (nz, ny, nx)\n",
    "            info[\"pos\"] = self.pos                  # ë§ˆì§€ë§‰ ìœ íš¨ ìœ„ì¹˜\n",
    "            info[\"reason\"] = \"out_of_vessel\"\n",
    "            return self._get_state(), reward, done, False, info\n",
    "\n",
    "        # ---------- 3) vessel ë‚´ë¶€: ë³´ìƒ ê³„ì‚° ----------\n",
    "        \n",
    "        # (A) ë°©í–¥ ë³´ìƒ: centerline tangentì™€ ì´ë™ ë°©í–¥ ê°„ cos\n",
    "        tangent = estimate_tangent(\n",
    "            self.centerline_coords,\n",
    "            self.centerline_tree,\n",
    "            (nz, ny, nx),\n",
    "        )\n",
    "        if tangent is not None:\n",
    "            cos_val = cosine_to_centerline((z, y, x), (nz, ny, nx), tangent)\n",
    "            r_dir = abs(cos_val)  # centerline ë°©í–¥ì´ê¸°ë§Œ í•˜ë©´ ë˜ë¯€ë¡œ ì ˆëŒ€ê°’ : ì¶• ë°©í–¥ì´ë©´ +1 ë˜ëŠ” -1 ê·¼ì²˜ê°€ ë˜ë¯€ë¡œ ì ˆëŒ“ê°’ ì‚¬ìš© (r_dir: 0~1)\n",
    "        else:\n",
    "            r_dir = 0.0  # ë°©í–¥ ë¶ˆëª…ì‹œ 0\n",
    "        \n",
    "        # (B) ê±°ë¦¬ ë³´ìƒ: centerlineì— ê°€ê¹Œìš¸ìˆ˜ë¡ 1ì— ê°€ê¹Œì›€\n",
    "        dist = float(self.dist_map[nz, ny, nx])\n",
    "        r_dist = math.exp(-(dist ** 2) / (2 * (self.sigma_dist ** 2)))  # 0~1\n",
    "\n",
    "        # (C) íƒí—˜ ë³´ìƒ : ìƒˆ voxelì„ ë°©ë¬¸í–ˆëŠ”ì§€ í™•ì¸\n",
    "        new_voxels = self._apply_brush((nz, ny, nx))\n",
    "                \n",
    "        if new_voxels == 0:\n",
    "            explore_reward = self.revisit_penalty \n",
    "        elif new_voxels < 5:\n",
    "            explore_reward = 0.1  # ì‘ì€ ë³´ë„ˆìŠ¤\n",
    "        elif new_voxels < 20:\n",
    "            explore_reward = 0.3  # ì¤‘ê°„ ë³´ë„ˆìŠ¤\n",
    "        else:\n",
    "            explore_reward = 0.5  # í° ë³´ë„ˆìŠ¤ (êµµì€ í˜ˆê´€)\n",
    "        \n",
    "        # ë³´ìƒ ì´í•© ([ë°©í–¥ ê°€ì¤‘ì¹˜ * ë°©í–¥ cosine] + [ê±°ë¦¬ê°€ì¤‘ì¹˜ * centerline ê³¼ ê±°ë¦¬] ë°˜ì˜)\n",
    "        reward = self.w_dir * r_dir + self.w_dist * r_dist + explore_reward\n",
    "\n",
    "        # ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "        self.pos = (nz, ny, nx)\n",
    "        self.step_count += 1\n",
    "        done = (self.step_count >= self.max_steps)\n",
    "\n",
    "        info[\"pos\"] = self.pos\n",
    "        info[\"reason\"] = \"normal\" if not done else \"max_steps\"\n",
    "\n",
    "        return self._get_state(), reward, done, False, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b829769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# C-2. 3D CNN Q-network (26 actions) + ReplayBuffer + train_step\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3D CNN Q-Network (26-actions)\n",
    "# ============================================================\n",
    "\n",
    "class CnnQNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Input state:  (2, 32, 32, 32)\n",
    "      - ch0: normalized CT patch\n",
    "      - ch1: visited patch\n",
    "\n",
    "    Output Q-values: (n_actions,)  # ê¸°ë³¸ 26\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=2, n_actions=26):\n",
    "        super().__init__()\n",
    "        self.n_actions = n_actions\n",
    "\n",
    "        # -------- 3D CNN Encoder -------- #\n",
    "        self.conv = nn.Sequential(\n",
    "            # (B,2,32,32,32) -> (B,16,32,32,32)\n",
    "            nn.Conv3d(in_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # -> (B,32,32,32,32)\n",
    "            nn.Conv3d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # -> (B,32,16,16,16)\n",
    "            nn.MaxPool3d(2),\n",
    "\n",
    "            # -> (B,64,16,16,16)\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # -> (B,64,16,16,16)\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # -> (B,64,8,8,8)\n",
    "            nn.MaxPool3d(2),\n",
    "        )\n",
    "\n",
    "        # -------- Fully Connected Head -------- #\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 8 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, self.n_actions)   # n_actions ì¶œë ¥\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = h.view(h.size(0), -1)  # flatten\n",
    "        q = self.fc(h)\n",
    "        return q\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_action(self, state, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        Epsilon-greedy action selection\n",
    "        state: numpy array (2,32,32,32)\n",
    "        \"\"\"\n",
    "        if random.random() < epsilon:\n",
    "            # 0 ~ n_actions-1 ì¤‘ ëœë¤\n",
    "            return random.randint(0, self.n_actions - 1)\n",
    "\n",
    "        s = torch.from_numpy(state).float().unsqueeze(0).to(DEVICE)\n",
    "        q = self.forward(s)  # (1, n_actions)\n",
    "        return int(torch.argmax(q, dim=1).item())\n",
    "    \n",
    "    \n",
    "    \n",
    "# ============================================================\n",
    "# Replay Buffer\n",
    "# ============================================================\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=100000):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, s, a, r, ns, done):\n",
    "        \"\"\"\n",
    "        s   : (2,32,32,32)\n",
    "        a   : int\n",
    "        r   : float\n",
    "        ns  : (2,32,32,32)\n",
    "        done: bool\n",
    "        \"\"\"\n",
    "        self.buffer.append((s, a, r, ns, done))\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        s, a, r, ns, done = zip(*(self.buffer[i] for i in indices))\n",
    "\n",
    "        return (\n",
    "            np.array(s, dtype=np.float32),       # (B,2,32,32,32)\n",
    "            np.array(a, dtype=np.int64),         # (B,)\n",
    "            np.array(r, dtype=np.float32),       # (B,)\n",
    "            np.array(ns, dtype=np.float32),      # (B,2,32,32,32)\n",
    "            np.array(done, dtype=np.float32),    # (B,)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c3a9c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ğŸ“Œ ìµœì í™”ëœ DQN í•™ìŠµ ë£¨í”„ (6ë°©í–¥ + centerline reward ì „ì œ)\n",
    "#   - step ê¸°ë°˜ epsilon decay\n",
    "#   - ì¶©ë¶„í•œ replay warm-up\n",
    "#   - target network ëŠë¦¬ê²Œ ë™ê¸°í™”\n",
    "#   - reward clipping\n",
    "#   - best model & ì •ê¸° checkpoint ì €ì¥\n",
    "#   - reward curve ì €ì¥\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "TRAIN_CONFIG = {\n",
    "    \"num_episodes\": 2000,                   # ì´ ì—í”¼ì†Œë“œ ìˆ˜\n",
    "    \"max_steps_per_ep\": 1000,               # í•œ ì—í”¼ì†Œë“œë‹¹ ìµœëŒ€ step ìˆ˜\n",
    "    \"batch_size\": 64,                       # ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°                            \n",
    "    \"gamma\": 0.99,                          # ê°ê°€ìœ¨    \n",
    "    \"lr\": 1e-5,                             # í•™ìŠµë¥   \n",
    "    \"epsilon_start\": 1.0,                   # íƒìƒ‰ë¥  ì‹œì‘ê°’    \n",
    "    \"epsilon_end\": 0.05,                    # íƒìƒ‰ë¥  ìµœì €ê°’\n",
    "    \"epsilon_decay_steps\": 30000,           # ê¸€ë¡œë²Œ step ê¸°ì¤€ìœ¼ë¡œ ì²œì²œíˆ ê°ì†Œ\n",
    "    \"replay_capacity\": 100000,               # replay buffer í¬ê¸°\n",
    "    \"replay_warmup\": 3000,                  # ì´ë§Œí¼ ìŒ“ì´ê¸° ì „ê¹Œì§€ëŠ” í•™ìŠµ ì•ˆ í•¨\n",
    "    \"target_update_steps\": 3000,            # ì´ stepë§ˆë‹¤ target_net ë™ê¸°í™”\n",
    "    \"ckpt_dir\": \"test08_checkpoints\",       # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬\n",
    "    \"ckpt_every_ep\": 50,                    # ëª‡ ì—í”¼ì†Œë“œë§ˆë‹¤ weight ì €ì¥í• ì§€\n",
    "    \"reward_clip_min\": -2.0,                # reward clipping ìµœì†Œê°’\n",
    "    \"reward_clip_max\": 4.0,                 # reward clipping ìµœëŒ€ê°’\n",
    "    \"max_grad_norm\": 5.0,                   # gradient clipping ê°’\n",
    "}\n",
    "#============================================================\n",
    "\n",
    "def train_dqn(env, config=None):\n",
    "    \"\"\"\n",
    "    DQN í•™ìŠµ ë£¨í”„\n",
    "    - ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” config(dict)ì—ì„œë§Œ ê°€ì ¸ì˜´\n",
    "    - configë¥¼ ìƒëµí•˜ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ TRAIN_CONFIG ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    # 1) config í•©ì¹˜ê¸° (ê¸°ë³¸ê°’ + override)\n",
    "    cfg = TRAIN_CONFIG.copy()\n",
    "    if config is not None:\n",
    "        cfg.update(config)   # í•„ìš”í•˜ë©´ ì¼ë¶€ë§Œ ë®ì–´ì“¸ ìˆ˜ ìˆìŒ\n",
    "\n",
    "    # 2) ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ì¤€ë¹„\n",
    "    os.makedirs(cfg[\"ckpt_dir\"], exist_ok=True)\n",
    "    n_actions = getattr(env, \"n_actions\")  # í™˜ê²½ì—ì„œ action ê°œìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "    # --- Q-network & Target-network ì¤€ë¹„ ---\n",
    "    q_net      = CnnQNet(in_channels=2, n_actions=n_actions).to(DEVICE)\n",
    "    target_net = CnnQNet(in_channels=2, n_actions=n_actions).to(DEVICE)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=cfg[\"lr\"])\n",
    "    buffer    = ReplayBuffer(capacity=cfg[\"replay_capacity\"])\n",
    "\n",
    "    global_step = 0\n",
    "    reward_hist = []\n",
    "\n",
    "    best_avg10 = -1e9\n",
    "    best_ckpt_path = os.path.join(cfg[\"ckpt_dir\"], \"best_model.pth\")\n",
    "\n",
    "    print(\">>> Training DQN started...\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 3) ì—í”¼ì†Œë“œ ë£¨í”„\n",
    "    for ep in range(1, cfg[\"num_episodes\"] + 1):\n",
    "        state, info = env.reset()\n",
    "        total_reward = 0.0\n",
    "\n",
    "        for step in range(cfg[\"max_steps_per_ep\"]):\n",
    "\n",
    "            # (1) epsilon ì—…ë°ì´íŠ¸\n",
    "            eps = cfg[\"epsilon_end\"] + (cfg[\"epsilon_start\"] - cfg[\"epsilon_end\"]) * \\\n",
    "                  np.exp(-1.0 * global_step / cfg[\"epsilon_decay_steps\"])\n",
    "\n",
    "            # (2) í–‰ë™ ì„ íƒ\n",
    "            action = q_net.sample_action(state, eps)\n",
    "\n",
    "            # (3) í™˜ê²½ ì§„í–‰\n",
    "            next_state, reward, done, _, info2 = env.step(action)\n",
    "\n",
    "            # reward clipping\n",
    "            reward_clipped = float(np.clip(\n",
    "                reward, cfg[\"reward_clip_min\"], cfg[\"reward_clip_max\"]\n",
    "            ))\n",
    "            done_float = 1.0 if done else 0.0\n",
    "\n",
    "            buffer.push(state, action, reward_clipped, next_state, done_float)\n",
    "\n",
    "            state = next_state\n",
    "            total_reward += reward_clipped\n",
    "            global_step += 1\n",
    "\n",
    "            # (4) replay warm-up ì´í›„ í•™ìŠµ\n",
    "            if len(buffer) >= cfg[\"replay_warmup\"] and len(buffer) >= cfg[\"batch_size\"]:\n",
    "                s, a, r, ns, d = buffer.sample(cfg[\"batch_size\"])\n",
    "\n",
    "                s_t  = torch.from_numpy(s).to(DEVICE)\n",
    "                a_t  = torch.from_numpy(a).to(DEVICE)\n",
    "                r_t  = torch.from_numpy(r).to(DEVICE)\n",
    "                ns_t = torch.from_numpy(ns).to(DEVICE)\n",
    "                d_t  = torch.from_numpy(d).to(DEVICE)\n",
    "\n",
    "                q_all = q_net(s_t)                              # (B, n_actions)\n",
    "                q_sa  = q_all.gather(1, a_t.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    q_next_all = target_net(ns_t)               # (B, n_actions)\n",
    "                    q_next_max = q_next_all.max(dim=1)[0]\n",
    "                    target = r_t + cfg[\"gamma\"] * q_next_max * (1.0 - d_t)\n",
    "\n",
    "                loss = F.smooth_l1_loss(q_sa, target)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(q_net.parameters(), cfg[\"max_grad_norm\"])\n",
    "                optimizer.step()\n",
    "\n",
    "            # (5) target network ë™ê¸°í™”\n",
    "            if global_step > 0 and global_step % cfg[\"target_update_steps\"] == 0:\n",
    "                target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # (6) ì—í”¼ì†Œë“œ ë¡œê·¸\n",
    "        reward_hist.append(total_reward)\n",
    "\n",
    "        if ep % 10 == 0:\n",
    "            avg10 = float(np.mean(reward_hist[-10:]))\n",
    "            elapsed = time.time() - t0\n",
    "            print(f\"[Ep {ep:04d}] \"\n",
    "                  f\"reward={total_reward:7.2f} (avg10={avg10:7.2f}), \"\n",
    "                  f\"steps={step+1:4d}, eps={eps:0.2f}, \"\n",
    "                  f\"buffer={len(buffer):6d}, case={info['case']}, \"\n",
    "                  f\"time={elapsed/60:5.1f} min\")\n",
    "\n",
    "            if avg10 > best_avg10 and len(reward_hist) >= 10:\n",
    "                best_avg10 = avg10\n",
    "                torch.save(q_net.state_dict(), best_ckpt_path)\n",
    "                print(f\"   â†³ âœ… best model updated (avg10={best_avg10:.2f})\")\n",
    "\n",
    "        # (7) ì •ê¸° checkpoint\n",
    "        if ep % cfg[\"ckpt_every_ep\"] == 0:\n",
    "            ckpt_path = os.path.join(cfg[\"ckpt_dir\"], f\"ep{ep:04d}.pth\")\n",
    "            torch.save(q_net.state_dict(), ckpt_path)\n",
    "            print(f\"   â†³ ğŸ’¾ checkpoint saved to {ckpt_path}\")\n",
    "\n",
    "    # (8) ìµœì¢… weight ì €ì¥\n",
    "    final_path = os.path.join(cfg[\"ckpt_dir\"], \"test07_final_model.pth\")\n",
    "    torch.save(q_net.state_dict(), final_path)\n",
    "    print(f\"\\n>>> Training completed! Final model saved to {final_path}\")\n",
    "    print(f\"    Best model (avg10={best_avg10:.2f}) saved to {best_ckpt_path}\")\n",
    "\n",
    "    # (9) reward curve ì €ì¥\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(reward_hist, label=\"episode reward\")\n",
    "    if len(reward_hist) >= 10:\n",
    "        ma = np.convolve(reward_hist, np.ones(10)/10, mode=\"valid\")\n",
    "        plt.plot(range(9, 9+len(ma)), ma, label=\"moving avg (10ep)\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Training Reward Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    curve_path = os.path.join(cfg[\"ckpt_dir\"], \"reward_curve.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(curve_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"ğŸ“ˆ Reward curve saved to {curve_path}\")\n",
    "\n",
    "    np.save(os.path.join(cfg[\"ckpt_dir\"], \"reward_hist.npy\"), np.array(reward_hist))\n",
    "\n",
    "    return q_net, target_net, reward_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08a77e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Env5] Using explicit case_dirs: 69 cases.\n",
      "[Env5] Using explicit case_dirs: 14 cases.\n"
     ]
    }
   ],
   "source": [
    "env_train = CTVesselEnv5(\n",
    "    case_dirs=train_case_dirs,\n",
    "    mode=\"train\",\n",
    "    augment=True,                    # âœ… í•™ìŠµìš©ì´ë‹ˆê¹Œ ì¼œë‘ê¸°\n",
    "    config=ENV_CONFIG,\n",
    ")\n",
    "\n",
    "env_val = CTVesselEnv5(\n",
    "    case_dirs=val_case_dirs,\n",
    "    mode=\"val\",\n",
    "    augment=False,                   # âœ… ê²€ì¦/ì‹œê°í™”ìš©ì´ë‹ˆê¹Œ ë„ê¸°\n",
    "    config=ENV_CONFIG,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "439b22b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Training DQN started...\n",
      "[Ep 0010] reward=  21.94 (avg10=  12.05), steps=  40, eps=0.90, buffer=   158, case=01011ug_527, time=  1.8 min\n",
      "   â†³ âœ… best model updated (avg10=12.05)\n",
      "[Ep 0020] reward=   4.53 (avg10=   3.10), steps=   8, eps=0.89, buffer=   214, case=01018ug_97, time=  3.4 min\n",
      "[Ep 0030] reward=   3.80 (avg10=   6.26), steps=   6, eps=0.89, buffer=   301, case=01011ug_530, time=  5.0 min\n",
      "[Ep 0040] reward=  24.27 (avg10=  17.44), steps=  54, eps=0.88, buffer=   628, case=01015ug_70, time=  6.8 min\n",
      "   â†³ âœ… best model updated (avg10=17.44)\n",
      "[Ep 0050] reward=  -0.23 (avg10=   5.77), steps=   3, eps=0.88, buffer=   758, case=01011ug_527, time=  8.4 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0050.pth\n",
      "[Ep 0060] reward=  80.37 (avg10=  27.83), steps=  93, eps=0.87, buffer=  1135, case=01018ug_94, time= 10.0 min\n",
      "   â†³ âœ… best model updated (avg10=27.83)\n",
      "[Ep 0070] reward=  40.30 (avg10=  11.49), steps=  44, eps=0.87, buffer=  1309, case=01018ug_89, time= 11.6 min\n",
      "[Ep 0080] reward=  -1.00 (avg10=   9.47), steps=   1, eps=0.86, buffer=  1474, case=01018ug_95, time= 13.1 min\n",
      "[Ep 0090] reward=  -0.02 (avg10=   0.76), steps=   2, eps=0.86, buffer=  1510, case=01015ug_76, time= 14.8 min\n",
      "[WARN] load failed at 01010ug_11: Error -3 while decompressing data: invalid literal/length code\n",
      "[Ep 0100] reward=  -1.00 (avg10=  13.60), steps=   1, eps=0.86, buffer=  1688, case=01011ug_503, time= 16.4 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0100.pth\n",
      "[Ep 0110] reward=  19.64 (avg10=  17.47), steps=  26, eps=0.85, buffer=  1960, case=01015ug_93, time= 18.0 min\n",
      "[Ep 0120] reward=   0.97 (avg10=   7.84), steps=   3, eps=0.85, buffer=  2101, case=01011ug_527, time= 19.9 min\n",
      "[Ep 0130] reward=   1.18 (avg10=   7.18), steps=   3, eps=0.84, buffer=  2216, case=01010ug_2, time= 21.7 min\n",
      "[Ep 0140] reward=   1.27 (avg10=   1.97), steps=   3, eps=0.84, buffer=  2255, case=01010ug_4, time= 23.3 min\n",
      "[Ep 0150] reward=  45.44 (avg10=   8.76), steps=  59, eps=0.84, buffer=  2388, case=01011ug_515, time= 24.8 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0150.pth\n",
      "[Ep 0160] reward=  -1.00 (avg10=  23.18), steps=   1, eps=0.83, buffer=  2718, case=01011ug_501, time= 26.6 min\n",
      "[Ep 0170] reward=   1.26 (avg10=   4.53), steps=   3, eps=0.83, buffer=  2788, case=01011ug_512, time= 28.3 min\n",
      "[Ep 0180] reward=  98.97 (avg10=  14.87), steps= 130, eps=0.82, buffer=  2990, case=01011ug_512, time= 30.0 min\n",
      "[Ep 0190] reward=  -1.00 (avg10=  18.82), steps=   1, eps=0.82, buffer=  3291, case=01010ug_171, time= 35.7 min\n",
      "[Ep 0200] reward=  -1.00 (avg10=   2.55), steps=   1, eps=0.82, buffer=  3341, case=01015ug_72, time= 37.9 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0200.pth\n",
      "[Ep 0210] reward=  -1.00 (avg10=   9.42), steps=   1, eps=0.81, buffer=  3480, case=01010ug_177, time= 41.4 min\n",
      "[Ep 0220] reward=   3.22 (avg10=   1.84), steps=   7, eps=0.81, buffer=  3526, case=01011ug_509, time= 44.0 min\n",
      "[Ep 0230] reward=  -1.00 (avg10=   0.86), steps=   1, eps=0.81, buffer=  3555, case=01015ug_70, time= 45.8 min\n",
      "[Ep 0240] reward=   1.39 (avg10=   0.56), steps=   8, eps=0.81, buffer=  3585, case=01015ug_75, time= 47.9 min\n",
      "[Ep 0250] reward=   0.18 (avg10=   7.18), steps=   2, eps=0.81, buffer=  3682, case=01015ug_93, time= 50.8 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0250.pth\n",
      "[Ep 0260] reward=  83.11 (avg10=  16.26), steps= 117, eps=0.80, buffer=  3963, case=01015ug_74, time= 56.3 min\n",
      "[Ep 0270] reward=  -1.00 (avg10=   3.68), steps=   1, eps=0.80, buffer=  4018, case=01018ug_73, time= 58.8 min\n",
      "[WARN] load failed at 01010ug_11: Error -3 while decompressing data: invalid literal/length code\n",
      "[WARN] load failed at 01010ug_11: Error -3 while decompressing data: invalid literal/length code\n",
      "[Ep 0280] reward=   0.14 (avg10=   2.64), steps=   2, eps=0.80, buffer=  4069, case=01018ug_89, time= 61.1 min\n",
      "[Ep 0290] reward=  -0.03 (avg10=  11.52), steps=   3, eps=0.79, buffer=  4259, case=01011ug_507, time= 65.2 min\n",
      "[Ep 0300] reward=  -1.00 (avg10=   5.43), steps=   1, eps=0.79, buffer=  4339, case=01010ug_2, time= 67.7 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0300.pth\n",
      "[Ep 0310] reward=  -1.00 (avg10=  11.05), steps=   1, eps=0.79, buffer=  4519, case=01011ug_515, time= 71.8 min\n",
      "[Ep 0320] reward=   0.29 (avg10=  17.37), steps=   2, eps=0.78, buffer=  4737, case=01018ug_80, time= 76.6 min\n",
      "[Ep 0330] reward=   0.02 (avg10=   5.09), steps=   2, eps=0.78, buffer=  4815, case=01011ug_527, time= 79.1 min\n",
      "[Ep 0340] reward=  70.68 (avg10=   8.66), steps=  91, eps=0.78, buffer=  4945, case=01010ug_5, time= 82.3 min\n",
      "[Ep 0350] reward=  -1.00 (avg10=   6.38), steps=   1, eps=0.78, buffer=  5051, case=01011ug_500, time= 85.5 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0350.pth\n",
      "[Ep 0360] reward=  -1.00 (avg10=   0.45), steps=   1, eps=0.78, buffer=  5079, case=01015ug_76, time= 87.3 min\n",
      "[WARN] load failed at 01010ug_11: Error -3 while decompressing data: invalid literal/length code\n",
      "[Ep 0370] reward=  -1.00 (avg10=   6.85), steps=   1, eps=0.77, buffer=  5207, case=01011ug_517, time= 90.5 min\n",
      "[Ep 0380] reward=   0.89 (avg10=   5.89), steps=   4, eps=0.77, buffer=  5300, case=01015ug_89, time= 93.5 min\n",
      "[Ep 0390] reward=  54.43 (avg10=   9.50), steps=  92, eps=0.77, buffer=  5458, case=01015ug_95, time= 97.3 min\n",
      "[Ep 0400] reward=  -1.00 (avg10=   0.34), steps=   1, eps=0.77, buffer=  5491, case=01018ug_70, time= 99.4 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0400.pth\n",
      "[Ep 0410] reward=   3.54 (avg10=  10.32), steps=   8, eps=0.76, buffer=  5631, case=01011ug_515, time=102.9 min\n",
      "[Ep 0420] reward=  81.23 (avg10=  23.96), steps= 114, eps=0.76, buffer=  5942, case=01018ug_82, time=108.7 min\n",
      "[Ep 0430] reward=  -1.00 (avg10=  26.53), steps=   1, eps=0.74, buffer=  6559, case=01011ug_512, time=118.9 min\n",
      "[Ep 0440] reward= 133.96 (avg10=  26.55), steps= 146, eps=0.74, buffer=  6914, case=01011ug_517, time=125.5 min\n",
      "[Ep 0450] reward=  10.20 (avg10=  18.25), steps=  13, eps=0.73, buffer=  7143, case=01011ug_508, time=130.2 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0450.pth\n",
      "[Ep 0460] reward= 274.45 (avg10=  42.93), steps= 498, eps=0.72, buffer=  7848, case=01015ug_90, time=141.6 min\n",
      "   â†³ âœ… best model updated (avg10=42.93)\n",
      "[Ep 0470] reward=   0.27 (avg10=  48.00), steps=   2, eps=0.70, buffer=  8535, case=01010ug_5, time=152.9 min\n",
      "   â†³ âœ… best model updated (avg10=48.00)\n",
      "[WARN] load failed at 01010ug_11: Error -3 while decompressing data: invalid literal/length code\n",
      "[Ep 0480] reward=   0.61 (avg10=   6.01), steps=   5, eps=0.70, buffer=  8618, case=01018ug_95, time=155.7 min\n",
      "[Ep 0490] reward=  -1.31 (avg10=   5.01), steps=   2, eps=0.70, buffer=  8699, case=01018ug_95, time=158.3 min\n",
      "[Ep 0500] reward=   4.64 (avg10=  11.82), steps=   6, eps=0.70, buffer=  8864, case=01011ug_514, time=162.2 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0500.pth\n",
      "[WARN] load failed at 01010ug_11: Error -3 while decompressing data: invalid literal/length code\n",
      "[Ep 0510] reward=  -1.00 (avg10=  23.27), steps=   1, eps=0.69, buffer=  9199, case=01011ug_515, time=168.3 min\n",
      "[Ep 0520] reward=   2.06 (avg10=   9.79), steps=   8, eps=0.69, buffer=  9324, case=01010ug_177, time=171.8 min\n",
      "[Ep 0530] reward=   2.25 (avg10=  16.87), steps=   4, eps=0.68, buffer=  9526, case=01011ug_507, time=176.0 min\n",
      "[Ep 0540] reward=   0.02 (avg10=  99.58), steps=   3, eps=0.66, buffer= 10777, case=01011ug_520, time=195.2 min\n",
      "   â†³ âœ… best model updated (avg10=99.58)\n",
      "[Ep 0550] reward=  -1.00 (avg10=  20.50), steps=   1, eps=0.65, buffer= 11059, case=01011ug_515, time=200.8 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0550.pth\n",
      "[Ep 0560] reward= 103.89 (avg10=  55.75), steps= 118, eps=0.64, buffer= 11732, case=01011ug_530, time=211.6 min\n",
      "[Ep 0570] reward=   0.10 (avg10=  43.30), steps=   2, eps=0.63, buffer= 12345, case=01010ug_171, time=221.6 min\n",
      "[Ep 0580] reward=  94.61 (avg10=  29.73), steps= 111, eps=0.62, buffer= 12730, case=01015ug_90, time=228.5 min\n",
      "[Ep 0590] reward=  -1.00 (avg10=  18.29), steps=   1, eps=0.62, buffer= 12946, case=01015ug_91, time=233.0 min\n",
      "[Ep 0600] reward=   4.44 (avg10=  32.52), steps=  11, eps=0.61, buffer= 13326, case=01011ug_521, time=239.9 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0600.pth\n",
      "[Ep 0610] reward=  -1.00 (avg10=  66.78), steps=   1, eps=0.60, buffer= 14218, case=01015ug_90, time=254.0 min\n",
      "[WARN] load failed at 01010ug_11: Error -3 while decompressing data: invalid literal/length code\n",
      "[Ep 0620] reward= 218.18 (avg10=  36.41), steps= 267, eps=0.59, buffer= 14687, case=01015ug_95, time=262.1 min\n",
      "[Ep 0630] reward=   3.42 (avg10=  44.89), steps=   6, eps=0.58, buffer= 15294, case=01015ug_71, time=272.2 min\n",
      "[Ep 0640] reward=   0.05 (avg10=   0.03), steps=   2, eps=0.58, buffer= 15320, case=01018ug_94, time=274.1 min\n",
      "[Ep 0650] reward=  -1.00 (avg10=   7.97), steps=   1, eps=0.58, buffer= 15434, case=01010ug_2, time=277.5 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0650.pth\n",
      "[Ep 0660] reward=   9.59 (avg10=  76.29), steps=   9, eps=0.56, buffer= 16294, case=01015ug_75, time=291.4 min\n",
      "[Ep 0670] reward=  -1.00 (avg10=   3.20), steps=   1, eps=0.56, buffer= 16349, case=01010ug_5, time=293.9 min\n",
      "[Ep 0680] reward= 266.35 (avg10=  33.52), steps= 268, eps=0.56, buffer= 16707, case=01015ug_100, time=300.4 min\n",
      "[Ep 0690] reward=  -0.24 (avg10=  42.42), steps=   3, eps=0.55, buffer= 17305, case=01015ug_93, time=310.6 min\n",
      "[Ep 0700] reward=  -0.14 (avg10=  13.74), steps=   4, eps=0.55, buffer= 17483, case=01011ug_522, time=314.8 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0700.pth\n",
      "[Ep 0710] reward= 181.96 (avg10=  58.13), steps= 232, eps=0.54, buffer= 18238, case=01011ug_514, time=327.2 min\n",
      "[Ep 0720] reward=  -1.00 (avg10=  58.42), steps=   1, eps=0.52, buffer= 19094, case=01015ug_95, time=341.0 min\n",
      "[Ep 0730] reward=   0.01 (avg10=   4.08), steps=   2, eps=0.52, buffer= 19163, case=01010ug_165, time=343.7 min\n",
      "[Ep 0740] reward= 141.38 (avg10=  65.83), steps= 135, eps=0.51, buffer= 19910, case=01010ug_171, time=355.9 min\n",
      "[Ep 0750] reward=  11.26 (avg10=   4.12), steps=  25, eps=0.51, buffer= 19987, case=01018ug_90, time=358.4 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0750.pth\n",
      "[Ep 0760] reward=   1.38 (avg10=   5.76), steps=   6, eps=0.51, buffer= 20067, case=01018ug_73, time=360.9 min\n",
      "[Ep 0770] reward=  -1.00 (avg10=  40.52), steps=   1, eps=0.50, buffer= 20505, case=01010ug_176, time=368.5 min\n",
      "[Ep 0780] reward=  -1.00 (avg10=  27.45), steps=   1, eps=0.50, buffer= 20872, case=01011ug_515, time=375.6 min\n",
      "[Ep 0790] reward=  -1.00 (avg10=   0.67), steps=   1, eps=0.50, buffer= 20900, case=01018ug_76, time=377.6 min\n",
      "[Ep 0800] reward=   1.95 (avg10=   0.26), steps=   6, eps=0.50, buffer= 20932, case=01010ug_167, time=379.6 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0800.pth\n",
      "[Ep 0810] reward=  -1.00 (avg10=  38.07), steps=   1, eps=0.49, buffer= 21311, case=01011ug_500, time=387.1 min\n",
      "[Ep 0820] reward=   0.25 (avg10=  86.39), steps=   2, eps=0.48, buffer= 22345, case=01018ug_80, time=403.7 min\n",
      "[WARN] load failed at 01010ug_11: Error -3 while decompressing data: invalid literal/length code\n",
      "[Ep 0830] reward= 104.89 (avg10=  11.15), steps= 147, eps=0.48, buffer= 22525, case=01015ug_90, time=408.1 min\n",
      "[Ep 0840] reward=  -0.05 (avg10=  95.74), steps=   2, eps=0.46, buffer= 23558, case=01010ug_165, time=424.4 min\n",
      "[Ep 0850] reward= 101.62 (avg10=  10.98), steps= 100, eps=0.46, buffer= 23687, case=01011ug_512, time=427.8 min\n",
      "   â†³ ğŸ’¾ checkpoint saved to test08_checkpoints/ep0850.pth\n",
      "[Ep 0860] reward=  -0.16 (avg10=  36.25), steps=   2, eps=0.46, buffer= 24138, case=01018ug_97, time=436.0 min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 29\u001b[0m\n\u001b[1;32m      5\u001b[0m TRAIN_CONFIG \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_episodes\u001b[39m\u001b[38;5;124m\"\u001b[39m:      \u001b[38;5;241m2000\u001b[39m,          \u001b[38;5;66;03m# ì „ì²´ ì—í”¼ì†Œë“œ ìˆ˜\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_steps_per_ep\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;241m1000\u001b[39m,     \u001b[38;5;66;03m# envì—ì„œ ì“´ ê°’ê³¼ ë§ì¶”ê¸°\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_grad_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m:     \u001b[38;5;241m5.0\u001b[39m,\n\u001b[1;32m     22\u001b[0m }\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# D-2. í•™ìŠµ ì‹œì‘\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m q_net, target_net, reward_hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dqn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAIN_CONFIG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# ë˜ëŠ” ê·¸ëƒ¥ train_dqn(env_train) (ë””í´íŠ¸ ì‚¬ìš©)\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Training finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[34], line 84\u001b[0m, in \u001b[0;36mtrain_dqn\u001b[0;34m(env, config)\u001b[0m\n\u001b[1;32m     80\u001b[0m eps \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon_end\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m (cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon_start\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon_end\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m*\u001b[39m \\\n\u001b[1;32m     81\u001b[0m       np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m global_step \u001b[38;5;241m/\u001b[39m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon_decay_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# (2) í–‰ë™ ì„ íƒ\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mq_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# (3) í™˜ê²½ ì§„í–‰\u001b[39;00m\n\u001b[1;32m     87\u001b[0m next_state, reward, done, _, info2 \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/rl_project/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 79\u001b[0m, in \u001b[0;36mCnnQNet.sample_action\u001b[0;34m(self, state, epsilon)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m epsilon:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# 0 ~ n_actions-1 ì¤‘ ëœë¤\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_actions \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(s)  \u001b[38;5;66;03m# (1, n_actions)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(torch\u001b[38;5;241m.\u001b[39margmax(q, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# D-1. í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "# ============================================\n",
    "\n",
    "TRAIN_CONFIG = {\n",
    "    \"num_episodes\":      2000,          # ì „ì²´ ì—í”¼ì†Œë“œ ìˆ˜\n",
    "    \"max_steps_per_ep\":  1000,     # envì—ì„œ ì“´ ê°’ê³¼ ë§ì¶”ê¸°\n",
    "    \"batch_size\":        64,\n",
    "    \"gamma\":             0.99,\n",
    "    \"lr\":                1e-5,\n",
    "    \"epsilon_start\":     0.9,\n",
    "    \"epsilon_end\":       0.1,\n",
    "    \"epsilon_decay_steps\": 30000,\n",
    "    \"replay_capacity\":   100000,\n",
    "    \"replay_warmup\":     3000,\n",
    "    \"target_update_steps\": 2000,\n",
    "    \"ckpt_dir\":          \"test08_checkpoints\",\n",
    "    \"ckpt_every_ep\":     50,\n",
    "    \"reward_clip_min\":   -2.0,\n",
    "    \"reward_clip_max\":   4.0,\n",
    "    \"max_grad_norm\":     5.0,\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# D-2. í•™ìŠµ ì‹œì‘\n",
    "# ============================================\n",
    "\n",
    "q_net, target_net, reward_hist = train_dqn(\n",
    "    env_train,\n",
    "    config=TRAIN_CONFIG,   # ë˜ëŠ” ê·¸ëƒ¥ train_dqn(env_train) (ë””í´íŠ¸ ì‚¬ìš©)\n",
    ")\n",
    "\n",
    "print(\"âœ… Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcbc89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward íˆìŠ¤í† ë¦¬ ë¶ˆëŸ¬ì™€ì„œ ì‹œê°í™”\n",
    "hist = np.load(\"../results/test08_checkpoints/reward_hist.npy\")\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(hist, alpha=0.5, label=\"episode reward\")\n",
    "if len(hist) >= 50:\n",
    "    ma = np.convolve(hist, np.ones(50)/50, mode=\"valid\")\n",
    "    plt.plot(range(49, 49+len(ma)), ma, label=\"moving avg(50)\")\n",
    "plt.legend(); plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6915f67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Running greedy evaluation on ALL val cases ...\n",
      "\n",
      "[01/14] case=01018ug_86 steps=3, R=-0.00, reason=out_of_vessel\n",
      "[02/14] case=01018ug_72 steps=9, R=8.29, reason=out_of_vessel\n",
      "[03/14] case=01018ug_87 steps=3, R=-0.00, reason=out_of_vessel\n",
      "[04/14] case=01010ug_8 steps=197, R=240.50, reason=out_of_vessel\n",
      "[05/14] case=01018ug_85 steps=4, R=-0.05, reason=out_of_vessel\n",
      "[06/14] case=01015ug_92 steps=2, R=-1.00, reason=out_of_vessel\n",
      "[07/14] case=01015ug_97 steps=3, R=-1.21, reason=out_of_vessel\n",
      "[08/14] case=01010ug_134 steps=3, R=0.03, reason=out_of_vessel\n",
      "[09/14] case=01010ug_164 steps=2, R=-1.00, reason=out_of_vessel\n",
      "[10/14] case=01011ug_529 steps=3, R=0.19, reason=out_of_vessel\n",
      "[11/14] case=01018ug_81 steps=3, R=0.07, reason=out_of_vessel\n",
      "[12/14] case=01018ug_84 steps=2, R=-1.00, reason=out_of_vessel\n",
      "[13/14] case=01011ug_502 steps=6, R=-0.49, reason=out_of_vessel\n",
      "[14/14] case=01010ug_174 steps=2, R=-1.00, reason=out_of_vessel\n",
      "\n",
      ">>> Evaluation finished!\n",
      "Results saved to: ../results/test08_val_greedy_results/val_results.csv\n",
      "Images saved to : ../results/test08_val_greedy_results\n"
     ]
    }
   ],
   "source": [
    "#################### \n",
    "# val envì—ì„œ greedy í‰ê°€\n",
    "#####################\n",
    "\n",
    "q_net = CnnQNet(in_channels=2, n_actions=26).to(DEVICE)\n",
    "state_dict = torch.load(\"../notebooks/test08_checkpoints/best_model.pth\", map_location=DEVICE)\n",
    "q_net.load_state_dict(state_dict)\n",
    "q_net.eval()\n",
    "\n",
    "\n",
    "def rollout_greedy(env, q_net, max_steps=300):\n",
    "    state, info = env.reset()\n",
    "    traj = [info[\"pos\"]]\n",
    "    total_r = 0.0\n",
    "    reasons = None\n",
    "\n",
    "    for t in range(max_steps):\n",
    "        a = q_net.sample_action(state, epsilon=0.0)\n",
    "        next_state, r, done, _, info2 = env.step(a)\n",
    "        traj.append(info2[\"pos\"])\n",
    "        total_r += r\n",
    "        state = next_state\n",
    "        if done:\n",
    "            reasons = info2[\"reason\"]\n",
    "            break\n",
    "    return np.array(traj), total_r, reasons\n",
    "\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# ì €ì¥ í´ë”\n",
    "save_dir = \"../results/test08_val_greedy_results\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(save_dir, \"val_results.csv\")\n",
    "\n",
    "# CSV ì¤€ë¹„\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"case\", \"steps\", \"total_reward\", \"reason\", \"png_path\"])\n",
    "\n",
    "print(\">>> Running greedy evaluation on ALL val cases ...\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, cdir in enumerate(val_case_dirs):\n",
    "    # val envì— í˜„ì¬ ì¼€ì´ìŠ¤ë§Œ ë„£ê¸°\n",
    "    env_val.case_dirs = [cdir]\n",
    "\n",
    "    # rollout\n",
    "    traj, total_R, reason = rollout_greedy(env_val, q_net, max_steps=300)\n",
    "    steps = len(traj)\n",
    "    case_name = cdir.name\n",
    "\n",
    "    # PNG ì €ì¥ ê²½ë¡œ\n",
    "    save_path = os.path.join(save_dir, f\"{case_name}_traj.png\")\n",
    "\n",
    "    # 3D plot ì €ì¥\n",
    "    plot_trajectory_3d(\n",
    "        centerline_vol=env_val.centerline,\n",
    "        traj=traj,\n",
    "        case_name=f\"{case_name}\",\n",
    "        save_path=save_path\n",
    "    )\n",
    "\n",
    "    results.append((case_name, steps, total_R, reason, save_path))\n",
    "\n",
    "    print(f\"[{idx+1:02d}/{len(val_case_dirs)}] case={case_name} \"\n",
    "          f\"steps={steps}, R={total_R:.2f}, reason={reason}\")\n",
    "\n",
    "# CSV ì €ì¥\n",
    "with open(csv_path, \"a\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(\"\\n>>> Evaluation finished!\")\n",
    "print(f\"Results saved to: {csv_path}\")\n",
    "print(f\"Images saved to : {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4463e90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
